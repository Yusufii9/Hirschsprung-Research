{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baa49fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import transforms, utils\n",
    "from einops import rearrange\n",
    "import os\n",
    "from torchvision.transforms import (\n",
    "    RandomHorizontalFlip,\n",
    "    RandomRotation,\n",
    "    RandomVerticalFlip,\n",
    "    RandomApply,\n",
    "    InterpolationMode,\n",
    "    RandomCrop,\n",
    "    RandomResizedCrop,\n",
    "    CenterCrop\n",
    ")\n",
    "import math\n",
    "import csv\n",
    "#from histo_vit import vit_small\n",
    "import random\n",
    "from torchvision.transforms.functional import hflip\n",
    "from torchvision.transforms.functional import vflip\n",
    "#import segmenter\n",
    "import og_mae\n",
    "from youssef_plexus_data_loading import HirschImagesDataset\n",
    "from metrics import mean_iou\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4c4773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image_with_map(_img, _map):\n",
    "    side_outer = 512\n",
    "    angle = torch.randint(low=0, high=90, size=(1,)).item()\n",
    "    \n",
    "    aug1 = torch.nn.Sequential(RandomRotation((angle, angle)))\n",
    "    \n",
    "    side_inner = side_outer / (math.cos(math.radians(angle)) + math.sin(math.radians(angle)))\n",
    "    #print(f\"The new h and w are: {side_inner}\")\n",
    "    \n",
    "    state = torch.get_rng_state()\n",
    "    _img = aug1(_img)\n",
    "\n",
    "    torch.set_rng_state(state)\n",
    "    _map = aug1(_map)\n",
    "    \n",
    "    center_x = side_outer // 2\n",
    "    center_y = side_outer // 2\n",
    "\n",
    "    half_width = side_inner // 2\n",
    "    half_height = side_inner // 2 \n",
    "\n",
    "    start_x = round(center_x - half_width)\n",
    "    end_x = round(center_x + half_width)\n",
    "    start_y = round(center_y - half_height)\n",
    "    end_y = round(center_y + half_height)\n",
    "\n",
    "    _img = _img[:, start_y:end_y, start_x:end_x]\n",
    "    _map = _map[:, start_y:end_y, start_x:end_x]\n",
    "    \n",
    "    aug2 = torch.nn.Sequential(\n",
    "    RandomHorizontalFlip(p=0.5),\n",
    "    RandomVerticalFlip(p=0.5),\n",
    "    RandomResizedCrop(size=(224, 224), scale=(0.5, 2.0)))\n",
    "    \n",
    "    state = torch.get_rng_state()\n",
    "    _img = aug2(_img)\n",
    "\n",
    "    torch.set_rng_state(state)\n",
    "    _map = aug2(_map)\n",
    "    \n",
    "    \n",
    "    return _img, _map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e854289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(epoch, sched_config):\n",
    "    \"\"\"Decay the learning rate with half-cycle cosine after warmup\"\"\"\n",
    "    if epoch < sched_config['warmup_epochs']:\n",
    "        lr = sched_config['lr'] * epoch / sched_config['warmup_epochs']\n",
    "    else:\n",
    "        lr = sched_config['min_lr'] + (sched_config['lr'] - sched_config['min_lr']) * 0.5 * \\\n",
    "            (1. + math.cos(math.pi * (epoch - sched_config['warmup_epochs']) / (sched_config['epochs'] - sched_config['warmup_epochs'])))\n",
    "    return lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "087c2f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "        for param_group in optimizer.param_groups:\n",
    "            return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19a825fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(y_pred, y_true):\n",
    "    smooth = 0.0001\n",
    "    # ytrue, ypred is a flatten vector\n",
    "    y_pred = y_pred.flatten()\n",
    "    y_true = y_true.flatten()\n",
    "    current = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "    # compute mean iou\n",
    "    intersection = np.diag(current)\n",
    "    ground_truth_set = current.sum(axis=1)\n",
    "    predicted_set = current.sum(axis=0)\n",
    "    union = ground_truth_set + predicted_set - intersection\n",
    "    IoU = (intersection+smooth) / (union.astype(np.float32)+smooth)\n",
    "    return np.mean(IoU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ed887cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = ['S14-580.pt',\n",
    "              'S00-1910.pt',\n",
    "              'S02-410.pt',\n",
    "              'S02-484.pt',\n",
    "              'S03-2391.pt',\n",
    "              'S01-18.pt',\n",
    "              \"S03-3178 D2.pt\",\n",
    "              \"S03-3178 D3.pt\",\n",
    "              \"S03-3178 D4.pt\",\n",
    "              'S04-52.pt',\n",
    "              'S04-910.pt',\n",
    "              'S07-1808.pt',\n",
    "              'S08-2215.pt',\n",
    "              'S09-2723.pt',\n",
    "              'S04-1840.pt',\n",
    "              'S07-1465.pt',\n",
    "              'S14-1715.pt',\n",
    "              'S09-2909.pt',\n",
    "              'S14-3414.pt',\n",
    "              'S14-2038.pt',\n",
    "              'S15-1442.pt',\n",
    "              'S15-1518.pt',\n",
    "              'S16-567.pt',\n",
    "              \"S16-1197 B1.pt\",\n",
    "              'S11-1760.pt',\n",
    "              'S16-1467.pt',\n",
    "              \"S16-1197 B3.pt\",\n",
    "              \"S16-1197 B2.pt\",\n",
    "              'S97-2054.pt',\n",
    "              'S16-1415.pt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2205ad9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 1e-05\n",
      "Epoch: 0, Train Loss: 1.2856874465942383, Val mIoU: 0.2483309462072781, Test mIoU: 0.24788114478446482, Base LR: 1e-05, LR Backbone: 0.0, LR Head: 0.0,\n",
      "Best Learning Rate: 1e-05\n",
      "SAVING\n",
      "Epoch: 1, Train Loss: 0.6635234355926514, Val mIoU: 0.45606926187342206, Test mIoU: 0.4568619153645153, Base LR: 1e-05, LR Backbone: 5.000000000000001e-07, LR Head: 5.000000000000001e-07,\n",
      "Best Learning Rate: 1e-05\n",
      "SAVING\n",
      "Epoch: 2, Train Loss: 0.11002148687839508, Val mIoU: 0.5008955117116878, Test mIoU: 0.5010086255956432, Base LR: 1e-05, LR Backbone: 1.0000000000000002e-06, LR Head: 1.0000000000000002e-06,\n",
      "Best Learning Rate: 1e-05\n",
      "SAVING\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [1e-5, 5e-5, 8e-5, 1e-4, 2e-4, 5e-4, 1e-3]\n",
    "best_lr = None\n",
    "best_model_state = None\n",
    "best_linear_layer = None\n",
    "use_mixup = False\n",
    "lambda_values = [0.2, 0.5, 0.8]\n",
    "\n",
    "columns = ['Learning Rate', 'Epoch', 'Train Loss', 'Val mIoU', 'Test mIoU']\n",
    "model_info_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for base_lr in learning_rates:\n",
    "\n",
    "    print(f'Learning Rate: {base_lr}')\n",
    "\n",
    "    batch_size = 64\n",
    "\n",
    "    train_dataset = HirschImagesDataset(data_file_path=\"plexus_train\", do_augmentation=True)\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=8\n",
    "                             )\n",
    "\n",
    "    val_dataset = HirschImagesDataset(data_file_path=\"plexus_val\", do_augmentation=False)\n",
    "    val_loader = DataLoader(val_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=False,\n",
    "                              num_workers=8\n",
    "                           )\n",
    "\n",
    "    test_dataset = HirschImagesDataset(data_file_path=\"plexus_test\", do_augmentation=False)\n",
    "    test_loader = DataLoader(test_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=False,\n",
    "                          num_workers=8\n",
    "                            )\n",
    "\n",
    "    best_val_miou = 0\n",
    "    #base_lr = 1e-4\n",
    "    learning_rate = base_lr * batch_size / 256 # added\n",
    "\n",
    "    model = og_mae.mae_vit_base_patch16_dec512d8b().cuda()\n",
    "    model.load_state_dict(torch.load('mae_visualize_vit_base.pth')['model'])\n",
    "    linear = nn.Linear(768, 512).cuda()\n",
    "\n",
    "    # optimizer\n",
    "    backbone_params = model.parameters()\n",
    "    linear_params = linear.parameters()\n",
    "    # head_params = seg_head.parameters()\n",
    "    opt = torch.optim.AdamW([{'params': backbone_params}, {'params': linear_params}], lr=learning_rate)\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Prep LR stepping\n",
    "    epochs = 50\n",
    "    multiplier = 1\n",
    "    backbone_config = {'lr': learning_rate,\n",
    "                       'warmup_epochs': 5,\n",
    "                       'min_lr': 0,\n",
    "                       'epochs': epochs}\n",
    "\n",
    "    head_config = {'lr': multiplier * learning_rate,\n",
    "                   'warmup_epochs': 5,\n",
    "                   'min_lr': 0,\n",
    "                   'epochs': epochs}\n",
    "    num_down = 0\n",
    "    for epoch in range(epochs):\n",
    "        if num_down >= 20:\n",
    "            break\n",
    "\n",
    "        opt.param_groups[0]['lr'] = adjust_learning_rate(epoch, backbone_config)\n",
    "        opt.param_groups[1]['lr'] = adjust_learning_rate(epoch, head_config)\n",
    "\n",
    "        current_lr_backbone = opt.param_groups[0]['lr']  # confirm\n",
    "        current_lr_head = opt.param_groups[1]['lr']  # confirm\n",
    "\n",
    "        train_losses = []\n",
    "\n",
    "        model = model.train()\n",
    "        # seg_head = seg_head.train()\n",
    "        linear = linear.train()\n",
    "        for batch in train_loader:\n",
    "            img, plexus = batch  # load from batch\n",
    "\n",
    "            # Q: I shouldn't augment again right?\n",
    "\n",
    "            img = img.cuda().to(dtype=torch.bfloat16) / 255  # (bsz, 3, H, W)\n",
    "            plexus = plexus.cuda().long().squeeze(dim=1)  # (bsz, H, W)\n",
    "\n",
    "            # Mix the inputs and the labels here\n",
    "            # 1st Step: flip the order of the images\n",
    "            if use_mixup:\n",
    "                img_flipped = img.flip(0)\n",
    "                img = (1 - lam) * img_flipped + lam * img\n",
    "\n",
    "            with torch.cuda.amp.autocast(dtype=torch.bfloat16):\n",
    "                x = model.patch_embed(img)\n",
    "                x = x + model.pos_embed[:, 1:, :]\n",
    "\n",
    "                cls_token = model.cls_token + model.pos_embed[:, :1, :]\n",
    "                cls_tokens = cls_token.expand(x.shape[0], -1, -1)\n",
    "                x = torch.cat((cls_tokens, x), dim=1)\n",
    "\n",
    "                # apply Transformer blocks\n",
    "                for blk in model.blocks:\n",
    "                    x = blk(x)  # (bsz, L, 768)\n",
    "\n",
    "                x = linear(x)  # (bsz, L, 512)\n",
    "                logits = rearrange(x[:, 1:, :], 'b (h w) (c i j) -> b c (h i) (w j)', h=14, w=14, c=2, i=16, j=16)  # (bsz, 2, H, W)\n",
    "                # logits = seg_head(features=x[:, 1:, :], HW_input=224, HW_target=224)  # (bsz, 2, H, W)\n",
    "\n",
    "#             print(logits.shape, plexus.shape)\n",
    "            if use_mixup:\n",
    "                loss_original = loss_function(logits, plexus)\n",
    "                loss_flipped = loss_function(logits, plexus.flip(0))\n",
    "                loss = (1 - lam) * loss_flipped + lam * loss_original\n",
    "            else:\n",
    "                loss = loss_function(logits, plexus)\n",
    "\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "#         val_losses = []\n",
    "        thresh = 0.5\n",
    "        all_predictions_val  = []\n",
    "        all_gt_val = []\n",
    "        model.eval()\n",
    "        for batch in val_loader:\n",
    "            img, plexus = batch  # load from batch\n",
    "            img = img.cuda().to(dtype=torch.bfloat16) / 255  # (bsz, 3, H, W)\n",
    "            plexus = plexus.cuda().long().squeeze(dim=1)  # (bsz, H, W)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                with torch.cuda.amp.autocast(dtype=torch.bfloat16):\n",
    "                    x = model.patch_embed(img)\n",
    "                    x = x + model.pos_embed[:, 1:, :]\n",
    "\n",
    "                    cls_token = model.cls_token + model.pos_embed[:, :1, :]\n",
    "                    cls_tokens = cls_token.expand(x.shape[0], -1, -1)\n",
    "                    x = torch.cat((cls_tokens, x), dim=1)\n",
    "\n",
    "                    # apply Transformer blocks\n",
    "                    for blk in model.blocks:\n",
    "                        x = blk(x)  # (bsz, L, 768)\n",
    "\n",
    "                    x = linear(x)  # (bsz, L, 512)\n",
    "                    logits = rearrange(x[:, 1:, :], 'b (h w) (c i j) -> b c (h i) (w j)', h=14, w=14, c=2, i=16,\n",
    "                                       j=16)  # (bsz, 2, H, W)\n",
    "                    probability = logits.softmax(dim=1)\n",
    "                    predictions = (probability[:,1,:, :] > thresh).long()\n",
    "#                     predictions  = logits.argmax(dim=1)  # (bza, H, W)\n",
    "            all_predictions_val.append(predictions.cpu())\n",
    "            all_gt_val.append(plexus.cpu())\n",
    "                    # logits = seg_head(features=x[:, 1:, :], HW_input=224, HW_target=224)  # (bsz, 2, H, W)\n",
    "\n",
    "#             loss = loss_function(logits, plexus)\n",
    "#             val_losses.append(loss.item())\n",
    "        all_predictions_val = torch.cat(all_predictions_val, dim=0).numpy()\n",
    "        all_gt_val = torch.cat(all_gt_val, dim=0).numpy()\n",
    "\n",
    "        val_miou = compute_iou(all_predictions_val, all_gt_val)\n",
    "\n",
    "#         val_miou = mean_iou(results=all_predictions_val,\n",
    "#                     gt_seg_maps=all_gt_val,\n",
    "#                     num_classes=2,\n",
    "#                     ignore_index=-1)\n",
    "\n",
    "#         test_losses = []\n",
    "        thresh = 0.5\n",
    "        all_predictions_test  = []\n",
    "        all_gt_test = []\n",
    "        model.eval()\n",
    "        for batch in test_loader:\n",
    "            img, plexus = batch  # load from batch\n",
    "            img = img.cuda().to(dtype=torch.bfloat16) / 255  # (bsz, 3, H, W)\n",
    "            plexus = plexus.cuda().long().squeeze(dim=1)  # (bsz, H, W)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                with torch.cuda.amp.autocast(dtype=torch.bfloat16):\n",
    "                    x = model.patch_embed(img)\n",
    "                    x = x + model.pos_embed[:, 1:, :]\n",
    "\n",
    "                    cls_token = model.cls_token + model.pos_embed[:, :1, :]\n",
    "                    cls_tokens = cls_token.expand(x.shape[0], -1, -1)\n",
    "                    x = torch.cat((cls_tokens, x), dim=1)\n",
    "\n",
    "                    # apply Transformer blocks\n",
    "                    for blk in model.blocks:\n",
    "                        x = blk(x)  # (bsz, L, 768)\n",
    "\n",
    "                    x = linear(x)  # (bsz, L, 512)\n",
    "                    logits = rearrange(x[:, 1:, :], 'b (h w) (c i j) -> b c (h i) (w j)', h=14, w=14, c=2, i=16,\n",
    "                                       j=16)  # (bsz, 2, H, W)\n",
    "                    probability = logits.softmax(dim=1)\n",
    "                    predictions = (probability[:,1,:, :] > thresh).long()\n",
    "#                     predictions  = logits.argmax(dim=1)  # (bza, H, W)\n",
    "            all_predictions_test.append(predictions.cpu())\n",
    "            all_gt_test.append(plexus.cpu())\n",
    "                    # logits = seg_head(features=x[:, 1:, :], HW_input=224, HW_target=224)  # (bsz, 2, H, W)\n",
    "\n",
    "#             loss = loss_function(logits, plexus)\n",
    "#             test_losses.append(loss.item())\n",
    "        all_predictions_test = torch.cat(all_predictions_test, dim=0).numpy()\n",
    "        all_gt_test = torch.cat(all_gt_test, dim=0).numpy()\n",
    "\n",
    "        test_miou = compute_iou(all_predictions_test, all_gt_test)\n",
    "\n",
    "#         test_miou = mean_iou(results=all_predictions_test,\n",
    "#                     gt_seg_maps=all_gt_test,\n",
    "#                     num_classes=2,\n",
    "#                     ignore_index=-1)\n",
    "\n",
    "        train_losses = torch.Tensor(train_losses).mean().item()\n",
    "#         val_losses = torch.Tensor(val_losses).mean().item()\n",
    "#         test_losses = torch.Tensor(test_losses).mean().item()\n",
    "        print(f'Epoch: {epoch}, Train Loss: {train_losses}, Val mIoU: {val_miou}, Test mIoU: {test_miou}, Base LR: {base_lr}, LR Backbone: {current_lr_backbone}, LR Head: {current_lr_head},')\n",
    "\n",
    "#         avg_val_miou = val_miou['IoU'].mean()\n",
    "\n",
    "        if val_miou > best_val_miou:\n",
    "            best_val_miou = val_miou\n",
    "            best_lr = base_lr\n",
    "#             best_model_state = copy.deepcopy(model.state_dict()) \n",
    "#             best_linear_layer = copy.deepcopy(linear.state_dict()) \n",
    "            print(f'Best Learning Rate: {best_lr}')\n",
    "            print(f'SAVING')\n",
    "            torch.save(obj={'backbone': model.state_dict(),\n",
    "                            'linear': linear.state_dict()},\n",
    "                       f=f'actual_plexus_saved_models/ViT_IN1k_plexus_{base_lr}.pt')\n",
    "            \n",
    "            d = {'Learning Rate': base_lr, 'Epoch': epoch, 'Train Loss': train_losses, 'Val mIoU': val_miou, \n",
    "                 'Test mIoU': test_miou}\n",
    "            model_info_df = pd.concat([model_info_df, pd.DataFrame([d])], ignore_index=True)\n",
    "            \n",
    "            num_down = 0\n",
    "        else:\n",
    "            num_down += 1\n",
    "\n",
    "        # write to logs\n",
    "        with open(f'ViT_IN1k_plexus_logs_{base_lr}.csv', 'a', errors=\"ignore\") as out_file:\n",
    "            csv_writer = csv.writer(out_file, delimiter=',', lineterminator='\\n')\n",
    "            csv_writer.writerow([epoch, train_losses, val_miou, test_miou, best_val_miou, current_lr_backbone, current_lr_head, base_lr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84514e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_miou_per_lr = model_info_df.groupby('Learning Rate')['Val mIoU'].transform('max')\n",
    "max_rows = model_info_df[model_info_df['Val mIoU'] == max_miou_per_lr]\n",
    "max_rows.to_csv(\"actual_plexus_saved_models/ViT_IN1k_plexus_logs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b017a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info_df.to_csv(\"actual_plexus_saved_models/ViT_IN1k_plexus_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11367772",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = get_model_info_df.iloc[get_model_info_df['Val mIoU'].idxmax()]\n",
    "best.to_csv(\"delete.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "db6f9915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base Learning Rate</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Val mIoU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.9200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.3540</td>\n",
       "      <td>0.8300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.8797</td>\n",
       "      <td>0.6789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.7900</td>\n",
       "      <td>0.6700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00020</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>0.5700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00050</td>\n",
       "      <td>0.7689</td>\n",
       "      <td>0.5679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.6780</td>\n",
       "      <td>0.6234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Base Learning Rate  Train Loss  Val mIoU\n",
       "0             0.00001      0.9990    0.9200\n",
       "1             0.00001      0.3540    0.8300\n",
       "2             0.00005      0.8797    0.6789\n",
       "3             0.00008      0.7900    0.6700\n",
       "4             0.00010      1.0000    0.4360\n",
       "5             0.00020      3.0000    0.5700\n",
       "6             0.00050      0.7689    0.5679\n",
       "7             0.00100      0.6780    0.6234"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_lr = [1e-5, 1e-5, 5e-5, 8e-5, 1e-4, 2e-4, 5e-4, 1e-3]\n",
    "train_loss = [0.999, 0.354, 0.8797, 0.79, 1, 3, 0.7689, 0.678]\n",
    "val_miou = [0.92, 0.83, 0.6789, 0.67, 0.436, 0.57, 0.5679, 0.6234]\n",
    "\n",
    "d = {'Base Learning Rate': base_lr, 'Train Loss': train_loss, 'Val mIoU': val_miou}\n",
    "\n",
    "get_model_info_df = pd.DataFrame(data=d)\n",
    "get_model_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "78278d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Base Learning Rate', 'Train Loss', 'Val mIoU', 'Test mIoU']\n",
    "model_info_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for i in range(4):\n",
    "    \n",
    "    d = {'Base Learning Rate': base_lr[i], \n",
    "             'Train Loss': train_loss[i], \n",
    "             'Val mIoU': val_miou[i]}\n",
    "    model_info_df = pd.concat([model_info_df, pd.DataFrame([d])], ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1fcfd6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base Learning Rate</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Val mIoU</th>\n",
       "      <th>Test mIoU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.9200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.3540</td>\n",
       "      <td>0.8300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.8797</td>\n",
       "      <td>0.6789</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.7900</td>\n",
       "      <td>0.6700</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Base Learning Rate  Train Loss  Val mIoU Test mIoU\n",
       "0             0.00001      0.9990    0.9200       NaN\n",
       "1             0.00001      0.3540    0.8300       NaN\n",
       "2             0.00005      0.8797    0.6789       NaN\n",
       "3             0.00008      0.7900    0.6700       NaN"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "65394726",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info_df.to_csv(\"delete.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c139d01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-05\n",
      "1e-05\n",
      "5e-05\n",
      "8e-05\n"
     ]
    }
   ],
   "source": [
    "for i in model_info_df['Base Learning Rate']:\n",
    "    print(i)\n",
    "    best = model_info_df['Val mIoU'].loc[i]\n",
    "    print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d1ca57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
