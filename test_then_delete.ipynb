{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baa49fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import transforms, utils\n",
    "from einops import rearrange\n",
    "import os\n",
    "from torchvision.transforms import (\n",
    "    RandomHorizontalFlip,\n",
    "    RandomRotation,\n",
    "    RandomVerticalFlip,\n",
    "    RandomApply,\n",
    "    InterpolationMode,\n",
    "    RandomCrop,\n",
    "    RandomResizedCrop,\n",
    "    CenterCrop\n",
    ")\n",
    "import math\n",
    "import csv\n",
    "#from histo_vit import vit_small\n",
    "import random\n",
    "from torchvision.transforms.functional import hflip\n",
    "from torchvision.transforms.functional import vflip\n",
    "#import segmenter\n",
    "import og_mae\n",
    "from youssef_data_loading import HirschImagesDataset\n",
    "from metrics import mean_iou\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4c4773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image_with_map(_img, _map):\n",
    "    side_outer = 512\n",
    "    angle = torch.randint(low=0, high=90, size=(1,)).item()\n",
    "    \n",
    "    aug1 = torch.nn.Sequential(RandomRotation((angle, angle)))\n",
    "    \n",
    "    side_inner = side_outer / (math.cos(math.radians(angle)) + math.sin(math.radians(angle)))\n",
    "    #print(f\"The new h and w are: {side_inner}\")\n",
    "    \n",
    "    state = torch.get_rng_state()\n",
    "    _img = aug1(_img)\n",
    "\n",
    "    torch.set_rng_state(state)\n",
    "    _map = aug1(_map)\n",
    "    \n",
    "    center_x = side_outer // 2\n",
    "    center_y = side_outer // 2\n",
    "\n",
    "    half_width = side_inner // 2\n",
    "    half_height = side_inner // 2 \n",
    "\n",
    "    start_x = round(center_x - half_width)\n",
    "    end_x = round(center_x + half_width)\n",
    "    start_y = round(center_y - half_height)\n",
    "    end_y = round(center_y + half_height)\n",
    "\n",
    "    _img = _img[:, start_y:end_y, start_x:end_x]\n",
    "    _map = _map[:, start_y:end_y, start_x:end_x]\n",
    "    \n",
    "    aug2 = torch.nn.Sequential(\n",
    "    RandomHorizontalFlip(p=0.5),\n",
    "    RandomVerticalFlip(p=0.5),\n",
    "    RandomResizedCrop(size=(224, 224), scale=(0.5, 2.0)))\n",
    "    \n",
    "    state = torch.get_rng_state()\n",
    "    _img = aug2(_img)\n",
    "\n",
    "    torch.set_rng_state(state)\n",
    "    _map = aug2(_map)\n",
    "    \n",
    "    \n",
    "    return _img, _map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e854289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(epoch, sched_config):\n",
    "    \"\"\"Decay the learning rate with half-cycle cosine after warmup\"\"\"\n",
    "    if epoch < sched_config['warmup_epochs']:\n",
    "        lr = sched_config['lr'] * epoch / sched_config['warmup_epochs']\n",
    "    else:\n",
    "        lr = sched_config['min_lr'] + (sched_config['lr'] - sched_config['min_lr']) * 0.5 * \\\n",
    "            (1. + math.cos(math.pi * (epoch - sched_config['warmup_epochs']) / (sched_config['epochs'] - sched_config['warmup_epochs'])))\n",
    "    return lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "087c2f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "        for param_group in optimizer.param_groups:\n",
    "            return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19a825fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(y_pred, y_true):\n",
    "    smooth = 0.0001\n",
    "    # ytrue, ypred is a flatten vector\n",
    "    y_pred = y_pred.flatten()\n",
    "    y_true = y_true.flatten()\n",
    "    current = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "    # compute mean iou\n",
    "    intersection = np.diag(current)\n",
    "    ground_truth_set = current.sum(axis=1)\n",
    "    predicted_set = current.sum(axis=0)\n",
    "    union = ground_truth_set + predicted_set - intersection\n",
    "    IoU = (intersection+smooth) / (union.astype(np.float32)+smooth)\n",
    "    return np.mean(IoU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ed887cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = ['S14-580.pt',\n",
    "              'S00-1910.pt',\n",
    "              'S02-410.pt',\n",
    "              'S02-484.pt',\n",
    "              'S03-2391.pt',\n",
    "              'S01-18.pt',\n",
    "              \"S03-3178 D2.pt\",\n",
    "              \"S03-3178 D3.pt\",\n",
    "              \"S03-3178 D4.pt\",\n",
    "              'S04-52.pt',\n",
    "              'S04-910.pt',\n",
    "              'S07-1808.pt',\n",
    "              'S08-2215.pt',\n",
    "              'S09-2723.pt',\n",
    "              'S04-1840.pt',\n",
    "              'S07-1465.pt',\n",
    "              'S14-1715.pt',\n",
    "              'S09-2909.pt',\n",
    "              'S14-3414.pt',\n",
    "              'S14-2038.pt',\n",
    "              'S15-1442.pt',\n",
    "              'S15-1518.pt',\n",
    "              'S16-567.pt',\n",
    "              \"S16-1197 B1.pt\",\n",
    "              'S11-1760.pt',\n",
    "              'S16-1467.pt',\n",
    "              \"S16-1197 B3.pt\",\n",
    "              \"S16-1197 B2.pt\",\n",
    "              'S97-2054.pt',\n",
    "              'S16-1415.pt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2205ad9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 1e-05\n",
      "Epoch: 0, Train Loss: 1.3387812376022339, Val mIoU: 0.30564502466967214, Test mIoU: 0.301461091322822, Base LR: 1e-05, LR Backbone: 0.0, LR Head: 0.0,\n",
      "Best Learning Rate: 1e-05\n",
      "SAVING\n",
      "Epoch: 1, Train Loss: 0.9210625290870667, Val mIoU: 0.4314647171498568, Test mIoU: 0.43889699930554027, Base LR: 1e-05, LR Backbone: 5.000000000000001e-07, LR Head: 5.000000000000001e-07,\n",
      "Best Learning Rate: 1e-05\n",
      "SAVING\n",
      "Epoch: 2, Train Loss: 0.3961718678474426, Val mIoU: 0.6617427998567613, Test mIoU: 0.695436437171063, Base LR: 1e-05, LR Backbone: 1.0000000000000002e-06, LR Head: 1.0000000000000002e-06,\n",
      "Best Learning Rate: 1e-05\n",
      "SAVING\n",
      "Epoch: 3, Train Loss: 0.17955273389816284, Val mIoU: 0.7566798197350719, Test mIoU: 0.8145553764689759, Base LR: 1e-05, LR Backbone: 1.5000000000000002e-06, LR Head: 1.5000000000000002e-06,\n",
      "Best Learning Rate: 1e-05\n",
      "SAVING\n",
      "Epoch: 4, Train Loss: 0.12006738036870956, Val mIoU: 0.74241715201476, Test mIoU: 0.794210325253226, Base LR: 1e-05, LR Backbone: 2.0000000000000003e-06, LR Head: 2.0000000000000003e-06,\n",
      "Epoch: 5, Train Loss: 0.0988789051771164, Val mIoU: 0.7695290132970953, Test mIoU: 0.831085684824638, Base LR: 1e-05, LR Backbone: 2.5e-06, LR Head: 2.5e-06,\n",
      "Best Learning Rate: 1e-05\n",
      "SAVING\n",
      "Epoch: 6, Train Loss: 0.08246679604053497, Val mIoU: 0.7950881325337634, Test mIoU: 0.8515027502008444, Base LR: 1e-05, LR Backbone: 2.4969550628247804e-06, LR Head: 2.4969550628247804e-06,\n",
      "Best Learning Rate: 1e-05\n",
      "SAVING\n",
      "Epoch: 7, Train Loss: 0.07101904600858688, Val mIoU: 0.7573131953074006, Test mIoU: 0.8024799321197149, Base LR: 1e-05, LR Backbone: 2.487835085926963e-06, LR Head: 2.487835085926963e-06,\n",
      "Epoch: 8, Train Loss: 0.0587778314948082, Val mIoU: 0.8297407363021722, Test mIoU: 0.8712791936402071, Base LR: 1e-05, LR Backbone: 2.4726845009172572e-06, LR Head: 2.4726845009172572e-06,\n",
      "Best Learning Rate: 1e-05\n",
      "SAVING\n",
      "Epoch: 9, Train Loss: 0.05315209925174713, Val mIoU: 0.8198549385247297, Test mIoU: 0.8614426666811217, Base LR: 1e-05, LR Backbone: 2.451577119922899e-06, LR Head: 2.451577119922899e-06,\n",
      "Epoch: 10, Train Loss: 0.049324218183755875, Val mIoU: 0.8440132164139006, Test mIoU: 0.8855930031973795, Base LR: 1e-05, LR Backbone: 2.4246157759823856e-06, LR Head: 2.4246157759823856e-06,\n",
      "Best Learning Rate: 1e-05\n",
      "SAVING\n",
      "Epoch: 11, Train Loss: 0.044456299394369125, Val mIoU: 0.8160646645564879, Test mIoU: 0.8540905213971927, Base LR: 1e-05, LR Backbone: 2.391931822053251e-06, LR Head: 2.391931822053251e-06,\n",
      "Epoch: 12, Train Loss: 0.04269653186202049, Val mIoU: 0.9119522943138185, Test mIoU: 0.9151497085163269, Base LR: 1e-05, LR Backbone: 2.353684491073659e-06, LR Head: 2.353684491073659e-06,\n",
      "Best Learning Rate: 1e-05\n",
      "SAVING\n",
      "Epoch: 13, Train Loss: 0.04086059704422951, Val mIoU: 0.8778071477089957, Test mIoU: 0.8899196248899129, Base LR: 1e-05, LR Backbone: 2.3100601201955324e-06, LR Head: 2.3100601201955324e-06,\n",
      "Epoch: 14, Train Loss: 0.04020043835043907, Val mIoU: 0.9213320357288872, Test mIoU: 0.9211051102771988, Base LR: 1e-05, LR Backbone: 2.2612712429686846e-06, LR Head: 2.2612712429686846e-06,\n",
      "Best Learning Rate: 1e-05\n",
      "SAVING\n",
      "Epoch: 15, Train Loss: 0.037150390446186066, Val mIoU: 0.9132039062209126, Test mIoU: 0.913995141028825, Base LR: 1e-05, LR Backbone: 2.2075555538987226e-06, LR Head: 2.2075555538987226e-06,\n",
      "Epoch: 16, Train Loss: 0.036595702171325684, Val mIoU: 0.8540142533919153, Test mIoU: 0.8828144345752585, Base LR: 1e-05, LR Backbone: 2.1491747504233142e-06, LR Head: 2.1491747504233142e-06,\n",
      "Epoch: 17, Train Loss: 0.03458593785762787, Val mIoU: 0.8461286428219353, Test mIoU: 0.8850277709028824, Base LR: 1e-05, LR Backbone: 2.086413257948573e-06, LR Head: 2.086413257948573e-06,\n",
      "Epoch: 18, Train Loss: 0.03623754903674126, Val mIoU: 0.9135204401088274, Test mIoU: 0.9154508643881163, Base LR: 1e-05, LR Backbone: 2.019576844157073e-06, LR Head: 2.019576844157073e-06,\n",
      "Epoch: 19, Train Loss: 0.03563928231596947, Val mIoU: 0.8448545046790367, Test mIoU: 0.8692099396025348, Base LR: 1e-05, LR Backbone: 1.9489911293384335e-06, LR Head: 1.9489911293384335e-06,\n",
      "Epoch: 20, Train Loss: 0.03374133259057999, Val mIoU: 0.838025495505541, Test mIoU: 0.865064263303861, Base LR: 1e-05, LR Backbone: 1.8750000000000003e-06, LR Head: 1.8750000000000003e-06,\n",
      "Epoch: 21, Train Loss: 0.03149756044149399, Val mIoU: 0.8398782968119676, Test mIoU: 0.8710152408545772, Base LR: 1e-05, LR Backbone: 1.797963933486347e-06, LR Head: 1.797963933486347e-06,\n",
      "Epoch: 22, Train Loss: 0.031080810353159904, Val mIoU: 0.8966687737947864, Test mIoU: 0.9090442214924317, Base LR: 1e-05, LR Backbone: 1.71825824176989e-06, LR Head: 1.71825824176989e-06,\n",
      "Epoch: 23, Train Loss: 0.03203222528100014, Val mIoU: 0.8859723297634596, Test mIoU: 0.8937193381240537, Base LR: 1e-05, LR Backbone: 1.6362712429686844e-06, LR Head: 1.6362712429686844e-06,\n",
      "Epoch: 24, Train Loss: 0.03045654296875, Val mIoU: 0.8429791762687533, Test mIoU: 0.8555460952491707, Base LR: 1e-05, LR Backbone: 1.5524023694995849e-06, LR Head: 1.5524023694995849e-06,\n",
      "Epoch: 25, Train Loss: 0.031088989228010178, Val mIoU: 0.8465863204526305, Test mIoU: 0.8709072437403859, Base LR: 1e-05, LR Backbone: 1.4670602220836634e-06, LR Head: 1.4670602220836634e-06,\n",
      "Epoch: 26, Train Loss: 0.02974572777748108, Val mIoU: 0.9197937463660054, Test mIoU: 0.9213873922953846, Base LR: 1e-05, LR Backbone: 1.380660579084567e-06, LR Head: 1.380660579084567e-06,\n",
      "Epoch: 27, Train Loss: 0.029441284015774727, Val mIoU: 0.8748371509700932, Test mIoU: 0.899113265318731, Base LR: 1e-05, LR Backbone: 1.2936243708781266e-06, LR Head: 1.2936243708781266e-06,\n",
      "Epoch: 28, Train Loss: 0.029090942814946175, Val mIoU: 0.8775536216911162, Test mIoU: 0.9004998972530385, Base LR: 1e-05, LR Backbone: 1.2063756291218743e-06, LR Head: 1.2063756291218743e-06,\n",
      "Epoch: 29, Train Loss: 0.02898608334362507, Val mIoU: 0.9135333105270103, Test mIoU: 0.9201057850073372, Base LR: 1e-05, LR Backbone: 1.1193394209154335e-06, LR Head: 1.1193394209154335e-06,\n",
      "Epoch: 30, Train Loss: 0.028325684368610382, Val mIoU: 0.9040347860249286, Test mIoU: 0.9137249793008744, Base LR: 1e-05, LR Backbone: 1.0329397779163373e-06, LR Head: 1.0329397779163373e-06,\n",
      "Epoch: 31, Train Loss: 0.027632812038064003, Val mIoU: 0.9443744912731601, Test mIoU: 0.9354998912063162, Base LR: 1e-05, LR Backbone: 9.475976305004153e-07, LR Head: 9.475976305004153e-07,\n",
      "Best Learning Rate: 1e-05\n",
      "SAVING\n",
      "Epoch: 32, Train Loss: 0.028205566108226776, Val mIoU: 0.9024445544029429, Test mIoU: 0.9167926328763303, Base LR: 1e-05, LR Backbone: 8.637287570313159e-07, LR Head: 8.637287570313159e-07,\n",
      "Epoch: 33, Train Loss: 0.02735559083521366, Val mIoU: 0.8986563597489203, Test mIoU: 0.9066118795401816, Base LR: 1e-05, LR Backbone: 7.8174175823011e-07, LR Head: 7.8174175823011e-07,\n",
      "Epoch: 34, Train Loss: 0.027045898139476776, Val mIoU: 0.9018965689571012, Test mIoU: 0.9142301030528609, Base LR: 1e-05, LR Backbone: 7.020360665136531e-07, LR Head: 7.020360665136531e-07,\n",
      "Epoch: 35, Train Loss: 0.02759350650012493, Val mIoU: 0.8832723227380397, Test mIoU: 0.8966254429975888, Base LR: 1e-05, LR Backbone: 6.250000000000004e-07, LR Head: 6.250000000000004e-07,\n",
      "Epoch: 36, Train Loss: 0.02674585022032261, Val mIoU: 0.8897184411104104, Test mIoU: 0.902292525786487, Base LR: 1e-05, LR Backbone: 5.510088706615667e-07, LR Head: 5.510088706615667e-07,\n",
      "Epoch: 37, Train Loss: 0.026305541396141052, Val mIoU: 0.875975674545403, Test mIoU: 0.8871641827791912, Base LR: 1e-05, LR Backbone: 4.804231558429272e-07, LR Head: 4.804231558429272e-07,\n",
      "Epoch: 38, Train Loss: 0.026625731959939003, Val mIoU: 0.8888183571106508, Test mIoU: 0.8980351955490513, Base LR: 1e-05, LR Backbone: 4.1358674205142726e-07, LR Head: 4.1358674205142726e-07,\n",
      "Epoch: 39, Train Loss: 0.02684680186212063, Val mIoU: 0.9045309754943571, Test mIoU: 0.9064410981186808, Base LR: 1e-05, LR Backbone: 3.50825249576686e-07, LR Head: 3.50825249576686e-07,\n",
      "Epoch: 40, Train Loss: 0.026427490636706352, Val mIoU: 0.9100851297016324, Test mIoU: 0.911658747659137, Base LR: 1e-05, LR Backbone: 2.9244444610127764e-07, LR Head: 2.9244444610127764e-07,\n",
      "Epoch: 41, Train Loss: 0.026158569380640984, Val mIoU: 0.8931711218367087, Test mIoU: 0.9037939317855763, Base LR: 1e-05, LR Backbone: 2.387287570313158e-07, LR Head: 2.387287570313158e-07,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42, Train Loss: 0.02575378492474556, Val mIoU: 0.9119548987056403, Test mIoU: 0.9174478727013072, Base LR: 1e-05, LR Backbone: 1.8993987980446756e-07, LR Head: 1.8993987980446756e-07,\n",
      "Epoch: 43, Train Loss: 0.02618139609694481, Val mIoU: 0.9157315987843333, Test mIoU: 0.9178230999836559, Base LR: 1e-05, LR Backbone: 1.4631550892634156e-07, LR Head: 1.4631550892634156e-07,\n",
      "Epoch: 44, Train Loss: 0.0254978034645319, Val mIoU: 0.8921197039938705, Test mIoU: 0.9050197390921542, Base LR: 1e-05, LR Backbone: 1.0806817794674906e-07, LR Head: 1.0806817794674906e-07,\n",
      "Epoch: 45, Train Loss: 0.025794921442866325, Val mIoU: 0.8936182484757297, Test mIoU: 0.9051217481531246, Base LR: 1e-05, LR Backbone: 7.53842240176146e-08, LR Head: 7.53842240176146e-08,\n",
      "Epoch: 46, Train Loss: 0.025075562298297882, Val mIoU: 0.8987590220410777, Test mIoU: 0.9079203996671663, Base LR: 1e-05, LR Backbone: 4.842288007710166e-08, LR Head: 4.842288007710166e-08,\n",
      "Epoch: 47, Train Loss: 0.02571398951113224, Val mIoU: 0.8950301388179718, Test mIoU: 0.9049666154882836, Base LR: 1e-05, LR Backbone: 2.731549908274289e-08, LR Head: 2.731549908274289e-08,\n",
      "Epoch: 48, Train Loss: 0.02579992637038231, Val mIoU: 0.8960526856634703, Test mIoU: 0.9059131768076247, Base LR: 1e-05, LR Backbone: 1.2164914073037187e-08, LR Head: 1.2164914073037187e-08,\n",
      "Epoch: 49, Train Loss: 0.02612036094069481, Val mIoU: 0.8964416280335259, Test mIoU: 0.9058928633173242, Base LR: 1e-05, LR Backbone: 3.0449371752197533e-09, LR Head: 3.0449371752197533e-09,\n",
      "Learning Rate: 5e-05\n",
      "Epoch: 0, Train Loss: 1.2572187185287476, Val mIoU: 0.2963900387917485, Test mIoU: 0.2920458373024862, Base LR: 5e-05, LR Backbone: 0.0, LR Head: 0.0,\n",
      "Best Learning Rate: 5e-05\n",
      "SAVING\n",
      "Epoch: 1, Train Loss: 0.4139414131641388, Val mIoU: 0.7507900870398803, Test mIoU: 0.7640027588230074, Base LR: 5e-05, LR Backbone: 2.5e-06, LR Head: 2.5e-06,\n",
      "Best Learning Rate: 5e-05\n",
      "SAVING\n",
      "Epoch: 2, Train Loss: 0.11809472739696503, Val mIoU: 0.7852964243733327, Test mIoU: 0.805415491952501, Base LR: 5e-05, LR Backbone: 5e-06, LR Head: 5e-06,\n",
      "Best Learning Rate: 5e-05\n",
      "SAVING\n",
      "Epoch: 3, Train Loss: 0.0837709978222847, Val mIoU: 0.8018066255931723, Test mIoU: 0.8402622322205912, Base LR: 5e-05, LR Backbone: 7.500000000000001e-06, LR Head: 7.500000000000001e-06,\n",
      "Best Learning Rate: 5e-05\n",
      "SAVING\n",
      "Epoch: 4, Train Loss: 0.057502441108226776, Val mIoU: 0.7662170261626251, Test mIoU: 0.8310202565733402, Base LR: 5e-05, LR Backbone: 1e-05, LR Head: 1e-05,\n",
      "Epoch: 5, Train Loss: 0.04810473695397377, Val mIoU: 0.8907154413430736, Test mIoU: 0.9210458084799552, Base LR: 5e-05, LR Backbone: 1.25e-05, LR Head: 1.25e-05,\n",
      "Best Learning Rate: 5e-05\n",
      "SAVING\n",
      "Epoch: 6, Train Loss: 0.045915406197309494, Val mIoU: 0.8841293892899669, Test mIoU: 0.9106280355860685, Base LR: 5e-05, LR Backbone: 1.2484775314123903e-05, LR Head: 1.2484775314123903e-05,\n",
      "Epoch: 7, Train Loss: 0.03694189339876175, Val mIoU: 0.8752367199546003, Test mIoU: 0.907809330090176, Base LR: 5e-05, LR Backbone: 1.2439175429634816e-05, LR Head: 1.2439175429634816e-05,\n",
      "Epoch: 8, Train Loss: 0.03518591448664665, Val mIoU: 0.9039928047106369, Test mIoU: 0.9235990926231488, Base LR: 5e-05, LR Backbone: 1.2363422504586286e-05, LR Head: 1.2363422504586286e-05,\n",
      "Best Learning Rate: 5e-05\n",
      "SAVING\n",
      "Epoch: 9, Train Loss: 0.034171998500823975, Val mIoU: 0.9366171476804674, Test mIoU: 0.93397664708888, Base LR: 5e-05, LR Backbone: 1.2257885599614494e-05, LR Head: 1.2257885599614494e-05,\n",
      "Best Learning Rate: 5e-05\n",
      "SAVING\n",
      "Epoch: 10, Train Loss: 0.030885253101587296, Val mIoU: 0.8372279608557782, Test mIoU: 0.8705736886854714, Base LR: 5e-05, LR Backbone: 1.2123078879911928e-05, LR Head: 1.2123078879911928e-05,\n",
      "Epoch: 11, Train Loss: 0.031846191734075546, Val mIoU: 0.8442031589344595, Test mIoU: 0.8998185436772769, Base LR: 5e-05, LR Backbone: 1.1959659110266256e-05, LR Head: 1.1959659110266256e-05,\n",
      "Epoch: 12, Train Loss: 0.0282131340354681, Val mIoU: 0.9267420117832701, Test mIoU: 0.9303661107397649, Base LR: 5e-05, LR Backbone: 1.1768422455368295e-05, LR Head: 1.1768422455368295e-05,\n",
      "Epoch: 13, Train Loss: 0.03091992251574993, Val mIoU: 0.940229745576518, Test mIoU: 0.9410227466893433, Base LR: 5e-05, LR Backbone: 1.1550300600977662e-05, LR Head: 1.1550300600977662e-05,\n",
      "Best Learning Rate: 5e-05\n",
      "SAVING\n",
      "Epoch: 14, Train Loss: 0.03141088783740997, Val mIoU: 0.8275992901840721, Test mIoU: 0.8423313462147779, Base LR: 5e-05, LR Backbone: 1.1306356214843423e-05, LR Head: 1.1306356214843423e-05,\n",
      "Epoch: 15, Train Loss: 0.027466552332043648, Val mIoU: 0.9401917472452734, Test mIoU: 0.933090233287913, Base LR: 5e-05, LR Backbone: 1.1037777769493613e-05, LR Head: 1.1037777769493613e-05,\n",
      "Epoch: 16, Train Loss: 0.026816895231604576, Val mIoU: 0.9542822362241097, Test mIoU: 0.9412634536919263, Base LR: 5e-05, LR Backbone: 1.0745873752116569e-05, LR Head: 1.0745873752116569e-05,\n",
      "Best Learning Rate: 5e-05\n",
      "SAVING\n",
      "Epoch: 17, Train Loss: 0.024786315858364105, Val mIoU: 0.9125716405585786, Test mIoU: 0.9266212329933342, Base LR: 5e-05, LR Backbone: 1.0432066289742864e-05, LR Head: 1.0432066289742864e-05,\n",
      "Epoch: 18, Train Loss: 0.0248104240745306, Val mIoU: 0.7792799592559632, Test mIoU: 0.8098863814258823, Base LR: 5e-05, LR Backbone: 1.0097884220785363e-05, LR Head: 1.0097884220785363e-05,\n",
      "Epoch: 19, Train Loss: 0.025159545242786407, Val mIoU: 0.8925057810261187, Test mIoU: 0.9118030348928943, Base LR: 5e-05, LR Backbone: 9.744955646692168e-06, LR Head: 9.744955646692168e-06,\n",
      "Epoch: 20, Train Loss: 0.0251774899661541, Val mIoU: 0.8647737072210304, Test mIoU: 0.9056525371226514, Base LR: 5e-05, LR Backbone: 9.375000000000001e-06, LR Head: 9.375000000000001e-06,\n",
      "Epoch: 21, Train Loss: 0.02334277331829071, Val mIoU: 0.9457277141157086, Test mIoU: 0.9405551270375925, Base LR: 5e-05, LR Backbone: 8.989819667431734e-06, LR Head: 8.989819667431734e-06,\n",
      "Epoch: 22, Train Loss: 0.02266870066523552, Val mIoU: 0.9260851039882132, Test mIoU: 0.9319074629128203, Base LR: 5e-05, LR Backbone: 8.59129120884945e-06, LR Head: 8.59129120884945e-06,\n",
      "Epoch: 23, Train Loss: 0.02258862368762493, Val mIoU: 0.9560332990192183, Test mIoU: 0.9425034094488314, Base LR: 5e-05, LR Backbone: 8.181356214843423e-06, LR Head: 8.181356214843423e-06,\n",
      "Best Learning Rate: 5e-05\n",
      "SAVING\n",
      "Epoch: 24, Train Loss: 0.024821044877171516, Val mIoU: 0.9413108116861542, Test mIoU: 0.9351082794323733, Base LR: 5e-05, LR Backbone: 7.762011847497924e-06, LR Head: 7.762011847497924e-06,\n",
      "Epoch: 25, Train Loss: 0.02229028381407261, Val mIoU: 0.9184114253025715, Test mIoU: 0.9265041683823976, Base LR: 5e-05, LR Backbone: 7.3353011104183164e-06, LR Head: 7.3353011104183164e-06,\n",
      "Epoch: 26, Train Loss: 0.020561279729008675, Val mIoU: 0.9307225460419772, Test mIoU: 0.9251717453876328, Base LR: 5e-05, LR Backbone: 6.903302895422835e-06, LR Head: 6.903302895422835e-06,\n",
      "Epoch: 27, Train Loss: 0.020722046494483948, Val mIoU: 0.9517186547765902, Test mIoU: 0.9344404618801228, Base LR: 5e-05, LR Backbone: 6.468121854390633e-06, LR Head: 6.468121854390633e-06,\n",
      "Epoch: 28, Train Loss: 0.021933715790510178, Val mIoU: 0.9403726474185921, Test mIoU: 0.9386110013914006, Base LR: 5e-05, LR Backbone: 6.031878145609371e-06, LR Head: 6.031878145609371e-06,\n",
      "Epoch: 29, Train Loss: 0.019853638485074043, Val mIoU: 0.9281925261903197, Test mIoU: 0.9244249225649991, Base LR: 5e-05, LR Backbone: 5.596697104577167e-06, LR Head: 5.596697104577167e-06,\n",
      "Epoch: 30, Train Loss: 0.019087646156549454, Val mIoU: 0.9279455595215675, Test mIoU: 0.9277399310877956, Base LR: 5e-05, LR Backbone: 5.164698889581686e-06, LR Head: 5.164698889581686e-06,\n",
      "Epoch: 31, Train Loss: 0.01964758336544037, Val mIoU: 0.9275082160656702, Test mIoU: 0.9248139169257755, Base LR: 5e-05, LR Backbone: 4.737988152502077e-06, LR Head: 4.737988152502077e-06,\n",
      "Epoch: 32, Train Loss: 0.01880224607884884, Val mIoU: 0.9589688192918491, Test mIoU: 0.9437057894451348, Base LR: 5e-05, LR Backbone: 4.3186437851565795e-06, LR Head: 4.3186437851565795e-06,\n",
      "Best Learning Rate: 5e-05\n",
      "SAVING\n",
      "Epoch: 33, Train Loss: 0.01894085668027401, Val mIoU: 0.9311829129454376, Test mIoU: 0.9206934062633731, Base LR: 5e-05, LR Backbone: 3.90870879115055e-06, LR Head: 3.90870879115055e-06,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34, Train Loss: 0.018086913973093033, Val mIoU: 0.9549533728481908, Test mIoU: 0.9372597458214944, Base LR: 5e-05, LR Backbone: 3.5101803325682656e-06, LR Head: 3.5101803325682656e-06,\n",
      "Epoch: 35, Train Loss: 0.01825866661965847, Val mIoU: 0.9320486907489074, Test mIoU: 0.9238959414950756, Base LR: 5e-05, LR Backbone: 3.1250000000000014e-06, LR Head: 3.1250000000000014e-06,\n",
      "Epoch: 36, Train Loss: 0.018405944108963013, Val mIoU: 0.9508515989073599, Test mIoU: 0.9391048907308406, Base LR: 5e-05, LR Backbone: 2.7550443533078335e-06, LR Head: 2.7550443533078335e-06,\n",
      "Epoch: 37, Train Loss: 0.018537597730755806, Val mIoU: 0.9480627839157014, Test mIoU: 0.9356043096801108, Base LR: 5e-05, LR Backbone: 2.4021157792146356e-06, LR Head: 2.4021157792146356e-06,\n",
      "Epoch: 38, Train Loss: 0.018398255109786987, Val mIoU: 0.9545886434994261, Test mIoU: 0.9387865999002885, Base LR: 5e-05, LR Backbone: 2.067933710257136e-06, LR Head: 2.067933710257136e-06,\n",
      "Epoch: 39, Train Loss: 0.01799572817981243, Val mIoU: 0.9639126559625515, Test mIoU: 0.947081222169309, Base LR: 5e-05, LR Backbone: 1.75412624788343e-06, LR Head: 1.75412624788343e-06,\n",
      "Best Learning Rate: 5e-05\n",
      "SAVING\n",
      "Epoch: 40, Train Loss: 0.01728729158639908, Val mIoU: 0.9630154924816694, Test mIoU: 0.943454825007821, Base LR: 5e-05, LR Backbone: 1.4622222305063882e-06, LR Head: 1.4622222305063882e-06,\n",
      "Epoch: 41, Train Loss: 0.017015930265188217, Val mIoU: 0.9601980101375951, Test mIoU: 0.9400562196246824, Base LR: 5e-05, LR Backbone: 1.1936437851565791e-06, LR Head: 1.1936437851565791e-06,\n",
      "Epoch: 42, Train Loss: 0.017354004085063934, Val mIoU: 0.9592374188089245, Test mIoU: 0.9406993061125702, Base LR: 5e-05, LR Backbone: 9.496993990223378e-07, LR Head: 9.496993990223378e-07,\n",
      "Epoch: 43, Train Loss: 0.01684759557247162, Val mIoU: 0.9541566805503565, Test mIoU: 0.9354071636796785, Base LR: 5e-05, LR Backbone: 7.315775446317077e-07, LR Head: 7.315775446317077e-07,\n",
      "Epoch: 44, Train Loss: 0.017042847350239754, Val mIoU: 0.9503400261418022, Test mIoU: 0.9342301947757106, Base LR: 5e-05, LR Backbone: 5.403408897337453e-07, LR Head: 5.403408897337453e-07,\n",
      "Epoch: 45, Train Loss: 0.01688476651906967, Val mIoU: 0.9492853923971458, Test mIoU: 0.9317515831561065, Base LR: 5e-05, LR Backbone: 3.7692112008807306e-07, LR Head: 3.7692112008807306e-07,\n",
      "Epoch: 46, Train Loss: 0.01661975122988224, Val mIoU: 0.9535657343577681, Test mIoU: 0.9360367439943795, Base LR: 5e-05, LR Backbone: 2.421144003855083e-07, LR Head: 2.421144003855083e-07,\n",
      "Epoch: 47, Train Loss: 0.017168700695037842, Val mIoU: 0.9538411840956293, Test mIoU: 0.9360910587637399, Base LR: 5e-05, LR Backbone: 1.3657749541371446e-07, LR Head: 1.3657749541371446e-07,\n",
      "Epoch: 48, Train Loss: 0.01661096140742302, Val mIoU: 0.9541394238295346, Test mIoU: 0.9360505893729499, Base LR: 5e-05, LR Backbone: 6.082457036518594e-08, LR Head: 6.082457036518594e-08,\n",
      "Epoch: 49, Train Loss: 0.016645384952425957, Val mIoU: 0.9538771604802947, Test mIoU: 0.9357253984490668, Base LR: 5e-05, LR Backbone: 1.5224685876098765e-08, LR Head: 1.5224685876098765e-08,\n",
      "Learning Rate: 8e-05\n",
      "Epoch: 0, Train Loss: 1.3128437995910645, Val mIoU: 0.29259661758764227, Test mIoU: 0.2886700977285376, Base LR: 8e-05, LR Backbone: 0.0, LR Head: 0.0,\n",
      "Best Learning Rate: 8e-05\n",
      "SAVING\n",
      "Epoch: 1, Train Loss: 0.3234550654888153, Val mIoU: 0.7469853805483728, Test mIoU: 0.7614451501378865, Base LR: 8e-05, LR Backbone: 4.000000000000001e-06, LR Head: 4.000000000000001e-06,\n",
      "Best Learning Rate: 8e-05\n",
      "SAVING\n",
      "Epoch: 2, Train Loss: 0.09652490168809891, Val mIoU: 0.8356989383498536, Test mIoU: 0.8555841944422902, Base LR: 8e-05, LR Backbone: 8.000000000000001e-06, LR Head: 8.000000000000001e-06,\n",
      "Best Learning Rate: 8e-05\n",
      "SAVING\n",
      "Epoch: 3, Train Loss: 0.06542431563138962, Val mIoU: 0.873593662452754, Test mIoU: 0.9037819019141595, Base LR: 8e-05, LR Backbone: 1.2000000000000002e-05, LR Head: 1.2000000000000002e-05,\n",
      "Best Learning Rate: 8e-05\n",
      "SAVING\n",
      "Epoch: 4, Train Loss: 0.04981445148587227, Val mIoU: 0.7789621645900422, Test mIoU: 0.8333346890230844, Base LR: 8e-05, LR Backbone: 1.6000000000000003e-05, LR Head: 1.6000000000000003e-05,\n",
      "Epoch: 5, Train Loss: 0.04365624859929085, Val mIoU: 0.9420433895667379, Test mIoU: 0.9371770502739938, Base LR: 8e-05, LR Backbone: 2e-05, LR Head: 2e-05,\n",
      "Best Learning Rate: 8e-05\n",
      "SAVING\n",
      "Epoch: 6, Train Loss: 0.04128344729542732, Val mIoU: 0.879612109086054, Test mIoU: 0.9200265722692031, Base LR: 8e-05, LR Backbone: 1.9975640502598243e-05, LR Head: 1.9975640502598243e-05,\n",
      "Epoch: 7, Train Loss: 0.03406384214758873, Val mIoU: 0.8323090697338864, Test mIoU: 0.8683739299815629, Base LR: 8e-05, LR Backbone: 1.9902680687415704e-05, LR Head: 1.9902680687415704e-05,\n",
      "Epoch: 8, Train Loss: 0.032191041857004166, Val mIoU: 0.9353498180812136, Test mIoU: 0.9305879244211822, Base LR: 8e-05, LR Backbone: 1.9781476007338058e-05, LR Head: 1.9781476007338058e-05,\n",
      "Epoch: 9, Train Loss: 0.032277341932058334, Val mIoU: 0.8940543444790716, Test mIoU: 0.9117110904196932, Base LR: 8e-05, LR Backbone: 1.961261695938319e-05, LR Head: 1.961261695938319e-05,\n",
      "Epoch: 10, Train Loss: 0.028357909992337227, Val mIoU: 0.9438663483128684, Test mIoU: 0.9335168817231017, Base LR: 8e-05, LR Backbone: 1.9396926207859085e-05, LR Head: 1.9396926207859085e-05,\n",
      "Best Learning Rate: 8e-05\n",
      "SAVING\n",
      "Epoch: 11, Train Loss: 0.027858886867761612, Val mIoU: 0.8800217246819202, Test mIoU: 0.9025395720214358, Base LR: 8e-05, LR Backbone: 1.913545457642601e-05, LR Head: 1.913545457642601e-05,\n",
      "Epoch: 12, Train Loss: 0.028599608689546585, Val mIoU: 0.917154607332054, Test mIoU: 0.9311826239421452, Base LR: 8e-05, LR Backbone: 1.8829475928589272e-05, LR Head: 1.8829475928589272e-05,\n",
      "Epoch: 13, Train Loss: 0.02860998548567295, Val mIoU: 0.9372920272780461, Test mIoU: 0.9381384184202777, Base LR: 8e-05, LR Backbone: 1.848048096156426e-05, LR Head: 1.848048096156426e-05,\n",
      "Epoch: 14, Train Loss: 0.02769140712916851, Val mIoU: 0.8806576934680876, Test mIoU: 0.915088138447884, Base LR: 8e-05, LR Backbone: 1.8090169943749477e-05, LR Head: 1.8090169943749477e-05,\n",
      "Epoch: 15, Train Loss: 0.028465576469898224, Val mIoU: 0.7871844600616695, Test mIoU: 0.8253866657208734, Base LR: 8e-05, LR Backbone: 1.766044443118978e-05, LR Head: 1.766044443118978e-05,\n",
      "Epoch: 16, Train Loss: 0.026111816987395287, Val mIoU: 0.9470741352130897, Test mIoU: 0.9364386097530508, Base LR: 8e-05, LR Backbone: 1.7193398003386514e-05, LR Head: 1.7193398003386514e-05,\n",
      "Best Learning Rate: 8e-05\n",
      "SAVING\n",
      "Epoch: 17, Train Loss: 0.023847777396440506, Val mIoU: 0.9557124019868595, Test mIoU: 0.9411088572673518, Base LR: 8e-05, LR Backbone: 1.6691306063588583e-05, LR Head: 1.6691306063588583e-05,\n",
      "Best Learning Rate: 8e-05\n",
      "SAVING\n",
      "Epoch: 18, Train Loss: 0.022618653252720833, Val mIoU: 0.9255452106546417, Test mIoU: 0.9335781532693714, Base LR: 8e-05, LR Backbone: 1.6156614753256583e-05, LR Head: 1.6156614753256583e-05,\n",
      "Epoch: 19, Train Loss: 0.021927978843450546, Val mIoU: 0.8927869192358889, Test mIoU: 0.9088397351247801, Base LR: 8e-05, LR Backbone: 1.5591929034707468e-05, LR Head: 1.5591929034707468e-05,\n",
      "Epoch: 20, Train Loss: 0.02452661097049713, Val mIoU: 0.8216937890548959, Test mIoU: 0.868042713526376, Base LR: 8e-05, LR Backbone: 1.5000000000000002e-05, LR Head: 1.5000000000000002e-05,\n",
      "Epoch: 21, Train Loss: 0.024073487147688866, Val mIoU: 0.9325658881587329, Test mIoU: 0.9381475096887645, Base LR: 8e-05, LR Backbone: 1.4383711467890776e-05, LR Head: 1.4383711467890776e-05,\n",
      "Epoch: 22, Train Loss: 0.022551147267222404, Val mIoU: 0.9163945283014131, Test mIoU: 0.9198864403729438, Base LR: 8e-05, LR Backbone: 1.374606593415912e-05, LR Head: 1.374606593415912e-05,\n",
      "Epoch: 23, Train Loss: 0.02207604981958866, Val mIoU: 0.9604696577448486, Test mIoU: 0.9443255231854737, Base LR: 8e-05, LR Backbone: 1.3090169943749475e-05, LR Head: 1.3090169943749475e-05,\n",
      "Best Learning Rate: 8e-05\n",
      "SAVING\n",
      "Epoch: 24, Train Loss: 0.020408812910318375, Val mIoU: 0.9454654709471102, Test mIoU: 0.9268962742232089, Base LR: 8e-05, LR Backbone: 1.2419218955996679e-05, LR Head: 1.2419218955996679e-05,\n",
      "Epoch: 25, Train Loss: 0.019715698435902596, Val mIoU: 0.9460792082606873, Test mIoU: 0.928866553044922, Base LR: 8e-05, LR Backbone: 1.1736481776669307e-05, LR Head: 1.1736481776669307e-05,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, Train Loss: 0.01922924816608429, Val mIoU: 0.9275136888205462, Test mIoU: 0.9307720820129783, Base LR: 8e-05, LR Backbone: 1.1045284632676535e-05, LR Head: 1.1045284632676535e-05,\n",
      "Epoch: 27, Train Loss: 0.01900048740208149, Val mIoU: 0.9297543144182251, Test mIoU: 0.9217649115212605, Base LR: 8e-05, LR Backbone: 1.0348994967025012e-05, LR Head: 1.0348994967025012e-05,\n",
      "Epoch: 28, Train Loss: 0.019061706960201263, Val mIoU: 0.960118504190643, Test mIoU: 0.9439320287103441, Base LR: 8e-05, LR Backbone: 9.651005032974994e-06, LR Head: 9.651005032974994e-06,\n",
      "Epoch: 29, Train Loss: 0.018993042409420013, Val mIoU: 0.9459503165195875, Test mIoU: 0.936388856462544, Base LR: 8e-05, LR Backbone: 8.954715367323468e-06, LR Head: 8.954715367323468e-06,\n",
      "Epoch: 30, Train Loss: 0.01815466396510601, Val mIoU: 0.9369997853421208, Test mIoU: 0.9304376234771267, Base LR: 8e-05, LR Backbone: 8.263518223330698e-06, LR Head: 8.263518223330698e-06,\n",
      "Epoch: 31, Train Loss: 0.01811205968260765, Val mIoU: 0.9387703117354023, Test mIoU: 0.9346309851302423, Base LR: 8e-05, LR Backbone: 7.580781044003323e-06, LR Head: 7.580781044003323e-06,\n",
      "Epoch: 32, Train Loss: 0.01852148398756981, Val mIoU: 0.9417977107006128, Test mIoU: 0.9376714116184239, Base LR: 8e-05, LR Backbone: 6.909830056250527e-06, LR Head: 6.909830056250527e-06,\n",
      "Epoch: 33, Train Loss: 0.018025267869234085, Val mIoU: 0.9626970452913797, Test mIoU: 0.9476255490673662, Base LR: 8e-05, LR Backbone: 6.25393406584088e-06, LR Head: 6.25393406584088e-06,\n",
      "Best Learning Rate: 8e-05\n",
      "SAVING\n",
      "Epoch: 34, Train Loss: 0.01734606921672821, Val mIoU: 0.9445562195276258, Test mIoU: 0.9338012799087424, Base LR: 8e-05, LR Backbone: 5.616288532109225e-06, LR Head: 5.616288532109225e-06,\n",
      "Epoch: 35, Train Loss: 0.01717272959649563, Val mIoU: 0.955667999939128, Test mIoU: 0.9436169884089849, Base LR: 8e-05, LR Backbone: 5.000000000000003e-06, LR Head: 5.000000000000003e-06,\n",
      "Epoch: 36, Train Loss: 0.016947265714406967, Val mIoU: 0.9577757965881594, Test mIoU: 0.9408475164335436, Base LR: 8e-05, LR Backbone: 4.408070965292534e-06, LR Head: 4.408070965292534e-06,\n",
      "Epoch: 37, Train Loss: 0.016477782279253006, Val mIoU: 0.9597928607109083, Test mIoU: 0.9484037335342472, Base LR: 8e-05, LR Backbone: 3.8433852467434175e-06, LR Head: 3.8433852467434175e-06,\n",
      "Epoch: 38, Train Loss: 0.016779663041234016, Val mIoU: 0.9496920027958826, Test mIoU: 0.9407513146644981, Base LR: 8e-05, LR Backbone: 3.308693936411418e-06, LR Head: 3.308693936411418e-06,\n",
      "Epoch: 39, Train Loss: 0.016245849430561066, Val mIoU: 0.9516299947308579, Test mIoU: 0.9407343232133878, Base LR: 8e-05, LR Backbone: 2.806601996613488e-06, LR Head: 2.806601996613488e-06,\n",
      "Epoch: 40, Train Loss: 0.01622289977967739, Val mIoU: 0.9429725037427588, Test mIoU: 0.9338328512007108, Base LR: 8e-05, LR Backbone: 2.339555568810221e-06, LR Head: 2.339555568810221e-06,\n",
      "Epoch: 41, Train Loss: 0.01612841710448265, Val mIoU: 0.9499808739783696, Test mIoU: 0.9371640358734885, Base LR: 8e-05, LR Backbone: 1.9098300562505266e-06, LR Head: 1.9098300562505266e-06,\n",
      "Epoch: 42, Train Loss: 0.016253052279353142, Val mIoU: 0.9638531177089005, Test mIoU: 0.9487198464518394, Base LR: 8e-05, LR Backbone: 1.5195190384357405e-06, LR Head: 1.5195190384357405e-06,\n",
      "Best Learning Rate: 8e-05\n",
      "SAVING\n",
      "Epoch: 43, Train Loss: 0.01591479405760765, Val mIoU: 0.959504322503213, Test mIoU: 0.9422882438223059, Base LR: 8e-05, LR Backbone: 1.1705240714107324e-06, LR Head: 1.1705240714107324e-06,\n",
      "Epoch: 44, Train Loss: 0.01549206580966711, Val mIoU: 0.956828294592011, Test mIoU: 0.9411330545644596, Base LR: 8e-05, LR Backbone: 8.645454235739925e-07, LR Head: 8.645454235739925e-07,\n",
      "Epoch: 45, Train Loss: 0.01534594688564539, Val mIoU: 0.9565554983844944, Test mIoU: 0.9411460244864979, Base LR: 8e-05, LR Backbone: 6.030737921409169e-07, LR Head: 6.030737921409169e-07,\n",
      "Epoch: 46, Train Loss: 0.01556396484375, Val mIoU: 0.9586430759257318, Test mIoU: 0.9422117474059992, Base LR: 8e-05, LR Backbone: 3.873830406168133e-07, LR Head: 3.873830406168133e-07,\n",
      "Epoch: 47, Train Loss: 0.015311523340642452, Val mIoU: 0.9582928599084339, Test mIoU: 0.9418460968763276, Base LR: 8e-05, LR Backbone: 2.1852399266194312e-07, LR Head: 2.1852399266194312e-07,\n",
      "Epoch: 48, Train Loss: 0.01562628149986267, Val mIoU: 0.9576910110613588, Test mIoU: 0.9409319297250462, Base LR: 8e-05, LR Backbone: 9.73193125842975e-08, LR Head: 9.73193125842975e-08,\n",
      "Epoch: 49, Train Loss: 0.015209656208753586, Val mIoU: 0.9582226770160331, Test mIoU: 0.9411681834263611, Base LR: 8e-05, LR Backbone: 2.4359497401758026e-08, LR Head: 2.4359497401758026e-08,\n",
      "Learning Rate: 0.0001\n",
      "Epoch: 0, Train Loss: 1.2250312566757202, Val mIoU: 0.3051239542627824, Test mIoU: 0.30175607240507063, Base LR: 0.0001, LR Backbone: 0.0, LR Head: 0.0,\n",
      "Best Learning Rate: 0.0001\n",
      "SAVING\n",
      "Epoch: 1, Train Loss: 0.2987402379512787, Val mIoU: 0.7591303529408899, Test mIoU: 0.7983825787524033, Base LR: 0.0001, LR Backbone: 5e-06, LR Head: 5e-06,\n",
      "Best Learning Rate: 0.0001\n",
      "SAVING\n",
      "Epoch: 2, Train Loss: 0.08206640928983688, Val mIoU: 0.800755171657582, Test mIoU: 0.8598879902778993, Base LR: 0.0001, LR Backbone: 1e-05, LR Head: 1e-05,\n",
      "Best Learning Rate: 0.0001\n",
      "SAVING\n",
      "Epoch: 3, Train Loss: 0.057976074516773224, Val mIoU: 0.8392662219573184, Test mIoU: 0.8920217812174833, Base LR: 0.0001, LR Backbone: 1.5000000000000002e-05, LR Head: 1.5000000000000002e-05,\n",
      "Best Learning Rate: 0.0001\n",
      "SAVING\n",
      "Epoch: 4, Train Loss: 0.04683007672429085, Val mIoU: 0.8157570710556517, Test mIoU: 0.8644348254587719, Base LR: 0.0001, LR Backbone: 2e-05, LR Head: 2e-05,\n",
      "Epoch: 5, Train Loss: 0.04432617127895355, Val mIoU: 0.8436059137387045, Test mIoU: 0.8931768464625713, Base LR: 0.0001, LR Backbone: 2.5e-05, LR Head: 2.5e-05,\n",
      "Best Learning Rate: 0.0001\n",
      "SAVING\n",
      "Epoch: 6, Train Loss: 0.03888915851712227, Val mIoU: 0.8801808380434681, Test mIoU: 0.9098599472284163, Base LR: 0.0001, LR Backbone: 2.4969550628247805e-05, LR Head: 2.4969550628247805e-05,\n",
      "Best Learning Rate: 0.0001\n",
      "SAVING\n",
      "Epoch: 7, Train Loss: 0.03649060055613518, Val mIoU: 0.7693597712016003, Test mIoU: 0.8365152092868025, Base LR: 0.0001, LR Backbone: 2.487835085926963e-05, LR Head: 2.487835085926963e-05,\n",
      "Epoch: 8, Train Loss: 0.034220702946186066, Val mIoU: 0.8374668274995238, Test mIoU: 0.8993157032591406, Base LR: 0.0001, LR Backbone: 2.4726845009172572e-05, LR Head: 2.4726845009172572e-05,\n",
      "Epoch: 9, Train Loss: 0.02982177771627903, Val mIoU: 0.8828591626318484, Test mIoU: 0.9192675453457688, Base LR: 0.0001, LR Backbone: 2.4515771199228987e-05, LR Head: 2.4515771199228987e-05,\n",
      "Best Learning Rate: 0.0001\n",
      "SAVING\n",
      "Epoch: 10, Train Loss: 0.031672120094299316, Val mIoU: 0.7447882495836812, Test mIoU: 0.7809559989226458, Base LR: 0.0001, LR Backbone: 2.4246157759823855e-05, LR Head: 2.4246157759823855e-05,\n",
      "Epoch: 11, Train Loss: 0.028855713084340096, Val mIoU: 0.9206770446196642, Test mIoU: 0.9307403490463162, Base LR: 0.0001, LR Backbone: 2.391931822053251e-05, LR Head: 2.391931822053251e-05,\n",
      "Best Learning Rate: 0.0001\n",
      "SAVING\n",
      "Epoch: 12, Train Loss: 0.029359741136431694, Val mIoU: 0.9350756766732239, Test mIoU: 0.9339444272703026, Base LR: 0.0001, LR Backbone: 2.353684491073659e-05, LR Head: 2.353684491073659e-05,\n",
      "Best Learning Rate: 0.0001\n",
      "SAVING\n",
      "Epoch: 13, Train Loss: 0.02658270299434662, Val mIoU: 0.9437461725681711, Test mIoU: 0.9345604833699882, Base LR: 0.0001, LR Backbone: 2.3100601201955324e-05, LR Head: 2.3100601201955324e-05,\n",
      "Best Learning Rate: 0.0001\n",
      "SAVING\n",
      "Epoch: 14, Train Loss: 0.025868896394968033, Val mIoU: 0.8761552716663494, Test mIoU: 0.8954511110006806, Base LR: 0.0001, LR Backbone: 2.2612712429686845e-05, LR Head: 2.2612712429686845e-05,\n",
      "Epoch: 15, Train Loss: 0.027360228821635246, Val mIoU: 0.9382613089811951, Test mIoU: 0.9356046204028327, Base LR: 0.0001, LR Backbone: 2.2075555538987227e-05, LR Head: 2.2075555538987227e-05,\n",
      "Epoch: 16, Train Loss: 0.027091430500149727, Val mIoU: 0.9364615003876765, Test mIoU: 0.939674522012016, Base LR: 0.0001, LR Backbone: 2.1491747504233138e-05, LR Head: 2.1491747504233138e-05,\n",
      "Epoch: 17, Train Loss: 0.022629760205745697, Val mIoU: 0.8975995385285961, Test mIoU: 0.924486438831169, Base LR: 0.0001, LR Backbone: 2.086413257948573e-05, LR Head: 2.086413257948573e-05,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Train Loss: 0.02256164513528347, Val mIoU: 0.8305358601740027, Test mIoU: 0.8618660872124986, Base LR: 0.0001, LR Backbone: 2.0195768441570727e-05, LR Head: 2.0195768441570727e-05,\n",
      "Epoch: 19, Train Loss: 0.02234448306262493, Val mIoU: 0.8028485356176016, Test mIoU: 0.8457155886642975, Base LR: 0.0001, LR Backbone: 1.9489911293384337e-05, LR Head: 1.9489911293384337e-05,\n",
      "Epoch: 20, Train Loss: 0.023672180250287056, Val mIoU: 0.9284425957261158, Test mIoU: 0.9325313706465805, Base LR: 0.0001, LR Backbone: 1.8750000000000002e-05, LR Head: 1.8750000000000002e-05,\n",
      "Epoch: 21, Train Loss: 0.022465698421001434, Val mIoU: 0.9411101508934911, Test mIoU: 0.9448832227484512, Base LR: 0.0001, LR Backbone: 1.7979639334863467e-05, LR Head: 1.7979639334863467e-05,\n",
      "Epoch: 22, Train Loss: 0.024516480043530464, Val mIoU: 0.7962835739702123, Test mIoU: 0.8468267535126646, Base LR: 0.0001, LR Backbone: 1.71825824176989e-05, LR Head: 1.71825824176989e-05,\n",
      "Epoch: 23, Train Loss: 0.02050183154642582, Val mIoU: 0.9389817375045666, Test mIoU: 0.9425682158605944, Base LR: 0.0001, LR Backbone: 1.6362712429686846e-05, LR Head: 1.6362712429686846e-05,\n",
      "Epoch: 24, Train Loss: 0.020262451842427254, Val mIoU: 0.9354145583615858, Test mIoU: 0.9372235489277716, Base LR: 0.0001, LR Backbone: 1.5524023694995848e-05, LR Head: 1.5524023694995848e-05,\n",
      "Epoch: 25, Train Loss: 0.019281860440969467, Val mIoU: 0.9429859094007131, Test mIoU: 0.9396335817522374, Base LR: 0.0001, LR Backbone: 1.4670602220836633e-05, LR Head: 1.4670602220836633e-05,\n",
      "Epoch: 26, Train Loss: 0.01876257359981537, Val mIoU: 0.9391488167618922, Test mIoU: 0.9357491403180975, Base LR: 0.0001, LR Backbone: 1.380660579084567e-05, LR Head: 1.380660579084567e-05,\n",
      "Epoch: 27, Train Loss: 0.02073059044778347, Val mIoU: 0.8580212829394298, Test mIoU: 0.900334217417911, Base LR: 0.0001, LR Backbone: 1.2936243708781266e-05, LR Head: 1.2936243708781266e-05,\n",
      "Epoch: 28, Train Loss: 0.02060534618794918, Val mIoU: 0.9503746872861787, Test mIoU: 0.944799991025661, Base LR: 0.0001, LR Backbone: 1.2063756291218742e-05, LR Head: 1.2063756291218742e-05,\n",
      "Best Learning Rate: 0.0001\n",
      "SAVING\n",
      "Epoch: 29, Train Loss: 0.01842993125319481, Val mIoU: 0.9405491170294507, Test mIoU: 0.9439927125924124, Base LR: 0.0001, LR Backbone: 1.1193394209154334e-05, LR Head: 1.1193394209154334e-05,\n",
      "Epoch: 30, Train Loss: 0.018444152548909187, Val mIoU: 0.9553248383074944, Test mIoU: 0.9414733838864144, Base LR: 0.0001, LR Backbone: 1.0329397779163372e-05, LR Head: 1.0329397779163372e-05,\n",
      "Best Learning Rate: 0.0001\n",
      "SAVING\n",
      "Epoch: 31, Train Loss: 0.017623839899897575, Val mIoU: 0.9232890632158611, Test mIoU: 0.9222414633140208, Base LR: 0.0001, LR Backbone: 9.475976305004153e-06, LR Head: 9.475976305004153e-06,\n",
      "Epoch: 32, Train Loss: 0.017858032137155533, Val mIoU: 0.9494084762817188, Test mIoU: 0.9157361586900277, Base LR: 0.0001, LR Backbone: 8.637287570313159e-06, LR Head: 8.637287570313159e-06,\n",
      "Epoch: 33, Train Loss: 0.01820935122668743, Val mIoU: 0.9517308193341343, Test mIoU: 0.9426362905210314, Base LR: 0.0001, LR Backbone: 7.8174175823011e-06, LR Head: 7.8174175823011e-06,\n",
      "Epoch: 34, Train Loss: 0.017772948369383812, Val mIoU: 0.9403494121372319, Test mIoU: 0.9382665659805437, Base LR: 0.0001, LR Backbone: 7.020360665136531e-06, LR Head: 7.020360665136531e-06,\n",
      "Epoch: 35, Train Loss: 0.016422485932707787, Val mIoU: 0.9557864610596994, Test mIoU: 0.9421830065091574, Base LR: 0.0001, LR Backbone: 6.250000000000003e-06, LR Head: 6.250000000000003e-06,\n",
      "Best Learning Rate: 0.0001\n",
      "SAVING\n",
      "Epoch: 36, Train Loss: 0.01687152124941349, Val mIoU: 0.9608095553777773, Test mIoU: 0.9474064792650989, Base LR: 0.0001, LR Backbone: 5.510088706615667e-06, LR Head: 5.510088706615667e-06,\n",
      "Best Learning Rate: 0.0001\n",
      "SAVING\n",
      "Epoch: 37, Train Loss: 0.016057800501585007, Val mIoU: 0.9547485194121983, Test mIoU: 0.9409785158830364, Base LR: 0.0001, LR Backbone: 4.804231558429271e-06, LR Head: 4.804231558429271e-06,\n",
      "Epoch: 38, Train Loss: 0.015638915821909904, Val mIoU: 0.9557069044835517, Test mIoU: 0.9406428934149829, Base LR: 0.0001, LR Backbone: 4.135867420514272e-06, LR Head: 4.135867420514272e-06,\n",
      "Epoch: 39, Train Loss: 0.015510497614741325, Val mIoU: 0.9552482919121676, Test mIoU: 0.9405564888634916, Base LR: 0.0001, LR Backbone: 3.50825249576686e-06, LR Head: 3.50825249576686e-06,\n",
      "Epoch: 40, Train Loss: 0.015223510563373566, Val mIoU: 0.9581839936281451, Test mIoU: 0.9421553957777606, Base LR: 0.0001, LR Backbone: 2.9244444610127764e-06, LR Head: 2.9244444610127764e-06,\n",
      "Epoch: 41, Train Loss: 0.01558221410959959, Val mIoU: 0.9600756147517362, Test mIoU: 0.9450660891289774, Base LR: 0.0001, LR Backbone: 2.3872875703131583e-06, LR Head: 2.3872875703131583e-06,\n",
      "Epoch: 42, Train Loss: 0.015596923418343067, Val mIoU: 0.9546023044672657, Test mIoU: 0.9437442722385972, Base LR: 0.0001, LR Backbone: 1.8993987980446755e-06, LR Head: 1.8993987980446755e-06,\n",
      "Epoch: 43, Train Loss: 0.015075256116688251, Val mIoU: 0.9504808639889186, Test mIoU: 0.9412110808912537, Base LR: 0.0001, LR Backbone: 1.4631550892634154e-06, LR Head: 1.4631550892634154e-06,\n",
      "Epoch: 44, Train Loss: 0.015144226141273975, Val mIoU: 0.9520283594850837, Test mIoU: 0.9396570181921298, Base LR: 0.0001, LR Backbone: 1.0806817794674906e-06, LR Head: 1.0806817794674906e-06,\n",
      "Epoch: 45, Train Loss: 0.015118316747248173, Val mIoU: 0.9572789703569036, Test mIoU: 0.9435520118299655, Base LR: 0.0001, LR Backbone: 7.538422401761461e-07, LR Head: 7.538422401761461e-07,\n",
      "Epoch: 46, Train Loss: 0.014776306226849556, Val mIoU: 0.9569279701642169, Test mIoU: 0.9434888208784966, Base LR: 0.0001, LR Backbone: 4.842288007710166e-07, LR Head: 4.842288007710166e-07,\n",
      "Epoch: 47, Train Loss: 0.01483447290956974, Val mIoU: 0.9573567449781984, Test mIoU: 0.9428355341971246, Base LR: 0.0001, LR Backbone: 2.7315499082742893e-07, LR Head: 2.7315499082742893e-07,\n",
      "Epoch: 48, Train Loss: 0.015035339631140232, Val mIoU: 0.957521331831545, Test mIoU: 0.9427322036712733, Base LR: 0.0001, LR Backbone: 1.2164914073037188e-07, LR Head: 1.2164914073037188e-07,\n",
      "Epoch: 49, Train Loss: 0.014796142466366291, Val mIoU: 0.9577048157239363, Test mIoU: 0.9429829816837996, Base LR: 0.0001, LR Backbone: 3.044937175219753e-08, LR Head: 3.044937175219753e-08,\n",
      "Learning Rate: 0.0002\n",
      "Epoch: 0, Train Loss: 1.2995938062667847, Val mIoU: 0.3017338791982299, Test mIoU: 0.29711897948670213, Base LR: 0.0002, LR Backbone: 0.0, LR Head: 0.0,\n",
      "Best Learning Rate: 0.0002\n",
      "SAVING\n",
      "Epoch: 1, Train Loss: 0.22750341892242432, Val mIoU: 0.8319534219304882, Test mIoU: 0.8813792976206811, Base LR: 0.0002, LR Backbone: 1e-05, LR Head: 1e-05,\n",
      "Best Learning Rate: 0.0002\n",
      "SAVING\n",
      "Epoch: 2, Train Loss: 0.0686040073633194, Val mIoU: 0.8554059010304036, Test mIoU: 0.8847379813407608, Base LR: 0.0002, LR Backbone: 2e-05, LR Head: 2e-05,\n",
      "Best Learning Rate: 0.0002\n",
      "SAVING\n",
      "Epoch: 3, Train Loss: 0.047438476234674454, Val mIoU: 0.8149311500074461, Test mIoU: 0.8900627867428093, Base LR: 0.0002, LR Backbone: 3.0000000000000004e-05, LR Head: 3.0000000000000004e-05,\n",
      "Epoch: 4, Train Loss: 0.044118162244558334, Val mIoU: 0.7966712518613545, Test mIoU: 0.8873906401543403, Base LR: 0.0002, LR Backbone: 4e-05, LR Head: 4e-05,\n",
      "Epoch: 5, Train Loss: 0.04107446223497391, Val mIoU: 0.8221749423224209, Test mIoU: 0.864389989565538, Base LR: 0.0002, LR Backbone: 5e-05, LR Head: 5e-05,\n",
      "Epoch: 6, Train Loss: 0.03535205125808716, Val mIoU: 0.8144530229004308, Test mIoU: 0.8720280174182723, Base LR: 0.0002, LR Backbone: 4.993910125649561e-05, LR Head: 4.993910125649561e-05,\n",
      "Epoch: 7, Train Loss: 0.033350829035043716, Val mIoU: 0.9055032307034772, Test mIoU: 0.9264241234240849, Base LR: 0.0002, LR Backbone: 4.975670171853926e-05, LR Head: 4.975670171853926e-05,\n",
      "Best Learning Rate: 0.0002\n",
      "SAVING\n",
      "Epoch: 8, Train Loss: 0.02953149378299713, Val mIoU: 0.9475796891743613, Test mIoU: 0.9440247036705234, Base LR: 0.0002, LR Backbone: 4.9453690018345144e-05, LR Head: 4.9453690018345144e-05,\n",
      "Best Learning Rate: 0.0002\n",
      "SAVING\n",
      "Epoch: 9, Train Loss: 0.029589110985398293, Val mIoU: 0.9015593544540594, Test mIoU: 0.9176478588880448, Base LR: 0.0002, LR Backbone: 4.9031542398457974e-05, LR Head: 4.9031542398457974e-05,\n",
      "Epoch: 10, Train Loss: 0.03262048214673996, Val mIoU: 0.8901200135803657, Test mIoU: 0.8872184683223381, Base LR: 0.0002, LR Backbone: 4.849231551964771e-05, LR Head: 4.849231551964771e-05,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Train Loss: 0.0258487556129694, Val mIoU: 0.8863644255321903, Test mIoU: 0.8956114864790303, Base LR: 0.0002, LR Backbone: 4.783863644106502e-05, LR Head: 4.783863644106502e-05,\n",
      "Epoch: 12, Train Loss: 0.02665051259100437, Val mIoU: 0.9134259606948016, Test mIoU: 0.9163259085628068, Base LR: 0.0002, LR Backbone: 4.707368982147318e-05, LR Head: 4.707368982147318e-05,\n",
      "Epoch: 13, Train Loss: 0.028352661058306694, Val mIoU: 0.928068380919738, Test mIoU: 0.9378587453169713, Base LR: 0.0002, LR Backbone: 4.620120240391065e-05, LR Head: 4.620120240391065e-05,\n",
      "Epoch: 14, Train Loss: 0.026796020567417145, Val mIoU: 0.9329946027054883, Test mIoU: 0.9240368657134235, Base LR: 0.0002, LR Backbone: 4.522542485937369e-05, LR Head: 4.522542485937369e-05,\n",
      "Epoch: 15, Train Loss: 0.022823607549071312, Val mIoU: 0.9604074571810579, Test mIoU: 0.9508717435944931, Base LR: 0.0002, LR Backbone: 4.415111107797445e-05, LR Head: 4.415111107797445e-05,\n",
      "Best Learning Rate: 0.0002\n",
      "SAVING\n",
      "Epoch: 16, Train Loss: 0.022691315039992332, Val mIoU: 0.9490737355741481, Test mIoU: 0.935848133968872, Base LR: 0.0002, LR Backbone: 4.2983495008466276e-05, LR Head: 4.2983495008466276e-05,\n",
      "Epoch: 17, Train Loss: 0.02468389831483364, Val mIoU: 0.9247178135559353, Test mIoU: 0.9450168507892338, Base LR: 0.0002, LR Backbone: 4.172826515897146e-05, LR Head: 4.172826515897146e-05,\n",
      "Epoch: 18, Train Loss: 0.024674072861671448, Val mIoU: 0.9557051689886364, Test mIoU: 0.9506893348150449, Base LR: 0.0002, LR Backbone: 4.039153688314145e-05, LR Head: 4.039153688314145e-05,\n",
      "Epoch: 19, Train Loss: 0.020954467356204987, Val mIoU: 0.9615682944647543, Test mIoU: 0.948778789858207, Base LR: 0.0002, LR Backbone: 3.897982258676867e-05, LR Head: 3.897982258676867e-05,\n",
      "Best Learning Rate: 0.0002\n",
      "SAVING\n",
      "Epoch: 20, Train Loss: 0.02358715794980526, Val mIoU: 0.9237713463034578, Test mIoU: 0.9175229281369386, Base LR: 0.0002, LR Backbone: 3.7500000000000003e-05, LR Head: 3.7500000000000003e-05,\n",
      "Epoch: 21, Train Loss: 0.022697754204273224, Val mIoU: 0.9545576992711382, Test mIoU: 0.9395456867434725, Base LR: 0.0002, LR Backbone: 3.5959278669726935e-05, LR Head: 3.5959278669726935e-05,\n",
      "Epoch: 22, Train Loss: 0.02300146408379078, Val mIoU: 0.9426173097368935, Test mIoU: 0.9466051026144542, Base LR: 0.0002, LR Backbone: 3.43651648353978e-05, LR Head: 3.43651648353978e-05,\n",
      "Epoch: 23, Train Loss: 0.020996704697608948, Val mIoU: 0.9536873815444469, Test mIoU: 0.9396727152430133, Base LR: 0.0002, LR Backbone: 3.272542485937369e-05, LR Head: 3.272542485937369e-05,\n",
      "Epoch: 24, Train Loss: 0.02006320282816887, Val mIoU: 0.9477781266927434, Test mIoU: 0.9341585883439901, Base LR: 0.0002, LR Backbone: 3.1048047389991696e-05, LR Head: 3.1048047389991696e-05,\n",
      "Epoch: 25, Train Loss: 0.018338866531848907, Val mIoU: 0.9547801556775313, Test mIoU: 0.9398349480893008, Base LR: 0.0002, LR Backbone: 2.9341204441673266e-05, LR Head: 2.9341204441673266e-05,\n",
      "Epoch: 26, Train Loss: 0.0256352536380291, Val mIoU: 0.9567443054932698, Test mIoU: 0.9473590678626831, Base LR: 0.0002, LR Backbone: 2.761321158169134e-05, LR Head: 2.761321158169134e-05,\n",
      "Epoch: 27, Train Loss: 0.018897460773587227, Val mIoU: 0.962765265292054, Test mIoU: 0.9512710711743917, Base LR: 0.0002, LR Backbone: 2.587248741756253e-05, LR Head: 2.587248741756253e-05,\n",
      "Best Learning Rate: 0.0002\n",
      "SAVING\n",
      "Epoch: 28, Train Loss: 0.018113646656274796, Val mIoU: 0.9500663584399804, Test mIoU: 0.9363593030832689, Base LR: 0.0002, LR Backbone: 2.4127512582437485e-05, LR Head: 2.4127512582437485e-05,\n",
      "Epoch: 29, Train Loss: 0.016940917819738388, Val mIoU: 0.9543921451176438, Test mIoU: 0.9432364461091634, Base LR: 0.0002, LR Backbone: 2.238678841830867e-05, LR Head: 2.238678841830867e-05,\n",
      "Epoch: 30, Train Loss: 0.017333373427391052, Val mIoU: 0.9605320453071187, Test mIoU: 0.9512902325118026, Base LR: 0.0002, LR Backbone: 2.0658795558326743e-05, LR Head: 2.0658795558326743e-05,\n",
      "Epoch: 31, Train Loss: 0.016996948048472404, Val mIoU: 0.9477630999369884, Test mIoU: 0.9379511577674793, Base LR: 0.0002, LR Backbone: 1.8951952610008307e-05, LR Head: 1.8951952610008307e-05,\n",
      "Epoch: 32, Train Loss: 0.016003234311938286, Val mIoU: 0.9506622535077041, Test mIoU: 0.9427420418014039, Base LR: 0.0002, LR Backbone: 1.7274575140626318e-05, LR Head: 1.7274575140626318e-05,\n",
      "Epoch: 33, Train Loss: 0.01728503406047821, Val mIoU: 0.9545700912492094, Test mIoU: 0.9373169348039546, Base LR: 0.0002, LR Backbone: 1.56348351646022e-05, LR Head: 1.56348351646022e-05,\n",
      "Epoch: 34, Train Loss: 0.01643102988600731, Val mIoU: 0.9509337615593356, Test mIoU: 0.9372158542821191, Base LR: 0.0002, LR Backbone: 1.4040721330273062e-05, LR Head: 1.4040721330273062e-05,\n",
      "Epoch: 35, Train Loss: 0.015617004595696926, Val mIoU: 0.9544908904009708, Test mIoU: 0.9438108989643831, Base LR: 0.0002, LR Backbone: 1.2500000000000006e-05, LR Head: 1.2500000000000006e-05,\n",
      "Epoch: 36, Train Loss: 0.015556884929537773, Val mIoU: 0.9577074862615914, Test mIoU: 0.9447594062563655, Base LR: 0.0002, LR Backbone: 1.1020177413231334e-05, LR Head: 1.1020177413231334e-05,\n",
      "Epoch: 37, Train Loss: 0.015313110314309597, Val mIoU: 0.9620000686486515, Test mIoU: 0.9457253822500158, Base LR: 0.0002, LR Backbone: 9.608463116858542e-06, LR Head: 9.608463116858542e-06,\n",
      "Epoch: 38, Train Loss: 0.015005615539848804, Val mIoU: 0.9636134276620577, Test mIoU: 0.9509868698504639, Base LR: 0.0002, LR Backbone: 8.271734841028545e-06, LR Head: 8.271734841028545e-06,\n",
      "Best Learning Rate: 0.0002\n",
      "SAVING\n",
      "Epoch: 39, Train Loss: 0.014876769855618477, Val mIoU: 0.9586484360458976, Test mIoU: 0.9482243181915121, Base LR: 0.0002, LR Backbone: 7.01650499153372e-06, LR Head: 7.01650499153372e-06,\n",
      "Epoch: 40, Train Loss: 0.014689940959215164, Val mIoU: 0.9621978862970773, Test mIoU: 0.9476385791049946, Base LR: 0.0002, LR Backbone: 5.848888922025553e-06, LR Head: 5.848888922025553e-06,\n",
      "Epoch: 41, Train Loss: 0.014115783385932446, Val mIoU: 0.9634279055955607, Test mIoU: 0.9503810165296405, Base LR: 0.0002, LR Backbone: 4.7745751406263165e-06, LR Head: 4.7745751406263165e-06,\n",
      "Epoch: 42, Train Loss: 0.014207703061401844, Val mIoU: 0.9624078616862259, Test mIoU: 0.9473996879440951, Base LR: 0.0002, LR Backbone: 3.798797596089351e-06, LR Head: 3.798797596089351e-06,\n",
      "Epoch: 43, Train Loss: 0.014017578214406967, Val mIoU: 0.959231729320563, Test mIoU: 0.9441001317066016, Base LR: 0.0002, LR Backbone: 2.926310178526831e-06, LR Head: 2.926310178526831e-06,\n",
      "Epoch: 44, Train Loss: 0.013930786401033401, Val mIoU: 0.963079589867132, Test mIoU: 0.9482008035022624, Base LR: 0.0002, LR Backbone: 2.161363558934981e-06, LR Head: 2.161363558934981e-06,\n",
      "Epoch: 45, Train Loss: 0.013710571452975273, Val mIoU: 0.9628122437558335, Test mIoU: 0.947863360197714, Base LR: 0.0002, LR Backbone: 1.5076844803522922e-06, LR Head: 1.5076844803522922e-06,\n",
      "Epoch: 46, Train Loss: 0.014179626479744911, Val mIoU: 0.9644035732734715, Test mIoU: 0.9496539235584908, Base LR: 0.0002, LR Backbone: 9.684576015420333e-07, LR Head: 9.684576015420333e-07,\n",
      "Best Learning Rate: 0.0002\n",
      "SAVING\n",
      "Epoch: 47, Train Loss: 0.013886413536965847, Val mIoU: 0.9635724408647748, Test mIoU: 0.94926609410081, Base LR: 0.0002, LR Backbone: 5.463099816548579e-07, LR Head: 5.463099816548579e-07,\n",
      "Epoch: 48, Train Loss: 0.01354833971709013, Val mIoU: 0.9632387066124724, Test mIoU: 0.9488547741678581, Base LR: 0.0002, LR Backbone: 2.4329828146074376e-07, LR Head: 2.4329828146074376e-07,\n",
      "Epoch: 49, Train Loss: 0.013741760514676571, Val mIoU: 0.9630812699798526, Test mIoU: 0.9486649040015809, Base LR: 0.0002, LR Backbone: 6.089874350439506e-08, LR Head: 6.089874350439506e-08,\n",
      "Learning Rate: 0.0005\n",
      "Epoch: 0, Train Loss: 1.3330625295639038, Val mIoU: 0.2934214644874434, Test mIoU: 0.2885074300794951, Base LR: 0.0005, LR Backbone: 0.0, LR Head: 0.0,\n",
      "Best Learning Rate: 0.0005\n",
      "SAVING\n",
      "Epoch: 1, Train Loss: 0.16617700457572937, Val mIoU: 0.9012558244851822, Test mIoU: 0.9209285692426277, Base LR: 0.0005, LR Backbone: 2.5e-05, LR Head: 2.5e-05,\n",
      "Best Learning Rate: 0.0005\n",
      "SAVING\n",
      "Epoch: 2, Train Loss: 0.06298144161701202, Val mIoU: 0.9298847660758491, Test mIoU: 0.932996910352176, Base LR: 0.0005, LR Backbone: 5e-05, LR Head: 5e-05,\n",
      "Best Learning Rate: 0.0005\n",
      "SAVING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train Loss: 0.04225732386112213, Val mIoU: 0.8807205991468734, Test mIoU: 0.9022021972040879, Base LR: 0.0005, LR Backbone: 7.500000000000001e-05, LR Head: 7.500000000000001e-05,\n",
      "Epoch: 4, Train Loss: 0.055461183190345764, Val mIoU: 0.878533727152651, Test mIoU: 0.8858947735751287, Base LR: 0.0005, LR Backbone: 0.0001, LR Head: 0.0001,\n",
      "Epoch: 5, Train Loss: 0.04420410096645355, Val mIoU: 0.9151500663340355, Test mIoU: 0.9197640657811869, Base LR: 0.0005, LR Backbone: 0.000125, LR Head: 0.000125,\n",
      "Epoch: 6, Train Loss: 0.036866698414087296, Val mIoU: 0.9170412522417164, Test mIoU: 0.9331530765864839, Base LR: 0.0005, LR Backbone: 0.00012484775314123902, LR Head: 0.00012484775314123902,\n",
      "Epoch: 7, Train Loss: 0.03362426906824112, Val mIoU: 0.8751715708000193, Test mIoU: 0.8948163038482567, Base LR: 0.0005, LR Backbone: 0.00012439175429634816, LR Head: 0.00012439175429634816,\n",
      "Epoch: 8, Train Loss: 0.036280762404203415, Val mIoU: 0.946210207838375, Test mIoU: 0.9356453044670167, Base LR: 0.0005, LR Backbone: 0.00012363422504586285, LR Head: 0.00012363422504586285,\n",
      "Best Learning Rate: 0.0005\n",
      "SAVING\n",
      "Epoch: 9, Train Loss: 0.03325793519616127, Val mIoU: 0.9214005986219074, Test mIoU: 0.9135979269111526, Base LR: 0.0005, LR Backbone: 0.00012257885599614493, LR Head: 0.00012257885599614493,\n",
      "Epoch: 10, Train Loss: 0.030207764357328415, Val mIoU: 0.9339441538250026, Test mIoU: 0.9314119446673901, Base LR: 0.0005, LR Backbone: 0.00012123078879911927, LR Head: 0.00012123078879911927,\n",
      "Epoch: 11, Train Loss: 0.030426025390625, Val mIoU: 0.9480842368295725, Test mIoU: 0.9322095594824553, Base LR: 0.0005, LR Backbone: 0.00011959659110266256, LR Head: 0.00011959659110266256,\n",
      "Best Learning Rate: 0.0005\n",
      "SAVING\n",
      "Epoch: 12, Train Loss: 0.029225585982203484, Val mIoU: 0.9312941831606569, Test mIoU: 0.9168600036629531, Base LR: 0.0005, LR Backbone: 0.00011768422455368293, LR Head: 0.00011768422455368293,\n",
      "Epoch: 13, Train Loss: 0.028244629502296448, Val mIoU: 0.9591834412552838, Test mIoU: 0.9412997436485009, Base LR: 0.0005, LR Backbone: 0.00011550300600977662, LR Head: 0.00011550300600977662,\n",
      "Best Learning Rate: 0.0005\n",
      "SAVING\n",
      "Epoch: 14, Train Loss: 0.0315239243209362, Val mIoU: 0.9164659453638042, Test mIoU: 0.914679240480012, Base LR: 0.0005, LR Backbone: 0.00011306356214843422, LR Head: 0.00011306356214843422,\n",
      "Epoch: 15, Train Loss: 0.027885742485523224, Val mIoU: 0.9603281108328254, Test mIoU: 0.9450962493117478, Base LR: 0.0005, LR Backbone: 0.00011037777769493612, LR Head: 0.00011037777769493612,\n",
      "Best Learning Rate: 0.0005\n",
      "SAVING\n",
      "Epoch: 16, Train Loss: 0.026383545249700546, Val mIoU: 0.9565983959514011, Test mIoU: 0.9394812269745864, Base LR: 0.0005, LR Backbone: 0.0001074587375211657, LR Head: 0.0001074587375211657,\n",
      "Epoch: 17, Train Loss: 0.02806359902024269, Val mIoU: 0.9586475609610443, Test mIoU: 0.9446649731955207, Base LR: 0.0005, LR Backbone: 0.00010432066289742864, LR Head: 0.00010432066289742864,\n",
      "Epoch: 18, Train Loss: 0.025435181334614754, Val mIoU: 0.9562828028343721, Test mIoU: 0.9420195559759916, Base LR: 0.0005, LR Backbone: 0.00010097884220785364, LR Head: 0.00010097884220785364,\n",
      "Epoch: 19, Train Loss: 0.023511413484811783, Val mIoU: 0.9526809199462698, Test mIoU: 0.9398381861960536, Base LR: 0.0005, LR Backbone: 9.744955646692168e-05, LR Head: 9.744955646692168e-05,\n",
      "Epoch: 20, Train Loss: 0.025516968220472336, Val mIoU: 0.9558569014919354, Test mIoU: 0.9493668128628333, Base LR: 0.0005, LR Backbone: 9.375e-05, LR Head: 9.375e-05,\n",
      "Epoch: 21, Train Loss: 0.026305053383111954, Val mIoU: 0.8852870688804615, Test mIoU: 0.9020137606704637, Base LR: 0.0005, LR Backbone: 8.989819667431733e-05, LR Head: 8.989819667431733e-05,\n",
      "Epoch: 22, Train Loss: 0.02970275841653347, Val mIoU: 0.9390655394323135, Test mIoU: 0.937221845579425, Base LR: 0.0005, LR Backbone: 8.59129120884945e-05, LR Head: 8.59129120884945e-05,\n",
      "Epoch: 23, Train Loss: 0.022074585780501366, Val mIoU: 0.9649076061274497, Test mIoU: 0.9508005817525056, Base LR: 0.0005, LR Backbone: 8.181356214843422e-05, LR Head: 8.181356214843422e-05,\n",
      "Best Learning Rate: 0.0005\n",
      "SAVING\n",
      "Epoch: 24, Train Loss: 0.02137463353574276, Val mIoU: 0.9522312776016075, Test mIoU: 0.9444745094960734, Base LR: 0.0005, LR Backbone: 7.762011847497924e-05, LR Head: 7.762011847497924e-05,\n",
      "Epoch: 25, Train Loss: 0.01940038986504078, Val mIoU: 0.9601981700667741, Test mIoU: 0.9456325390289495, Base LR: 0.0005, LR Backbone: 7.335301110418317e-05, LR Head: 7.335301110418317e-05,\n",
      "Epoch: 26, Train Loss: 0.019092895090579987, Val mIoU: 0.9469323548721018, Test mIoU: 0.9357940740771347, Base LR: 0.0005, LR Backbone: 6.903302895422835e-05, LR Head: 6.903302895422835e-05,\n",
      "Epoch: 27, Train Loss: 0.018733032047748566, Val mIoU: 0.9469637997416428, Test mIoU: 0.9362255538327802, Base LR: 0.0005, LR Backbone: 6.468121854390632e-05, LR Head: 6.468121854390632e-05,\n",
      "Epoch: 28, Train Loss: 0.019893310964107513, Val mIoU: 0.9365338025433471, Test mIoU: 0.9318464996174588, Base LR: 0.0005, LR Backbone: 6.031878145609371e-05, LR Head: 6.031878145609371e-05,\n",
      "Epoch: 29, Train Loss: 0.02155786193907261, Val mIoU: 0.9490397526532615, Test mIoU: 0.943193076178862, Base LR: 0.0005, LR Backbone: 5.596697104577167e-05, LR Head: 5.596697104577167e-05,\n",
      "Epoch: 30, Train Loss: 0.01996752992272377, Val mIoU: 0.9495954573062992, Test mIoU: 0.9341535787998807, Base LR: 0.0005, LR Backbone: 5.164698889581686e-05, LR Head: 5.164698889581686e-05,\n",
      "Epoch: 31, Train Loss: 0.0184482429176569, Val mIoU: 0.9561618469946325, Test mIoU: 0.9424418145587081, Base LR: 0.0005, LR Backbone: 4.737988152502076e-05, LR Head: 4.737988152502076e-05,\n",
      "Epoch: 32, Train Loss: 0.017320312559604645, Val mIoU: 0.9623049723494402, Test mIoU: 0.947152226466422, Base LR: 0.0005, LR Backbone: 4.318643785156579e-05, LR Head: 4.318643785156579e-05,\n",
      "Epoch: 33, Train Loss: 0.01770959421992302, Val mIoU: 0.9510217624517262, Test mIoU: 0.9453859627170351, Base LR: 0.0005, LR Backbone: 3.9087087911505495e-05, LR Head: 3.9087087911505495e-05,\n",
      "Epoch: 34, Train Loss: 0.016786132007837296, Val mIoU: 0.9602331782549107, Test mIoU: 0.9463688687207059, Base LR: 0.0005, LR Backbone: 3.5101803325682655e-05, LR Head: 3.5101803325682655e-05,\n",
      "Epoch: 35, Train Loss: 0.015726501122117043, Val mIoU: 0.9543939886986337, Test mIoU: 0.9427438539979371, Base LR: 0.0005, LR Backbone: 3.1250000000000014e-05, LR Head: 3.1250000000000014e-05,\n",
      "Epoch: 36, Train Loss: 0.015576599165797234, Val mIoU: 0.9586649231082687, Test mIoU: 0.9463183947934677, Base LR: 0.0005, LR Backbone: 2.7550443533078333e-05, LR Head: 2.7550443533078333e-05,\n",
      "Epoch: 37, Train Loss: 0.015114685520529747, Val mIoU: 0.9627582319729615, Test mIoU: 0.9504740995852252, Base LR: 0.0005, LR Backbone: 2.4021157792146356e-05, LR Head: 2.4021157792146356e-05,\n",
      "Epoch: 38, Train Loss: 0.014806396327912807, Val mIoU: 0.961440623671736, Test mIoU: 0.9495381223543695, Base LR: 0.0005, LR Backbone: 2.067933710257136e-05, LR Head: 2.067933710257136e-05,\n",
      "Epoch: 39, Train Loss: 0.015172119252383709, Val mIoU: 0.9656397840305004, Test mIoU: 0.9519617049407583, Base LR: 0.0005, LR Backbone: 1.7541262478834302e-05, LR Head: 1.7541262478834302e-05,\n",
      "Best Learning Rate: 0.0005\n",
      "SAVING\n",
      "Epoch: 40, Train Loss: 0.014760985970497131, Val mIoU: 0.9646516747833813, Test mIoU: 0.949847680781484, Base LR: 0.0005, LR Backbone: 1.4622222305063882e-05, LR Head: 1.4622222305063882e-05,\n",
      "Epoch: 41, Train Loss: 0.014461182057857513, Val mIoU: 0.9627501968268706, Test mIoU: 0.9494179094442677, Base LR: 0.0005, LR Backbone: 1.1936437851565791e-05, LR Head: 1.1936437851565791e-05,\n",
      "Epoch: 42, Train Loss: 0.01445324718952179, Val mIoU: 0.962512230577796, Test mIoU: 0.9502336823109314, Base LR: 0.0005, LR Backbone: 9.496993990223377e-06, LR Head: 9.496993990223377e-06,\n",
      "Epoch: 43, Train Loss: 0.013711669482290745, Val mIoU: 0.9607923099230133, Test mIoU: 0.946561118544559, Base LR: 0.0005, LR Backbone: 7.315775446317077e-06, LR Head: 7.315775446317077e-06,\n",
      "Epoch: 44, Train Loss: 0.013799927197396755, Val mIoU: 0.9608978027903301, Test mIoU: 0.9461529874366349, Base LR: 0.0005, LR Backbone: 5.403408897337453e-06, LR Head: 5.403408897337453e-06,\n",
      "Epoch: 45, Train Loss: 0.013513275422155857, Val mIoU: 0.9631921238355377, Test mIoU: 0.9507707779971235, Base LR: 0.0005, LR Backbone: 3.7692112008807303e-06, LR Head: 3.7692112008807303e-06,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46, Train Loss: 0.01330249011516571, Val mIoU: 0.9634917929531428, Test mIoU: 0.952007521500277, Base LR: 0.0005, LR Backbone: 2.421144003855083e-06, LR Head: 2.421144003855083e-06,\n",
      "Epoch: 47, Train Loss: 0.01324609387665987, Val mIoU: 0.9632249493323164, Test mIoU: 0.9510069565585112, Base LR: 0.0005, LR Backbone: 1.3657749541371445e-06, LR Head: 1.3657749541371445e-06,\n",
      "Epoch: 48, Train Loss: 0.01345233153551817, Val mIoU: 0.9634358023260089, Test mIoU: 0.9519161940851992, Base LR: 0.0005, LR Backbone: 6.082457036518593e-07, LR Head: 6.082457036518593e-07,\n",
      "Epoch: 49, Train Loss: 0.013225342147052288, Val mIoU: 0.9634261291329599, Test mIoU: 0.951716280332386, Base LR: 0.0005, LR Backbone: 1.5224685876098765e-07, LR Head: 1.5224685876098765e-07,\n",
      "Learning Rate: 0.001\n",
      "Epoch: 0, Train Loss: 1.4430625438690186, Val mIoU: 0.28130972475442406, Test mIoU: 0.2757947857160728, Base LR: 0.001, LR Backbone: 0.0, LR Head: 0.0,\n",
      "Best Learning Rate: 0.001\n",
      "SAVING\n",
      "Epoch: 1, Train Loss: 0.15151123702526093, Val mIoU: 0.8340883745303815, Test mIoU: 0.8767744289662417, Base LR: 0.001, LR Backbone: 5e-05, LR Head: 5e-05,\n",
      "Best Learning Rate: 0.001\n",
      "SAVING\n",
      "Epoch: 2, Train Loss: 0.06745068728923798, Val mIoU: 0.8692171254838708, Test mIoU: 0.9011071415077698, Base LR: 0.001, LR Backbone: 0.0001, LR Head: 0.0001,\n",
      "Best Learning Rate: 0.001\n",
      "SAVING\n",
      "Epoch: 3, Train Loss: 0.05156005918979645, Val mIoU: 0.9088706900586303, Test mIoU: 0.9259459983371843, Base LR: 0.001, LR Backbone: 0.00015000000000000001, LR Head: 0.00015000000000000001,\n",
      "Best Learning Rate: 0.001\n",
      "SAVING\n",
      "Epoch: 4, Train Loss: 0.08656542748212814, Val mIoU: 0.42610832865778353, Test mIoU: 0.43603636084659625, Base LR: 0.001, LR Backbone: 0.0002, LR Head: 0.0002,\n",
      "Epoch: 5, Train Loss: 0.5434726476669312, Val mIoU: 0.4179778822767402, Test mIoU: 0.4302797174595595, Base LR: 0.001, LR Backbone: 0.00025, LR Head: 0.00025,\n",
      "Epoch: 6, Train Loss: 0.4787265658378601, Val mIoU: 0.42753376337714993, Test mIoU: 0.4481193831495748, Base LR: 0.001, LR Backbone: 0.00024969550628247805, LR Head: 0.00024969550628247805,\n",
      "Epoch: 7, Train Loss: 0.2634257674217224, Val mIoU: 0.8339032818779102, Test mIoU: 0.7659193793868164, Base LR: 0.001, LR Backbone: 0.0002487835085926963, LR Head: 0.0002487835085926963,\n",
      "Epoch: 8, Train Loss: 0.17674022912979126, Val mIoU: 0.8561735460716506, Test mIoU: 0.8271171532677606, Base LR: 0.001, LR Backbone: 0.0002472684500917257, LR Head: 0.0002472684500917257,\n",
      "Epoch: 9, Train Loss: 0.16352637112140656, Val mIoU: 0.8463888165351491, Test mIoU: 0.7970211272784817, Base LR: 0.001, LR Backbone: 0.00024515771199228986, LR Head: 0.00024515771199228986,\n",
      "Epoch: 10, Train Loss: 0.15211035311222076, Val mIoU: 0.7392063838055456, Test mIoU: 0.7616040695960238, Base LR: 0.001, LR Backbone: 0.00024246157759823855, LR Head: 0.00024246157759823855,\n",
      "Epoch: 11, Train Loss: 0.13875780999660492, Val mIoU: 0.8456521960529164, Test mIoU: 0.8363443775745685, Base LR: 0.001, LR Backbone: 0.0002391931822053251, LR Head: 0.0002391931822053251,\n",
      "Epoch: 12, Train Loss: 0.34731054306030273, Val mIoU: 0.644578510942227, Test mIoU: 0.6334590220861682, Base LR: 0.001, LR Backbone: 0.00023536844910736587, LR Head: 0.00023536844910736587,\n",
      "Epoch: 13, Train Loss: 0.2480156272649765, Val mIoU: 0.8324037283469641, Test mIoU: 0.8137836514167128, Base LR: 0.001, LR Backbone: 0.00023100601201955323, LR Head: 0.00023100601201955323,\n",
      "Epoch: 14, Train Loss: 0.295654296875, Val mIoU: 0.7534288875462043, Test mIoU: 0.7539827339485375, Base LR: 0.001, LR Backbone: 0.00022612712429686844, LR Head: 0.00022612712429686844,\n",
      "Epoch: 15, Train Loss: 0.16169336438179016, Val mIoU: 0.8459534600908235, Test mIoU: 0.8211318982832225, Base LR: 0.001, LR Backbone: 0.00022075555538987224, LR Head: 0.00022075555538987224,\n",
      "Epoch: 16, Train Loss: 0.1476113349199295, Val mIoU: 0.8487477567004917, Test mIoU: 0.7986713528909366, Base LR: 0.001, LR Backbone: 0.0002149174750423314, LR Head: 0.0002149174750423314,\n",
      "Epoch: 17, Train Loss: 0.14369434118270874, Val mIoU: 0.8046527169253507, Test mIoU: 0.808735115225949, Base LR: 0.001, LR Backbone: 0.0002086413257948573, LR Head: 0.0002086413257948573,\n",
      "Epoch: 18, Train Loss: 0.13541406393051147, Val mIoU: 0.8606383660381014, Test mIoU: 0.8271520172087503, Base LR: 0.001, LR Backbone: 0.00020195768441570727, LR Head: 0.00020195768441570727,\n",
      "Epoch: 19, Train Loss: 0.13327442109584808, Val mIoU: 0.8011514577138252, Test mIoU: 0.7289542213285207, Base LR: 0.001, LR Backbone: 0.00019489911293384335, LR Head: 0.00019489911293384335,\n",
      "Epoch: 20, Train Loss: 0.12128027528524399, Val mIoU: 0.7262932729311935, Test mIoU: 0.7537014156157744, Base LR: 0.001, LR Backbone: 0.0001875, LR Head: 0.0001875,\n",
      "Epoch: 21, Train Loss: 0.12458300590515137, Val mIoU: 0.8722488916134395, Test mIoU: 0.8453376588303982, Base LR: 0.001, LR Backbone: 0.00017979639334863467, LR Head: 0.00017979639334863467,\n",
      "Epoch: 22, Train Loss: 0.11850976198911667, Val mIoU: 0.8706925756640009, Test mIoU: 0.8585137448090439, Base LR: 0.001, LR Backbone: 0.000171825824176989, LR Head: 0.000171825824176989,\n",
      "Epoch: 23, Train Loss: 0.11143261939287186, Val mIoU: 0.8433093202464181, Test mIoU: 0.8043567716537048, Base LR: 0.001, LR Backbone: 0.00016362712429686844, LR Head: 0.00016362712429686844,\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [1e-5, 5e-5, 8e-5, 1e-4, 2e-4, 5e-4, 1e-3]\n",
    "best_lr = None\n",
    "best_model_state = None\n",
    "best_linear_layer = None\n",
    "use_mixup = False\n",
    "lambda_values = [0.2, 0.5, 0.8]\n",
    "\n",
    "columns = ['Learning Rate', 'Epoch', 'Train Loss', 'Val mIoU', 'Test mIoU']\n",
    "model_info_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for base_lr in learning_rates:\n",
    "#     for lam in lambda_values:\n",
    "\n",
    "#     validation_files = file_names[(6*fold_num):(6*fold_num+6)]\n",
    "\n",
    "#     train_imgs = []\n",
    "#     train_labels = []\n",
    "#     val_imgs = []\n",
    "#     val_labels = []\n",
    "\n",
    "#     data_paths = os.listdir('muscle_5x_normed')\n",
    "#     for i_path, data_path in enumerate(data_paths):\n",
    "#         torch_obj = torch.load(f'muscle_5x_normed/{data_path}')\n",
    "\n",
    "#         if data_path in validation_files:\n",
    "#             val_imgs.append(torch_obj['imgs'])\n",
    "#             val_labels.append(torch_obj['muscles'])\n",
    "#         else:\n",
    "#             train_imgs.append(torch_obj['imgs'])\n",
    "#             train_labels.append(torch_obj['muscles'])\n",
    "\n",
    "#     # 512 now not 256\n",
    "#     train_imgs = torch.cat(train_imgs, dim=0)  # (48_000, 3, 256, 256) \n",
    "#     train_labels = torch.cat(train_labels, dim=0)  # (48_000, 1, 256, 256)\n",
    "#     val_imgs = torch.cat(val_imgs, dim=0)  # (12_000, 3, 256, 256)\n",
    "#     val_labels = torch.cat(val_labels, dim=0)  # (12_000, 1, 256, 256)\n",
    "\n",
    "    print(f'Learning Rate: {base_lr}')\n",
    "#     print(train_imgs.shape, train_labels.shape)\n",
    "#     print(val_imgs.shape, val_labels.shape)\n",
    "\n",
    "    batch_size = 64\n",
    "\n",
    "    train_dataset = HirschImagesDataset(data_file_path=\"muscle_train\", do_augmentation=True)\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=8\n",
    "                             )\n",
    "\n",
    "    val_dataset = HirschImagesDataset(data_file_path=\"muscle_val\", do_augmentation=False)\n",
    "    val_loader = DataLoader(val_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=False,\n",
    "                              num_workers=8\n",
    "                           )\n",
    "\n",
    "    test_dataset = HirschImagesDataset(data_file_path=\"muscle_test\", do_augmentation=False)\n",
    "    test_loader = DataLoader(test_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=False,\n",
    "                          num_workers=8\n",
    "                            )\n",
    "\n",
    "#     train_loader = DataLoader(TensorDataset(train_imgs, train_labels), batch_size=batch_size, shuffle=True)\n",
    "#     val_loader = DataLoader(TensorDataset(val_imgs, val_labels), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#     del train_imgs\n",
    "#     del train_labels\n",
    "#     del val_imgs\n",
    "#     del val_labels\n",
    "\n",
    "    best_val_miou = 0\n",
    "    #base_lr = 1e-4\n",
    "    learning_rate = base_lr * batch_size / 256 # added\n",
    "\n",
    "    model = og_mae.mae_vit_base_patch16_dec512d8b().cuda()\n",
    "    model.load_state_dict(torch.load('mae_visualize_vit_base.pth')['model'])\n",
    "    linear = nn.Linear(768, 512).cuda()\n",
    "\n",
    "    # decoder = segmenter.MaskTransformer(n_cls=2,\n",
    "    #                                     patch_size=16,\n",
    "    #                                     d_encoder=384,\n",
    "    #                                     n_layers=2,\n",
    "    #                                     n_heads=12,\n",
    "    #                                     d_model=384,\n",
    "    #                                     d_ff=1536,\n",
    "    #                                     drop_path_rate=0,\n",
    "    #                                     dropout=0)\n",
    "    # seg_head = segmenter.Segmenter(decoder=decoder, n_cls=2).cuda()\n",
    "\n",
    "    # optimizer\n",
    "    backbone_params = model.parameters()\n",
    "    linear_params = linear.parameters()\n",
    "    # head_params = seg_head.parameters()\n",
    "    opt = torch.optim.AdamW([{'params': backbone_params}, {'params': linear_params}], lr=learning_rate)\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Prep LR stepping\n",
    "    epochs = 50\n",
    "    multiplier = 1\n",
    "    backbone_config = {'lr': learning_rate,\n",
    "                       'warmup_epochs': 5,\n",
    "                       'min_lr': 0,\n",
    "                       'epochs': epochs}\n",
    "\n",
    "    head_config = {'lr': multiplier * learning_rate,\n",
    "                   'warmup_epochs': 5,\n",
    "                   'min_lr': 0,\n",
    "                   'epochs': epochs}\n",
    "    num_down = 0\n",
    "    for epoch in range(epochs):\n",
    "        if num_down >= 20:\n",
    "            break\n",
    "\n",
    "        opt.param_groups[0]['lr'] = adjust_learning_rate(epoch, backbone_config)\n",
    "        opt.param_groups[1]['lr'] = adjust_learning_rate(epoch, head_config)\n",
    "\n",
    "        current_lr_backbone = opt.param_groups[0]['lr']  # confirm\n",
    "        current_lr_head = opt.param_groups[1]['lr']  # confirm\n",
    "\n",
    "        train_losses = []\n",
    "\n",
    "        model = model.train()\n",
    "        # seg_head = seg_head.train()\n",
    "        linear = linear.train()\n",
    "        for batch in train_loader:\n",
    "            img, plexus = batch  # load from batch\n",
    "\n",
    "            # Q: I shouldn't augment again right?\n",
    "\n",
    "            img = img.cuda().to(dtype=torch.bfloat16) / 255  # (bsz, 3, H, W)\n",
    "            plexus = plexus.cuda().long().squeeze(dim=1)  # (bsz, H, W)\n",
    "\n",
    "            # Mix the inputs and the labels here\n",
    "            # 1st Step: flip the order of the images\n",
    "            if use_mixup:\n",
    "                img_flipped = img.flip(0)\n",
    "                img = (1 - lam) * img_flipped + lam * img\n",
    "\n",
    "            with torch.cuda.amp.autocast(dtype=torch.bfloat16):\n",
    "                x = model.patch_embed(img)\n",
    "                x = x + model.pos_embed[:, 1:, :]\n",
    "\n",
    "                cls_token = model.cls_token + model.pos_embed[:, :1, :]\n",
    "                cls_tokens = cls_token.expand(x.shape[0], -1, -1)\n",
    "                x = torch.cat((cls_tokens, x), dim=1)\n",
    "\n",
    "                # apply Transformer blocks\n",
    "                for blk in model.blocks:\n",
    "                    x = blk(x)  # (bsz, L, 768)\n",
    "\n",
    "                x = linear(x)  # (bsz, L, 512)\n",
    "                logits = rearrange(x[:, 1:, :], 'b (h w) (c i j) -> b c (h i) (w j)', h=14, w=14, c=2, i=16, j=16)  # (bsz, 2, H, W)\n",
    "                # logits = seg_head(features=x[:, 1:, :], HW_input=224, HW_target=224)  # (bsz, 2, H, W)\n",
    "\n",
    "#             print(logits.shape, plexus.shape)\n",
    "            if use_mixup:\n",
    "                loss_original = loss_function(logits, plexus)\n",
    "                loss_flipped = loss_function(logits, plexus.flip(0))\n",
    "                loss = (1 - lam) * loss_flipped + lam * loss_original\n",
    "            else:\n",
    "                loss = loss_function(logits, plexus)\n",
    "\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "#         val_losses = []\n",
    "        thresh = 0.5\n",
    "        all_predictions_val  = []\n",
    "        all_gt_val = []\n",
    "        model.eval()\n",
    "        for batch in val_loader:\n",
    "            img, plexus = batch  # load from batch\n",
    "            img = img.cuda().to(dtype=torch.bfloat16) / 255  # (bsz, 3, H, W)\n",
    "            plexus = plexus.cuda().long().squeeze(dim=1)  # (bsz, H, W)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                with torch.cuda.amp.autocast(dtype=torch.bfloat16):\n",
    "                    x = model.patch_embed(img)\n",
    "                    x = x + model.pos_embed[:, 1:, :]\n",
    "\n",
    "                    cls_token = model.cls_token + model.pos_embed[:, :1, :]\n",
    "                    cls_tokens = cls_token.expand(x.shape[0], -1, -1)\n",
    "                    x = torch.cat((cls_tokens, x), dim=1)\n",
    "\n",
    "                    # apply Transformer blocks\n",
    "                    for blk in model.blocks:\n",
    "                        x = blk(x)  # (bsz, L, 768)\n",
    "\n",
    "                    x = linear(x)  # (bsz, L, 512)\n",
    "                    logits = rearrange(x[:, 1:, :], 'b (h w) (c i j) -> b c (h i) (w j)', h=14, w=14, c=2, i=16,\n",
    "                                       j=16)  # (bsz, 2, H, W)\n",
    "                    probability = logits.softmax(dim=1)\n",
    "                    predictions = (probability[:,1,:, :] > thresh).long()\n",
    "#                     predictions  = logits.argmax(dim=1)  # (bza, H, W)\n",
    "            all_predictions_val.append(predictions.cpu())\n",
    "            all_gt_val.append(plexus.cpu())\n",
    "                    # logits = seg_head(features=x[:, 1:, :], HW_input=224, HW_target=224)  # (bsz, 2, H, W)\n",
    "\n",
    "#             loss = loss_function(logits, plexus)\n",
    "#             val_losses.append(loss.item())\n",
    "        all_predictions_val = torch.cat(all_predictions_val, dim=0).numpy()\n",
    "        all_gt_val = torch.cat(all_gt_val, dim=0).numpy()\n",
    "\n",
    "        val_miou = compute_iou(all_predictions_val, all_gt_val)\n",
    "\n",
    "#         val_miou = mean_iou(results=all_predictions_val,\n",
    "#                     gt_seg_maps=all_gt_val,\n",
    "#                     num_classes=2,\n",
    "#                     ignore_index=-1)\n",
    "\n",
    "#         test_losses = []\n",
    "        thresh = 0.5\n",
    "        all_predictions_test  = []\n",
    "        all_gt_test = []\n",
    "        model.eval()\n",
    "        for batch in test_loader:\n",
    "            img, plexus = batch  # load from batch\n",
    "            img = img.cuda().to(dtype=torch.bfloat16) / 255  # (bsz, 3, H, W)\n",
    "            plexus = plexus.cuda().long().squeeze(dim=1)  # (bsz, H, W)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                with torch.cuda.amp.autocast(dtype=torch.bfloat16):\n",
    "                    x = model.patch_embed(img)\n",
    "                    x = x + model.pos_embed[:, 1:, :]\n",
    "\n",
    "                    cls_token = model.cls_token + model.pos_embed[:, :1, :]\n",
    "                    cls_tokens = cls_token.expand(x.shape[0], -1, -1)\n",
    "                    x = torch.cat((cls_tokens, x), dim=1)\n",
    "\n",
    "                    # apply Transformer blocks\n",
    "                    for blk in model.blocks:\n",
    "                        x = blk(x)  # (bsz, L, 768)\n",
    "\n",
    "                    x = linear(x)  # (bsz, L, 512)\n",
    "                    logits = rearrange(x[:, 1:, :], 'b (h w) (c i j) -> b c (h i) (w j)', h=14, w=14, c=2, i=16,\n",
    "                                       j=16)  # (bsz, 2, H, W)\n",
    "                    probability = logits.softmax(dim=1)\n",
    "                    predictions = (probability[:,1,:, :] > thresh).long()\n",
    "#                     predictions  = logits.argmax(dim=1)  # (bza, H, W)\n",
    "            all_predictions_test.append(predictions.cpu())\n",
    "            all_gt_test.append(plexus.cpu())\n",
    "                    # logits = seg_head(features=x[:, 1:, :], HW_input=224, HW_target=224)  # (bsz, 2, H, W)\n",
    "\n",
    "#             loss = loss_function(logits, plexus)\n",
    "#             test_losses.append(loss.item())\n",
    "        all_predictions_test = torch.cat(all_predictions_test, dim=0).numpy()\n",
    "        all_gt_test = torch.cat(all_gt_test, dim=0).numpy()\n",
    "\n",
    "        test_miou = compute_iou(all_predictions_test, all_gt_test)\n",
    "\n",
    "#         test_miou = mean_iou(results=all_predictions_test,\n",
    "#                     gt_seg_maps=all_gt_test,\n",
    "#                     num_classes=2,\n",
    "#                     ignore_index=-1)\n",
    "\n",
    "        train_losses = torch.Tensor(train_losses).mean().item()\n",
    "#         val_losses = torch.Tensor(val_losses).mean().item()\n",
    "#         test_losses = torch.Tensor(test_losses).mean().item()\n",
    "        print(f'Epoch: {epoch}, Train Loss: {train_losses}, Val mIoU: {val_miou}, Test mIoU: {test_miou}, Base LR: {base_lr}, LR Backbone: {current_lr_backbone}, LR Head: {current_lr_head},')\n",
    "\n",
    "#         avg_val_miou = val_miou['IoU'].mean()\n",
    "\n",
    "        if val_miou > best_val_miou:\n",
    "            best_val_miou = val_miou\n",
    "            best_lr = base_lr\n",
    "#             best_model_state = copy.deepcopy(model.state_dict()) \n",
    "#             best_linear_layer = copy.deepcopy(linear.state_dict()) \n",
    "            print(f'Best Learning Rate: {best_lr}')\n",
    "            print(f'SAVING')\n",
    "            # torch.save(obj={'backbone': model.state_dict(),\n",
    "            #                 'head': seg_head.state_dict()},\n",
    "            #            f=f'saved_models/ViT_HIPT_{fold_num}_muscle_5x_{base_lr}.pt')\n",
    "            torch.save(obj={'backbone': model.state_dict(),\n",
    "                            'linear': linear.state_dict()},\n",
    "                       f=f'test_then_delete/ViT_IN1k_muscle_{base_lr}.pt')\n",
    "            \n",
    "            d = {'Learning Rate': base_lr, 'Epoch': epoch, 'Train Loss': train_losses, 'Val mIoU': val_miou, \n",
    "                 'Test mIoU': test_miou}\n",
    "            model_info_df = pd.concat([model_info_df, pd.DataFrame([d])], ignore_index=True)\n",
    "            \n",
    "            num_down = 0\n",
    "        else:\n",
    "            num_down += 1\n",
    "\n",
    "        # write to logs\n",
    "        with open(f'ViT_IN1k_muscle_logs_{base_lr}.csv', 'a', errors=\"ignore\") as out_file:\n",
    "            csv_writer = csv.writer(out_file, delimiter=',', lineterminator='\\n')\n",
    "            csv_writer.writerow([epoch, train_losses, val_miou, test_miou, best_val_miou, current_lr_backbone, current_lr_head, base_lr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84514e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_miou_per_lr = model_info_df.groupby('Learning Rate')['Val mIoU'].transform('max')\n",
    "max_rows = model_info_df[model_info_df['Val mIoU'] == max_miou_per_lr]\n",
    "max_rows.to_csv(\"test_then_delete/ViT_IN1k_muscle_logs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53b017a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info_df.to_csv(\"test_then_delete/ViT_IN1k_muscle_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11367772",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = get_model_info_df.iloc[get_model_info_df['Val mIoU'].idxmax()]\n",
    "best.to_csv(\"delete.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "db6f9915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base Learning Rate</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Val mIoU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.9200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.3540</td>\n",
       "      <td>0.8300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.8797</td>\n",
       "      <td>0.6789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.7900</td>\n",
       "      <td>0.6700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00020</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>0.5700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00050</td>\n",
       "      <td>0.7689</td>\n",
       "      <td>0.5679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.6780</td>\n",
       "      <td>0.6234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Base Learning Rate  Train Loss  Val mIoU\n",
       "0             0.00001      0.9990    0.9200\n",
       "1             0.00001      0.3540    0.8300\n",
       "2             0.00005      0.8797    0.6789\n",
       "3             0.00008      0.7900    0.6700\n",
       "4             0.00010      1.0000    0.4360\n",
       "5             0.00020      3.0000    0.5700\n",
       "6             0.00050      0.7689    0.5679\n",
       "7             0.00100      0.6780    0.6234"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_lr = [1e-5, 1e-5, 5e-5, 8e-5, 1e-4, 2e-4, 5e-4, 1e-3]\n",
    "train_loss = [0.999, 0.354, 0.8797, 0.79, 1, 3, 0.7689, 0.678]\n",
    "val_miou = [0.92, 0.83, 0.6789, 0.67, 0.436, 0.57, 0.5679, 0.6234]\n",
    "\n",
    "d = {'Base Learning Rate': base_lr, 'Train Loss': train_loss, 'Val mIoU': val_miou}\n",
    "\n",
    "get_model_info_df = pd.DataFrame(data=d)\n",
    "get_model_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "78278d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Base Learning Rate', 'Train Loss', 'Val mIoU', 'Test mIoU']\n",
    "model_info_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for i in range(4):\n",
    "    \n",
    "    d = {'Base Learning Rate': base_lr[i], \n",
    "             'Train Loss': train_loss[i], \n",
    "             'Val mIoU': val_miou[i]}\n",
    "    model_info_df = pd.concat([model_info_df, pd.DataFrame([d])], ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1fcfd6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base Learning Rate</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Val mIoU</th>\n",
       "      <th>Test mIoU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.9200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.3540</td>\n",
       "      <td>0.8300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.8797</td>\n",
       "      <td>0.6789</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.7900</td>\n",
       "      <td>0.6700</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Base Learning Rate  Train Loss  Val mIoU Test mIoU\n",
       "0             0.00001      0.9990    0.9200       NaN\n",
       "1             0.00001      0.3540    0.8300       NaN\n",
       "2             0.00005      0.8797    0.6789       NaN\n",
       "3             0.00008      0.7900    0.6700       NaN"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "65394726",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info_df.to_csv(\"delete.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c139d01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-05\n",
      "1e-05\n",
      "5e-05\n",
      "8e-05\n"
     ]
    }
   ],
   "source": [
    "for i in model_info_df['Base Learning Rate']:\n",
    "    print(i)\n",
    "    best = model_info_df['Val mIoU'].loc[i]\n",
    "    print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d1ca57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
