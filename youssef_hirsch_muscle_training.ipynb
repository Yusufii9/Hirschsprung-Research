{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b550615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import transforms, utils\n",
    "from einops import rearrange\n",
    "import os\n",
    "from torchvision.transforms import RandomRotation\n",
    "import math\n",
    "import csv\n",
    "#from histo_vit import vit_small\n",
    "import random\n",
    "from torchvision.transforms.functional import hflip\n",
    "from torchvision.transforms.functional import vflip\n",
    "#import segmenter\n",
    "import og_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31455816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image_with_map(_img, _map):\n",
    "    side_outer = 512\n",
    "    angle = torch.randint(low=1, high=90, size=(1,)).item()\n",
    "    \n",
    "    aug1 = torch.nn.Sequential(RandomRotation((angle, angle)))\n",
    "    \n",
    "    side_inner = side_outer / (math.cos(math.radians(angle)) + math.sin(math.radians(angle)))\n",
    "    print(f\"The new h and w are: {side_inner}\")\n",
    "    \n",
    "    state = torch.get_rng_state()\n",
    "    _img = aug1(_img)\n",
    "\n",
    "    torch.set_rng_state(state)\n",
    "    _map = aug1(_map)\n",
    "    \n",
    "    center_x = side_outer // 2\n",
    "    center_y = side_outer // 2\n",
    "\n",
    "    half_width = side_inner // 2\n",
    "    half_height = side_inner // 2 \n",
    "\n",
    "    start_x = round(center_x - half_width)\n",
    "    end_x = round(center_x + half_width)\n",
    "    start_y = round(center_y - half_height)\n",
    "    end_y = round(center_y + half_height)\n",
    "\n",
    "    _img = _img[:, start_y:end_y, start_x:end_x]\n",
    "    _map = _map[:, start_y:end_y, start_x:end_x]\n",
    "    \n",
    "    aug2 = torch.nn.Sequential(\n",
    "    RandomHorizontalFlip(p=0.5),\n",
    "    RandomVerticalFlip(p=0.5),\n",
    "    RandomResizedCrop(size=(224, 224), scale=(0.5, 2.0)))\n",
    "    \n",
    "    state = torch.get_rng_state()\n",
    "    _img = aug2(_img)\n",
    "\n",
    "    torch.set_rng_state(state)\n",
    "    _map = aug2(_map)\n",
    "    \n",
    "    \n",
    "    return _img, _map\n",
    "\n",
    "\n",
    "\n",
    "# def augment_image_with_map(_img, _map):\n",
    "#     x_start = torch.randint(low=0, high=(256-224), size=(1,)).item()\n",
    "#     y_start = torch.randint(low=0, high=(256-224), size=(1,)).item()\n",
    "#     _img = _img[:, :, x_start:(x_start + 224), y_start:(y_start + 224)]\n",
    "#     _map = _map[:, x_start:(x_start + 224), y_start:(y_start + 224)]\n",
    "\n",
    "#     if torch.rand(1).item() < 0.5:\n",
    "#         _img = hflip(_img)  # horizontal flip\n",
    "#         _map = hflip(_map)  # horizontal flip\n",
    "\n",
    "#     if torch.rand(1).item() < 0.5:\n",
    "#         _img = vflip(_img)  # vertical flip\n",
    "#         _map = vflip(_map)  # vertical flip\n",
    "\n",
    "#     random_rotation = random.choice([RandomRotation((0, 0)),\n",
    "#                                      RandomRotation((90, 90)),\n",
    "#                                      RandomRotation((-90, -90)),\n",
    "#                                      RandomRotation((180, 180))])\n",
    "\n",
    "#     _img = random_rotation(_img)  # rotate\n",
    "#     _map = random_rotation(_map)  # rotate\n",
    "#     return _img, _map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67af8e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(epoch, sched_config):\n",
    "    \"\"\"Decay the learning rate with half-cycle cosine after warmup\"\"\"\n",
    "    if epoch < sched_config['warmup_epochs']:\n",
    "        lr = sched_config['lr'] * epoch / sched_config['warmup_epochs']\n",
    "    else:\n",
    "        lr = sched_config['min_lr'] + (sched_config['lr'] - sched_config['min_lr']) * 0.5 * \\\n",
    "            (1. + math.cos(math.pi * (epoch - sched_config['warmup_epochs']) / (sched_config['epochs'] - sched_config['warmup_epochs'])))\n",
    "    return lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96c042bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "        for param_group in optimizer.param_groups:\n",
    "            return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c1389a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = ['S14-580.pt',\n",
    "              'S00-1910.pt',\n",
    "              'S02-410.pt',\n",
    "              'S02-484.pt',\n",
    "              'S03-2391.pt',\n",
    "              'S01-18.pt',\n",
    "              \"S03-3178 D2.pt\",\n",
    "              \"S03-3178 D3.pt\",\n",
    "              \"S03-3178 D4.pt\",\n",
    "              'S04-52.pt',\n",
    "              'S04-910.pt',\n",
    "              'S07-1808.pt',\n",
    "              'S08-2215.pt',\n",
    "              'S09-2723.pt',\n",
    "              'S04-1840.pt',\n",
    "              'S07-1465.pt',\n",
    "              'S14-1715.pt',\n",
    "              'S09-2909.pt',\n",
    "              'S14-3414.pt',\n",
    "              'S14-2038.pt',\n",
    "              'S15-1442.pt',\n",
    "              'S15-1518.pt',\n",
    "              'S16-567.pt',\n",
    "              \"S16-1197 B1.pt\",\n",
    "              'S11-1760.pt',\n",
    "              'S16-1467.pt',\n",
    "              \"S16-1197 B3.pt\",\n",
    "              \"S16-1197 B2.pt\",\n",
    "              'S97-2054.pt',\n",
    "              'S16-1415.pt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2a5c770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fold: 0\n",
      "torch.Size([48000, 3, 256, 256]) torch.Size([48000, 256, 256])\n",
      "torch.Size([12000, 3, 256, 256]) torch.Size([12000, 256, 256])\n",
      "Epoch: 0, Train Loss: 1.2739686965942383, Val Loss: 1.274187445640564, LR Backbone: 0.0, LR Head: 0.0,\n",
      "SAVING\n",
      "Epoch: 1, Train Loss: 0.1454479992389679, Val Loss: 0.05487304553389549, LR Backbone: 7.500000000000001e-06, LR Head: 7.500000000000001e-06,\n",
      "SAVING\n",
      "Epoch: 2, Train Loss: 0.04395141452550888, Val Loss: 0.037751954048871994, LR Backbone: 1.5000000000000002e-05, LR Head: 1.5000000000000002e-05,\n",
      "SAVING\n",
      "Epoch: 3, Train Loss: 0.03577282652258873, Val Loss: 0.03147949278354645, LR Backbone: 2.25e-05, LR Head: 2.25e-05,\n",
      "SAVING\n",
      "Epoch: 4, Train Loss: 0.031036376953125, Val Loss: 0.028806639835238457, LR Backbone: 3.0000000000000004e-05, LR Head: 3.0000000000000004e-05,\n",
      "SAVING\n",
      "Epoch: 5, Train Loss: 0.02903076261281967, Val Loss: 0.030205322429537773, LR Backbone: 3.7500000000000003e-05, LR Head: 3.7500000000000003e-05,\n",
      "Epoch: 6, Train Loss: 0.025585083290934563, Val Loss: 0.027611328288912773, LR Backbone: 3.745432594237171e-05, LR Head: 3.745432594237171e-05,\n",
      "SAVING\n",
      "Epoch: 7, Train Loss: 0.0244145505130291, Val Loss: 0.029830321669578552, LR Backbone: 3.731752628890445e-05, LR Head: 3.731752628890445e-05,\n",
      "Epoch: 8, Train Loss: 0.023370178416371346, Val Loss: 0.027253661304712296, LR Backbone: 3.709026751375886e-05, LR Head: 3.709026751375886e-05,\n",
      "SAVING\n",
      "Epoch: 9, Train Loss: 0.024176940321922302, Val Loss: 0.027076659724116325, LR Backbone: 3.6773656798843484e-05, LR Head: 3.6773656798843484e-05,\n",
      "SAVING\n",
      "Epoch: 10, Train Loss: 0.021611817181110382, Val Loss: 0.028203614056110382, LR Backbone: 3.6369236639735785e-05, LR Head: 3.6369236639735785e-05,\n",
      "Epoch: 11, Train Loss: 0.019705994054675102, Val Loss: 0.025414306670427322, LR Backbone: 3.587897733079877e-05, LR Head: 3.587897733079877e-05,\n",
      "SAVING\n",
      "Epoch: 12, Train Loss: 0.02117907628417015, Val Loss: 0.024330809712409973, LR Backbone: 3.5305267366104884e-05, LR Head: 3.5305267366104884e-05,\n",
      "SAVING\n",
      "Epoch: 13, Train Loss: 0.01962152123451233, Val Loss: 0.02637036144733429, LR Backbone: 3.465090180293299e-05, LR Head: 3.465090180293299e-05,\n",
      "Epoch: 14, Train Loss: 0.0192792359739542, Val Loss: 0.025633545592427254, LR Backbone: 3.391906864453027e-05, LR Head: 3.391906864453027e-05,\n",
      "Epoch: 15, Train Loss: 0.018994994461536407, Val Loss: 0.03206836059689522, LR Backbone: 3.311333330848084e-05, LR Head: 3.311333330848084e-05,\n",
      "Epoch: 16, Train Loss: 0.018430419266223907, Val Loss: 0.027200927957892418, LR Backbone: 3.223762125634971e-05, LR Head: 3.223762125634971e-05,\n",
      "Epoch: 17, Train Loss: 0.018013793975114822, Val Loss: 0.027946533635258675, LR Backbone: 3.129619886922859e-05, LR Head: 3.129619886922859e-05,\n",
      "Epoch: 18, Train Loss: 0.017065245658159256, Val Loss: 0.023546386510133743, LR Backbone: 3.0293652662356095e-05, LR Head: 3.0293652662356095e-05,\n",
      "SAVING\n",
      "Epoch: 19, Train Loss: 0.016898559406399727, Val Loss: 0.025572998449206352, LR Backbone: 2.9234866940076505e-05, LR Head: 2.9234866940076505e-05,\n",
      "Epoch: 20, Train Loss: 0.01626293919980526, Val Loss: 0.024012451991438866, LR Backbone: 2.8125000000000003e-05, LR Head: 2.8125000000000003e-05,\n",
      "Epoch: 21, Train Loss: 0.016005737707018852, Val Loss: 0.02518041990697384, LR Backbone: 2.6969459002295203e-05, LR Head: 2.6969459002295203e-05,\n",
      "Epoch: 22, Train Loss: 0.016062622889876366, Val Loss: 0.026737304404377937, LR Backbone: 2.577387362654835e-05, LR Head: 2.577387362654835e-05,\n",
      "Epoch: 23, Train Loss: 0.014973632991313934, Val Loss: 0.025943603366613388, LR Backbone: 2.4544068644530267e-05, LR Head: 2.4544068644530267e-05,\n",
      "Epoch: 24, Train Loss: 0.01369699090719223, Val Loss: 0.025727538391947746, LR Backbone: 2.3286035542493773e-05, LR Head: 2.3286035542493773e-05,\n",
      "Epoch: 25, Train Loss: 0.015036865137517452, Val Loss: 0.031254637986421585, LR Backbone: 2.200590333125495e-05, LR Head: 2.200590333125495e-05,\n",
      "Epoch: 26, Train Loss: 0.013619812205433846, Val Loss: 0.026325196027755737, LR Backbone: 2.0709908686268504e-05, LR Head: 2.0709908686268504e-05,\n",
      "Epoch: 27, Train Loss: 0.013827514834702015, Val Loss: 0.024492431432008743, LR Backbone: 1.94043655631719e-05, LR Head: 1.94043655631719e-05,\n",
      "Epoch: 28, Train Loss: 0.012961517088115215, Val Loss: 0.025142578408122063, LR Backbone: 1.8095634436828114e-05, LR Head: 1.8095634436828114e-05,\n",
      "Epoch: 29, Train Loss: 0.01303710974752903, Val Loss: 0.026604004204273224, LR Backbone: 1.6790091313731502e-05, LR Head: 1.6790091313731502e-05,\n",
      "Epoch: 30, Train Loss: 0.012202209793031216, Val Loss: 0.025408202782273293, LR Backbone: 1.549409666874506e-05, LR Head: 1.549409666874506e-05,\n",
      "Epoch: 31, Train Loss: 0.012602722272276878, Val Loss: 0.0267949216067791, LR Backbone: 1.421396445750623e-05, LR Head: 1.421396445750623e-05,\n",
      "Epoch: 32, Train Loss: 0.011692962609231472, Val Loss: 0.024459227919578552, LR Backbone: 1.2955931355469738e-05, LR Head: 1.2955931355469738e-05,\n",
      "Epoch: 33, Train Loss: 0.01172320544719696, Val Loss: 0.027202391996979713, LR Backbone: 1.172612637345165e-05, LR Head: 1.172612637345165e-05,\n",
      "Epoch: 34, Train Loss: 0.011326354928314686, Val Loss: 0.02449023351073265, LR Backbone: 1.0530540997704797e-05, LR Head: 1.0530540997704797e-05,\n",
      "Epoch: 35, Train Loss: 0.011493286117911339, Val Loss: 0.026189209893345833, LR Backbone: 9.375000000000004e-06, LR Head: 9.375000000000004e-06,\n",
      "Epoch: 36, Train Loss: 0.010967285372316837, Val Loss: 0.026659423485398293, LR Backbone: 8.2651330599235e-06, LR Head: 8.2651330599235e-06,\n",
      "Epoch: 37, Train Loss: 0.01095135509967804, Val Loss: 0.026085693389177322, LR Backbone: 7.206347337643908e-06, LR Head: 7.206347337643908e-06,\n",
      "Epoch: 38, Train Loss: 0.010609008371829987, Val Loss: 0.026092529296875, LR Backbone: 6.2038011307714084e-06, LR Head: 6.2038011307714084e-06,\n",
      "Starting fold: 1\n",
      "torch.Size([48000, 3, 256, 256]) torch.Size([48000, 256, 256])\n",
      "torch.Size([12000, 3, 256, 256]) torch.Size([12000, 256, 256])\n",
      "Epoch: 0, Train Loss: 1.250406265258789, Val Loss: 1.251562476158142, LR Backbone: 0.0, LR Head: 0.0,\n",
      "SAVING\n",
      "Epoch: 1, Train Loss: 0.13488158583641052, Val Loss: 0.06370410323143005, LR Backbone: 7.500000000000001e-06, LR Head: 7.500000000000001e-06,\n",
      "SAVING\n",
      "Epoch: 2, Train Loss: 0.039400145411491394, Val Loss: 0.053794920444488525, LR Backbone: 1.5000000000000002e-05, LR Head: 1.5000000000000002e-05,\n",
      "SAVING\n",
      "Epoch: 3, Train Loss: 0.03240661695599556, Val Loss: 0.0405571274459362, LR Backbone: 2.25e-05, LR Head: 2.25e-05,\n",
      "SAVING\n",
      "Epoch: 4, Train Loss: 0.034889038652181625, Val Loss: 0.03971923887729645, LR Backbone: 3.0000000000000004e-05, LR Head: 3.0000000000000004e-05,\n",
      "SAVING\n",
      "Epoch: 5, Train Loss: 0.026957398280501366, Val Loss: 0.04049121215939522, LR Backbone: 3.7500000000000003e-05, LR Head: 3.7500000000000003e-05,\n",
      "Epoch: 6, Train Loss: 0.025073181837797165, Val Loss: 0.03794677555561066, LR Backbone: 3.745432594237171e-05, LR Head: 3.745432594237171e-05,\n",
      "SAVING\n",
      "Epoch: 7, Train Loss: 0.022650573402643204, Val Loss: 0.036299318075180054, LR Backbone: 3.731752628890445e-05, LR Head: 3.731752628890445e-05,\n",
      "SAVING\n",
      "Epoch: 8, Train Loss: 0.022406738251447678, Val Loss: 0.034782715141773224, LR Backbone: 3.709026751375886e-05, LR Head: 3.709026751375886e-05,\n",
      "SAVING\n",
      "Epoch: 9, Train Loss: 0.020909423008561134, Val Loss: 0.04467480629682541, LR Backbone: 3.6773656798843484e-05, LR Head: 3.6773656798843484e-05,\n",
      "Epoch: 10, Train Loss: 0.020308716222643852, Val Loss: 0.0384824201464653, LR Backbone: 3.6369236639735785e-05, LR Head: 3.6369236639735785e-05,\n",
      "Epoch: 11, Train Loss: 0.023928223177790642, Val Loss: 0.034364745020866394, LR Backbone: 3.587897733079877e-05, LR Head: 3.587897733079877e-05,\n",
      "SAVING\n",
      "Epoch: 12, Train Loss: 0.01999511756002903, Val Loss: 0.05116504058241844, LR Backbone: 3.5305267366104884e-05, LR Head: 3.5305267366104884e-05,\n",
      "Epoch: 13, Train Loss: 0.01862371899187565, Val Loss: 0.03775708004832268, LR Backbone: 3.465090180293299e-05, LR Head: 3.465090180293299e-05,\n",
      "Epoch: 14, Train Loss: 0.0185848381370306, Val Loss: 0.03599316254258156, LR Backbone: 3.391906864453027e-05, LR Head: 3.391906864453027e-05,\n",
      "Epoch: 15, Train Loss: 0.01810900866985321, Val Loss: 0.03816894441843033, LR Backbone: 3.311333330848084e-05, LR Head: 3.311333330848084e-05,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Train Loss: 0.016929564997553825, Val Loss: 0.039115723222494125, LR Backbone: 3.223762125634971e-05, LR Head: 3.223762125634971e-05,\n",
      "Epoch: 17, Train Loss: 0.024095946922898293, Val Loss: 0.03681640699505806, LR Backbone: 3.129619886922859e-05, LR Head: 3.129619886922859e-05,\n",
      "Epoch: 18, Train Loss: 0.01735791005194187, Val Loss: 0.05097753927111626, LR Backbone: 3.0293652662356095e-05, LR Head: 3.0293652662356095e-05,\n",
      "Epoch: 19, Train Loss: 0.01697210781276226, Val Loss: 0.04170214757323265, LR Backbone: 2.9234866940076505e-05, LR Head: 2.9234866940076505e-05,\n",
      "Epoch: 20, Train Loss: 0.01596960425376892, Val Loss: 0.03465014696121216, LR Backbone: 2.8125000000000003e-05, LR Head: 2.8125000000000003e-05,\n",
      "Epoch: 21, Train Loss: 0.015120788477361202, Val Loss: 0.03492016717791557, LR Backbone: 2.6969459002295203e-05, LR Head: 2.6969459002295203e-05,\n",
      "Epoch: 22, Train Loss: 0.01493981946259737, Val Loss: 0.03475146368145943, LR Backbone: 2.577387362654835e-05, LR Head: 2.577387362654835e-05,\n",
      "Epoch: 23, Train Loss: 0.015701843425631523, Val Loss: 0.0357973650097847, LR Backbone: 2.4544068644530267e-05, LR Head: 2.4544068644530267e-05,\n",
      "Epoch: 24, Train Loss: 0.015113281086087227, Val Loss: 0.04234130680561066, LR Backbone: 2.3286035542493773e-05, LR Head: 2.3286035542493773e-05,\n",
      "Epoch: 25, Train Loss: 0.015233703888952732, Val Loss: 0.04144873097538948, LR Backbone: 2.200590333125495e-05, LR Head: 2.200590333125495e-05,\n",
      "Epoch: 26, Train Loss: 0.013813965022563934, Val Loss: 0.037187255918979645, LR Backbone: 2.0709908686268504e-05, LR Head: 2.0709908686268504e-05,\n",
      "Epoch: 27, Train Loss: 0.013736572116613388, Val Loss: 0.03648583963513374, LR Backbone: 1.94043655631719e-05, LR Head: 1.94043655631719e-05,\n",
      "Epoch: 28, Train Loss: 0.013447479344904423, Val Loss: 0.037379395216703415, LR Backbone: 1.8095634436828114e-05, LR Head: 1.8095634436828114e-05,\n",
      "Epoch: 29, Train Loss: 0.012949157506227493, Val Loss: 0.039728760719299316, LR Backbone: 1.6790091313731502e-05, LR Head: 1.6790091313731502e-05,\n",
      "Epoch: 30, Train Loss: 0.013035827316343784, Val Loss: 0.03693774342536926, LR Backbone: 1.549409666874506e-05, LR Head: 1.549409666874506e-05,\n",
      "Epoch: 31, Train Loss: 0.012558593414723873, Val Loss: 0.040043700486421585, LR Backbone: 1.421396445750623e-05, LR Head: 1.421396445750623e-05,\n",
      "Starting fold: 2\n",
      "torch.Size([48000, 3, 256, 256]) torch.Size([48000, 256, 256])\n",
      "torch.Size([12000, 3, 256, 256]) torch.Size([12000, 256, 256])\n",
      "Epoch: 0, Train Loss: 1.2345625162124634, Val Loss: 1.233875036239624, LR Backbone: 0.0, LR Head: 0.0,\n",
      "SAVING\n",
      "Epoch: 1, Train Loss: 0.12721142172813416, Val Loss: 0.05714355409145355, LR Backbone: 7.500000000000001e-06, LR Head: 7.500000000000001e-06,\n",
      "SAVING\n",
      "Epoch: 2, Train Loss: 0.039533935487270355, Val Loss: 0.03652270510792732, LR Backbone: 1.5000000000000002e-05, LR Head: 1.5000000000000002e-05,\n",
      "SAVING\n",
      "Epoch: 3, Train Loss: 0.03372131288051605, Val Loss: 0.029719971120357513, LR Backbone: 2.25e-05, LR Head: 2.25e-05,\n",
      "SAVING\n",
      "Epoch: 4, Train Loss: 0.0307622067630291, Val Loss: 0.03453613445162773, LR Backbone: 3.0000000000000004e-05, LR Head: 3.0000000000000004e-05,\n",
      "Epoch: 5, Train Loss: 0.03330151364207268, Val Loss: 0.0361323244869709, LR Backbone: 3.7500000000000003e-05, LR Head: 3.7500000000000003e-05,\n",
      "Epoch: 6, Train Loss: 0.02500738576054573, Val Loss: 0.03153320401906967, LR Backbone: 3.745432594237171e-05, LR Head: 3.745432594237171e-05,\n",
      "Epoch: 7, Train Loss: 0.022787047550082207, Val Loss: 0.02742321789264679, LR Backbone: 3.731752628890445e-05, LR Head: 3.731752628890445e-05,\n",
      "SAVING\n",
      "Epoch: 8, Train Loss: 0.023022888228297234, Val Loss: 0.03782861307263374, LR Backbone: 3.709026751375886e-05, LR Head: 3.709026751375886e-05,\n",
      "Epoch: 9, Train Loss: 0.021719666197896004, Val Loss: 0.0299077145755291, LR Backbone: 3.6773656798843484e-05, LR Head: 3.6773656798843484e-05,\n",
      "Epoch: 10, Train Loss: 0.020479125902056694, Val Loss: 0.04118701070547104, LR Backbone: 3.6369236639735785e-05, LR Head: 3.6369236639735785e-05,\n",
      "Epoch: 11, Train Loss: 0.02155395597219467, Val Loss: 0.047993406653404236, LR Backbone: 3.587897733079877e-05, LR Head: 3.587897733079877e-05,\n",
      "Epoch: 12, Train Loss: 0.020726623013615608, Val Loss: 0.031070556491613388, LR Backbone: 3.5305267366104884e-05, LR Head: 3.5305267366104884e-05,\n",
      "Epoch: 13, Train Loss: 0.020021788775920868, Val Loss: 0.03412256017327309, LR Backbone: 3.465090180293299e-05, LR Head: 3.465090180293299e-05,\n",
      "Epoch: 14, Train Loss: 0.01982928439974785, Val Loss: 0.0699155256152153, LR Backbone: 3.391906864453027e-05, LR Head: 3.391906864453027e-05,\n",
      "Epoch: 15, Train Loss: 0.018404662609100342, Val Loss: 0.05892382934689522, LR Backbone: 3.311333330848084e-05, LR Head: 3.311333330848084e-05,\n",
      "Epoch: 16, Train Loss: 0.019312439486384392, Val Loss: 0.030118651688098907, LR Backbone: 3.223762125634971e-05, LR Head: 3.223762125634971e-05,\n",
      "Epoch: 17, Train Loss: 0.017543334513902664, Val Loss: 0.0372626967728138, LR Backbone: 3.129619886922859e-05, LR Head: 3.129619886922859e-05,\n",
      "Epoch: 18, Train Loss: 0.017522644251585007, Val Loss: 0.025648193433880806, LR Backbone: 3.0293652662356095e-05, LR Head: 3.0293652662356095e-05,\n",
      "SAVING\n",
      "Epoch: 19, Train Loss: 0.017477478832006454, Val Loss: 0.028447264805436134, LR Backbone: 2.9234866940076505e-05, LR Head: 2.9234866940076505e-05,\n",
      "Epoch: 20, Train Loss: 0.01673547364771366, Val Loss: 0.026152100414037704, LR Backbone: 2.8125000000000003e-05, LR Head: 2.8125000000000003e-05,\n",
      "Epoch: 21, Train Loss: 0.015707459300756454, Val Loss: 0.03066394105553627, LR Backbone: 2.6969459002295203e-05, LR Head: 2.6969459002295203e-05,\n",
      "Epoch: 22, Train Loss: 0.015355652198195457, Val Loss: 0.03668554872274399, LR Backbone: 2.577387362654835e-05, LR Head: 2.577387362654835e-05,\n",
      "Epoch: 23, Train Loss: 0.014969268813729286, Val Loss: 0.04151294007897377, LR Backbone: 2.4544068644530267e-05, LR Head: 2.4544068644530267e-05,\n",
      "Epoch: 24, Train Loss: 0.015464416705071926, Val Loss: 0.03147277981042862, LR Backbone: 2.3286035542493773e-05, LR Head: 2.3286035542493773e-05,\n",
      "Epoch: 25, Train Loss: 0.014589324593544006, Val Loss: 0.03352075070142746, LR Backbone: 2.200590333125495e-05, LR Head: 2.200590333125495e-05,\n",
      "Epoch: 26, Train Loss: 0.014013366773724556, Val Loss: 0.029731445014476776, LR Backbone: 2.0709908686268504e-05, LR Head: 2.0709908686268504e-05,\n",
      "Epoch: 27, Train Loss: 0.014848876744508743, Val Loss: 0.03406689316034317, LR Backbone: 1.94043655631719e-05, LR Head: 1.94043655631719e-05,\n",
      "Epoch: 28, Train Loss: 0.013289428316056728, Val Loss: 0.031895995140075684, LR Backbone: 1.8095634436828114e-05, LR Head: 1.8095634436828114e-05,\n",
      "Epoch: 29, Train Loss: 0.0131452027708292, Val Loss: 0.03996948152780533, LR Backbone: 1.6790091313731502e-05, LR Head: 1.6790091313731502e-05,\n",
      "Epoch: 30, Train Loss: 0.012519195675849915, Val Loss: 0.04522912576794624, LR Backbone: 1.549409666874506e-05, LR Head: 1.549409666874506e-05,\n",
      "Epoch: 31, Train Loss: 0.013794677332043648, Val Loss: 0.04897985979914665, LR Backbone: 1.421396445750623e-05, LR Head: 1.421396445750623e-05,\n",
      "Epoch: 32, Train Loss: 0.012178100645542145, Val Loss: 0.04986938461661339, LR Backbone: 1.2955931355469738e-05, LR Head: 1.2955931355469738e-05,\n",
      "Epoch: 33, Train Loss: 0.012194336391985416, Val Loss: 0.035765137523412704, LR Backbone: 1.172612637345165e-05, LR Head: 1.172612637345165e-05,\n",
      "Epoch: 34, Train Loss: 0.01200122106820345, Val Loss: 0.05397924780845642, LR Backbone: 1.0530540997704797e-05, LR Head: 1.0530540997704797e-05,\n",
      "Epoch: 35, Train Loss: 0.011955413967370987, Val Loss: 0.03829394653439522, LR Backbone: 9.375000000000004e-06, LR Head: 9.375000000000004e-06,\n",
      "Epoch: 36, Train Loss: 0.011456634849309921, Val Loss: 0.04896154627203941, LR Backbone: 8.2651330599235e-06, LR Head: 8.2651330599235e-06,\n",
      "Epoch: 37, Train Loss: 0.01120928954333067, Val Loss: 0.03719824180006981, LR Backbone: 7.206347337643908e-06, LR Head: 7.206347337643908e-06,\n",
      "Epoch: 38, Train Loss: 0.011117920279502869, Val Loss: 0.03788086026906967, LR Backbone: 6.2038011307714084e-06, LR Head: 6.2038011307714084e-06,\n",
      "Starting fold: 3\n",
      "torch.Size([48000, 3, 256, 256]) torch.Size([48000, 256, 256])\n",
      "torch.Size([12000, 3, 256, 256]) torch.Size([12000, 256, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 1.2991719245910645, Val Loss: 1.2988125085830688, LR Backbone: 0.0, LR Head: 0.0,\n",
      "SAVING\n",
      "Epoch: 1, Train Loss: 0.1434931606054306, Val Loss: 0.0610341802239418, LR Backbone: 7.500000000000001e-06, LR Head: 7.500000000000001e-06,\n",
      "SAVING\n",
      "Epoch: 2, Train Loss: 0.04421301186084747, Val Loss: 0.056892577558755875, LR Backbone: 1.5000000000000002e-05, LR Head: 1.5000000000000002e-05,\n",
      "SAVING\n",
      "Epoch: 3, Train Loss: 0.03858136013150215, Val Loss: 0.03274316340684891, LR Backbone: 2.25e-05, LR Head: 2.25e-05,\n",
      "SAVING\n",
      "Epoch: 4, Train Loss: 0.03397534042596817, Val Loss: 0.03163720667362213, LR Backbone: 3.0000000000000004e-05, LR Head: 3.0000000000000004e-05,\n",
      "SAVING\n",
      "Epoch: 5, Train Loss: 0.03041253611445427, Val Loss: 0.02798193320631981, LR Backbone: 3.7500000000000003e-05, LR Head: 3.7500000000000003e-05,\n",
      "SAVING\n",
      "Epoch: 6, Train Loss: 0.02829202264547348, Val Loss: 0.026553954929113388, LR Backbone: 3.745432594237171e-05, LR Head: 3.745432594237171e-05,\n",
      "SAVING\n",
      "Epoch: 7, Train Loss: 0.029425842687487602, Val Loss: 0.030765624716877937, LR Backbone: 3.731752628890445e-05, LR Head: 3.731752628890445e-05,\n",
      "Epoch: 8, Train Loss: 0.025166260078549385, Val Loss: 0.030875489115715027, LR Backbone: 3.709026751375886e-05, LR Head: 3.709026751375886e-05,\n",
      "Epoch: 9, Train Loss: 0.022992003709077835, Val Loss: 0.024000000208616257, LR Backbone: 3.6773656798843484e-05, LR Head: 3.6773656798843484e-05,\n",
      "SAVING\n",
      "Epoch: 10, Train Loss: 0.02155761793255806, Val Loss: 0.02366967685520649, LR Backbone: 3.6369236639735785e-05, LR Head: 3.6369236639735785e-05,\n",
      "SAVING\n",
      "Epoch: 11, Train Loss: 0.022913208231329918, Val Loss: 0.023957274854183197, LR Backbone: 3.587897733079877e-05, LR Head: 3.587897733079877e-05,\n",
      "Epoch: 12, Train Loss: 0.021366393193602562, Val Loss: 0.025391357019543648, LR Backbone: 3.5305267366104884e-05, LR Head: 3.5305267366104884e-05,\n",
      "Epoch: 13, Train Loss: 0.020871398970484734, Val Loss: 0.02216528356075287, LR Backbone: 3.465090180293299e-05, LR Head: 3.465090180293299e-05,\n",
      "SAVING\n",
      "Epoch: 14, Train Loss: 0.019582398235797882, Val Loss: 0.023957030847668648, LR Backbone: 3.391906864453027e-05, LR Head: 3.391906864453027e-05,\n",
      "Epoch: 15, Train Loss: 0.02146276831626892, Val Loss: 0.02333666943013668, LR Backbone: 3.311333330848084e-05, LR Head: 3.311333330848084e-05,\n",
      "Epoch: 16, Train Loss: 0.018760254606604576, Val Loss: 0.02350122109055519, LR Backbone: 3.223762125634971e-05, LR Head: 3.223762125634971e-05,\n",
      "Epoch: 17, Train Loss: 0.018248047679662704, Val Loss: 0.022435791790485382, LR Backbone: 3.129619886922859e-05, LR Head: 3.129619886922859e-05,\n",
      "Epoch: 18, Train Loss: 0.0184626467525959, Val Loss: 0.021989990025758743, LR Backbone: 3.0293652662356095e-05, LR Head: 3.0293652662356095e-05,\n",
      "SAVING\n",
      "Epoch: 19, Train Loss: 0.017975464463233948, Val Loss: 0.022178711369633675, LR Backbone: 2.9234866940076505e-05, LR Head: 2.9234866940076505e-05,\n",
      "Epoch: 20, Train Loss: 0.017506347969174385, Val Loss: 0.02171996980905533, LR Backbone: 2.8125000000000003e-05, LR Head: 2.8125000000000003e-05,\n",
      "SAVING\n",
      "Epoch: 21, Train Loss: 0.01635131798684597, Val Loss: 0.021519042551517487, LR Backbone: 2.6969459002295203e-05, LR Head: 2.6969459002295203e-05,\n",
      "SAVING\n",
      "Epoch: 22, Train Loss: 0.015695495530962944, Val Loss: 0.021482665091753006, LR Backbone: 2.577387362654835e-05, LR Head: 2.577387362654835e-05,\n",
      "SAVING\n",
      "Epoch: 23, Train Loss: 0.015969177708029747, Val Loss: 0.02144799754023552, LR Backbone: 2.4544068644530267e-05, LR Head: 2.4544068644530267e-05,\n",
      "SAVING\n",
      "Epoch: 24, Train Loss: 0.014971436001360416, Val Loss: 0.022887451574206352, LR Backbone: 2.3286035542493773e-05, LR Head: 2.3286035542493773e-05,\n",
      "Epoch: 25, Train Loss: 0.015286682173609734, Val Loss: 0.020350342616438866, LR Backbone: 2.200590333125495e-05, LR Head: 2.200590333125495e-05,\n",
      "SAVING\n",
      "Epoch: 26, Train Loss: 0.015172057785093784, Val Loss: 0.02047143504023552, LR Backbone: 2.0709908686268504e-05, LR Head: 2.0709908686268504e-05,\n",
      "Epoch: 27, Train Loss: 0.013511352241039276, Val Loss: 0.020882079377770424, LR Backbone: 1.94043655631719e-05, LR Head: 1.94043655631719e-05,\n",
      "Epoch: 28, Train Loss: 0.014858398586511612, Val Loss: 0.027146240696310997, LR Backbone: 1.8095634436828114e-05, LR Head: 1.8095634436828114e-05,\n",
      "Epoch: 29, Train Loss: 0.013362365774810314, Val Loss: 0.021128905937075615, LR Backbone: 1.6790091313731502e-05, LR Head: 1.6790091313731502e-05,\n",
      "Epoch: 30, Train Loss: 0.01330242957919836, Val Loss: 0.019951537251472473, LR Backbone: 1.549409666874506e-05, LR Head: 1.549409666874506e-05,\n",
      "SAVING\n",
      "Epoch: 31, Train Loss: 0.012558898888528347, Val Loss: 0.02112475596368313, LR Backbone: 1.421396445750623e-05, LR Head: 1.421396445750623e-05,\n",
      "Epoch: 32, Train Loss: 0.0124895628541708, Val Loss: 0.020754151046276093, LR Backbone: 1.2955931355469738e-05, LR Head: 1.2955931355469738e-05,\n",
      "Epoch: 33, Train Loss: 0.012592162936925888, Val Loss: 0.022090820595622063, LR Backbone: 1.172612637345165e-05, LR Head: 1.172612637345165e-05,\n",
      "Epoch: 34, Train Loss: 0.01198483258485794, Val Loss: 0.02113061584532261, LR Backbone: 1.0530540997704797e-05, LR Head: 1.0530540997704797e-05,\n",
      "Epoch: 35, Train Loss: 0.011866027489304543, Val Loss: 0.021003173664212227, LR Backbone: 9.375000000000004e-06, LR Head: 9.375000000000004e-06,\n",
      "Epoch: 36, Train Loss: 0.01136880461126566, Val Loss: 0.02115185558795929, LR Backbone: 8.2651330599235e-06, LR Head: 8.2651330599235e-06,\n",
      "Epoch: 37, Train Loss: 0.011364501900970936, Val Loss: 0.020911864936351776, LR Backbone: 7.206347337643908e-06, LR Head: 7.206347337643908e-06,\n",
      "Epoch: 38, Train Loss: 0.01119384728372097, Val Loss: 0.0210422370582819, LR Backbone: 6.2038011307714084e-06, LR Head: 6.2038011307714084e-06,\n",
      "Epoch: 39, Train Loss: 0.010965210385620594, Val Loss: 0.021061522886157036, LR Backbone: 5.26237874365029e-06, LR Head: 5.26237874365029e-06,\n",
      "Epoch: 40, Train Loss: 0.010881256312131882, Val Loss: 0.02150561474263668, LR Backbone: 4.3866666915191645e-06, LR Head: 4.3866666915191645e-06,\n",
      "Epoch: 41, Train Loss: 0.010764343664050102, Val Loss: 0.02090185508131981, LR Backbone: 3.5809313554697376e-06, LR Head: 3.5809313554697376e-06,\n",
      "Epoch: 42, Train Loss: 0.010673675686120987, Val Loss: 0.02108471654355526, LR Backbone: 2.8490981970670135e-06, LR Head: 2.8490981970670135e-06,\n",
      "Epoch: 43, Train Loss: 0.01063485722988844, Val Loss: 0.021001221612095833, LR Backbone: 2.1947326338951233e-06, LR Head: 2.1947326338951233e-06,\n",
      "Epoch: 44, Train Loss: 0.010486908257007599, Val Loss: 0.021279051899909973, LR Backbone: 1.621022669201236e-06, LR Head: 1.621022669201236e-06,\n",
      "Epoch: 45, Train Loss: 0.010478698648512363, Val Loss: 0.021289551630616188, LR Backbone: 1.1307633602642191e-06, LR Head: 1.1307633602642191e-06,\n",
      "Epoch: 46, Train Loss: 0.010472900234162807, Val Loss: 0.02163037098944187, LR Backbone: 7.26343201156525e-07, LR Head: 7.26343201156525e-07,\n",
      "Epoch: 47, Train Loss: 0.010373596101999283, Val Loss: 0.021262940019369125, LR Backbone: 4.0973248624114337e-07, LR Head: 4.0973248624114337e-07,\n",
      "Epoch: 48, Train Loss: 0.010373870842158794, Val Loss: 0.021256348118185997, LR Backbone: 1.8247371109555782e-07, LR Head: 1.8247371109555782e-07,\n",
      "Epoch: 49, Train Loss: 0.010463867336511612, Val Loss: 0.021400146186351776, LR Backbone: 4.56740576282963e-08, LR Head: 4.56740576282963e-08,\n",
      "Starting fold: 4\n",
      "torch.Size([48000, 3, 256, 256]) torch.Size([48000, 256, 256])\n",
      "torch.Size([12000, 3, 256, 256]) torch.Size([12000, 256, 256])\n",
      "Epoch: 0, Train Loss: 1.2825312614440918, Val Loss: 1.281499981880188, LR Backbone: 0.0, LR Head: 0.0,\n",
      "SAVING\n",
      "Epoch: 1, Train Loss: 0.15592041611671448, Val Loss: 0.049897462129592896, LR Backbone: 7.500000000000001e-06, LR Head: 7.500000000000001e-06,\n",
      "SAVING\n",
      "Epoch: 2, Train Loss: 0.04526294022798538, Val Loss: 0.05212744325399399, LR Backbone: 1.5000000000000002e-05, LR Head: 1.5000000000000002e-05,\n",
      "Epoch: 3, Train Loss: 0.0372927263379097, Val Loss: 0.03276757895946503, LR Backbone: 2.25e-05, LR Head: 2.25e-05,\n",
      "SAVING\n",
      "Epoch: 4, Train Loss: 0.03436816483736038, Val Loss: 0.028258057311177254, LR Backbone: 3.0000000000000004e-05, LR Head: 3.0000000000000004e-05,\n",
      "SAVING\n",
      "Epoch: 5, Train Loss: 0.030078064650297165, Val Loss: 0.03151635825634003, LR Backbone: 3.7500000000000003e-05, LR Head: 3.7500000000000003e-05,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Train Loss: 0.028734253719449043, Val Loss: 0.027270996943116188, LR Backbone: 3.745432594237171e-05, LR Head: 3.745432594237171e-05,\n",
      "SAVING\n",
      "Epoch: 7, Train Loss: 0.02618725597858429, Val Loss: 0.02649194374680519, LR Backbone: 3.731752628890445e-05, LR Head: 3.731752628890445e-05,\n",
      "SAVING\n",
      "Epoch: 8, Train Loss: 0.024755127727985382, Val Loss: 0.04279540851712227, LR Backbone: 3.709026751375886e-05, LR Head: 3.709026751375886e-05,\n",
      "Epoch: 9, Train Loss: 0.02425878867506981, Val Loss: 0.027224121615290642, LR Backbone: 3.6773656798843484e-05, LR Head: 3.6773656798843484e-05,\n",
      "Epoch: 10, Train Loss: 0.02331274375319481, Val Loss: 0.030298583209514618, LR Backbone: 3.6369236639735785e-05, LR Head: 3.6369236639735785e-05,\n",
      "Epoch: 11, Train Loss: 0.021297607570886612, Val Loss: 0.02840893529355526, LR Backbone: 3.587897733079877e-05, LR Head: 3.587897733079877e-05,\n",
      "Epoch: 12, Train Loss: 0.024414917454123497, Val Loss: 0.025880616158246994, LR Backbone: 3.5305267366104884e-05, LR Head: 3.5305267366104884e-05,\n",
      "SAVING\n",
      "Epoch: 13, Train Loss: 0.019887330010533333, Val Loss: 0.02650109864771366, LR Backbone: 3.465090180293299e-05, LR Head: 3.465090180293299e-05,\n",
      "Epoch: 14, Train Loss: 0.020671386271715164, Val Loss: 0.027182862162590027, LR Backbone: 3.391906864453027e-05, LR Head: 3.391906864453027e-05,\n",
      "Epoch: 15, Train Loss: 0.021949341520667076, Val Loss: 0.026023926213383675, LR Backbone: 3.311333330848084e-05, LR Head: 3.311333330848084e-05,\n",
      "Epoch: 16, Train Loss: 0.01986602693796158, Val Loss: 0.023368896916508675, LR Backbone: 3.223762125634971e-05, LR Head: 3.223762125634971e-05,\n",
      "SAVING\n",
      "Epoch: 17, Train Loss: 0.01871655322611332, Val Loss: 0.025858398526906967, LR Backbone: 3.129619886922859e-05, LR Head: 3.129619886922859e-05,\n",
      "Epoch: 18, Train Loss: 0.018253052607178688, Val Loss: 0.029136352241039276, LR Backbone: 3.0293652662356095e-05, LR Head: 3.0293652662356095e-05,\n",
      "Epoch: 19, Train Loss: 0.018437683582305908, Val Loss: 0.033540282398462296, LR Backbone: 2.9234866940076505e-05, LR Head: 2.9234866940076505e-05,\n",
      "Epoch: 20, Train Loss: 0.01859332248568535, Val Loss: 0.024855224415659904, LR Backbone: 2.8125000000000003e-05, LR Head: 2.8125000000000003e-05,\n",
      "Epoch: 21, Train Loss: 0.016708800569176674, Val Loss: 0.026447022333741188, LR Backbone: 2.6969459002295203e-05, LR Head: 2.6969459002295203e-05,\n",
      "Epoch: 22, Train Loss: 0.01588323898613453, Val Loss: 0.026569824665784836, LR Backbone: 2.577387362654835e-05, LR Head: 2.577387362654835e-05,\n",
      "Epoch: 23, Train Loss: 0.016510985791683197, Val Loss: 0.027143554762005806, LR Backbone: 2.4544068644530267e-05, LR Head: 2.4544068644530267e-05,\n",
      "Epoch: 24, Train Loss: 0.015679748728871346, Val Loss: 0.02765795961022377, LR Backbone: 2.3286035542493773e-05, LR Head: 2.3286035542493773e-05,\n",
      "Epoch: 25, Train Loss: 0.014629760757088661, Val Loss: 0.028699463233351707, LR Backbone: 2.200590333125495e-05, LR Head: 2.200590333125495e-05,\n",
      "Epoch: 26, Train Loss: 0.015110412612557411, Val Loss: 0.02849707007408142, LR Backbone: 2.0709908686268504e-05, LR Head: 2.0709908686268504e-05,\n",
      "Epoch: 27, Train Loss: 0.014207825064659119, Val Loss: 0.028709961101412773, LR Backbone: 1.94043655631719e-05, LR Head: 1.94043655631719e-05,\n",
      "Epoch: 28, Train Loss: 0.013960815034806728, Val Loss: 0.027263183146715164, LR Backbone: 1.8095634436828114e-05, LR Head: 1.8095634436828114e-05,\n",
      "Epoch: 29, Train Loss: 0.013863708823919296, Val Loss: 0.029722290113568306, LR Backbone: 1.6790091313731502e-05, LR Head: 1.6790091313731502e-05,\n",
      "Epoch: 30, Train Loss: 0.013393127359449863, Val Loss: 0.027299804612994194, LR Backbone: 1.549409666874506e-05, LR Head: 1.549409666874506e-05,\n",
      "Epoch: 31, Train Loss: 0.0136415408924222, Val Loss: 0.02906152419745922, LR Backbone: 1.421396445750623e-05, LR Head: 1.421396445750623e-05,\n",
      "Epoch: 32, Train Loss: 0.012817932292819023, Val Loss: 0.02752075158059597, LR Backbone: 1.2955931355469738e-05, LR Head: 1.2955931355469738e-05,\n",
      "Epoch: 33, Train Loss: 0.012663879431784153, Val Loss: 0.028830688446760178, LR Backbone: 1.172612637345165e-05, LR Head: 1.172612637345165e-05,\n",
      "Epoch: 34, Train Loss: 0.012265502475202084, Val Loss: 0.030668212100863457, LR Backbone: 1.0530540997704797e-05, LR Head: 1.0530540997704797e-05,\n",
      "Epoch: 35, Train Loss: 0.012132018804550171, Val Loss: 0.029765624552965164, LR Backbone: 9.375000000000004e-06, LR Head: 9.375000000000004e-06,\n",
      "Epoch: 36, Train Loss: 0.011922302655875683, Val Loss: 0.03020666539669037, LR Backbone: 8.2651330599235e-06, LR Head: 8.2651330599235e-06,\n"
     ]
    }
   ],
   "source": [
    "for fold_num in range(5):\n",
    "\n",
    "    validation_files = file_names[(6*fold_num):(6*fold_num+6)]\n",
    "\n",
    "    train_imgs = []\n",
    "    train_labels = []\n",
    "    val_imgs = []\n",
    "    val_labels = []\n",
    "\n",
    "    data_paths = os.listdir('muscle_5x_normed')\n",
    "    for i_path, data_path in enumerate(data_paths):\n",
    "        torch_obj = torch.load(f'muscle_5x_normed/{data_path}')\n",
    "\n",
    "        if data_path in validation_files:\n",
    "            val_imgs.append(torch_obj['imgs'])\n",
    "            val_labels.append(torch_obj['muscles'])\n",
    "        else:\n",
    "            train_imgs.append(torch_obj['imgs'])\n",
    "            train_labels.append(torch_obj['muscles'])\n",
    "\n",
    "    # 512 now not 256\n",
    "    train_imgs = torch.cat(train_imgs, dim=0)  # (48_000, 3, 256, 256) \n",
    "    train_labels = torch.cat(train_labels, dim=0)  # (48_000, 1, 256, 256)\n",
    "    val_imgs = torch.cat(val_imgs, dim=0)  # (12_000, 3, 256, 256)\n",
    "    val_labels = torch.cat(val_labels, dim=0)  # (12_000, 1, 256, 256)\n",
    "\n",
    "    print(f'Starting fold: {fold_num}')\n",
    "    print(train_imgs.shape, train_labels.shape)\n",
    "    print(val_imgs.shape, val_labels.shape)\n",
    "\n",
    "    batch_size = 96\n",
    "    train_loader = DataLoader(TensorDataset(train_imgs, train_labels), batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(val_imgs, val_labels), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    del train_imgs\n",
    "    del train_labels\n",
    "    del val_imgs\n",
    "    del val_labels\n",
    "\n",
    "    best_val_loss = 10\n",
    "    base_lr = 1e-4\n",
    "    learning_rate = base_lr * batch_size / 256 # 256 before\n",
    "\n",
    "    model = og_mae.mae_vit_base_patch16_dec512d8b().cuda()\n",
    "    model.load_state_dict(torch.load('mae_visualize_vit_base.pth')['model'])\n",
    "    linear = nn.Linear(768, 512).cuda()\n",
    "\n",
    "    # decoder = segmenter.MaskTransformer(n_cls=2,\n",
    "    #                                     patch_size=16,\n",
    "    #                                     d_encoder=384,\n",
    "    #                                     n_layers=2,\n",
    "    #                                     n_heads=12,\n",
    "    #                                     d_model=384,\n",
    "    #                                     d_ff=1536,\n",
    "    #                                     drop_path_rate=0,\n",
    "    #                                     dropout=0)\n",
    "    # seg_head = segmenter.Segmenter(decoder=decoder, n_cls=2).cuda()\n",
    "\n",
    "    # optimizer\n",
    "    backbone_params = model.parameters()\n",
    "    linear_params = linear.parameters()\n",
    "    # head_params = seg_head.parameters()\n",
    "    opt = torch.optim.AdamW([{'params': backbone_params}, {'params': linear_params}], lr=learning_rate)\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Prep LR stepping\n",
    "    epochs = 50\n",
    "    multiplier = 1\n",
    "    backbone_config = {'lr': learning_rate,\n",
    "                       'warmup_epochs': 5,\n",
    "                       'min_lr': 0,\n",
    "                       'epochs': epochs}\n",
    "\n",
    "    head_config = {'lr': multiplier * learning_rate,\n",
    "                   'warmup_epochs': 5,\n",
    "                   'min_lr': 0,\n",
    "                   'epochs': epochs}\n",
    "    num_down = 0\n",
    "    for epoch in range(epochs):\n",
    "        if num_down >= 20:\n",
    "            break\n",
    "\n",
    "        opt.param_groups[0]['lr'] = adjust_learning_rate(epoch, backbone_config)\n",
    "        opt.param_groups[1]['lr'] = adjust_learning_rate(epoch, head_config)\n",
    "\n",
    "        current_lr_backbone = opt.param_groups[0]['lr']  # confirm\n",
    "        current_lr_head = opt.param_groups[1]['lr']  # confirm\n",
    "\n",
    "        train_losses = []\n",
    "\n",
    "        model = model.train()\n",
    "        # seg_head = seg_head.train()\n",
    "        linear = linear.train()\n",
    "        for batch in train_loader:\n",
    "            img, plexus = batch  # load from batch\n",
    "            img, plexus = augment_image_with_map(img.cuda(), plexus.cuda())  # perform data augmentation\n",
    "\n",
    "            img = img.to(dtype=torch.bfloat16) / 255  # (bsz, 3, H, W)\n",
    "            plexus = plexus.long()  # (bsz, H, W)\n",
    "\n",
    "            with torch.cuda.amp.autocast(dtype=torch.bfloat16):\n",
    "                x = model.patch_embed(img)\n",
    "                x = x + model.pos_embed[:, 1:, :]\n",
    "\n",
    "                cls_token = model.cls_token + model.pos_embed[:, :1, :]\n",
    "                cls_tokens = cls_token.expand(x.shape[0], -1, -1)\n",
    "                x = torch.cat((cls_tokens, x), dim=1)\n",
    "\n",
    "                # apply Transformer blocks\n",
    "                for blk in model.blocks:\n",
    "                    x = blk(x)  # (bsz, L, 768)\n",
    "\n",
    "                x = linear(x)  # (bsz, L, 512)\n",
    "                logits = rearrange(x[:, 1:, :], 'b (h w) (c i j) -> b c (h i) (w j)', h=14, w=14, c=2, i=16, j=16)  # (bsz, 2, H, W)\n",
    "                # logits = seg_head(features=x[:, 1:, :], HW_input=224, HW_target=224)  # (bsz, 2, H, W)\n",
    "\n",
    "\n",
    "            loss = loss_function(logits, plexus)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        val_losses = []\n",
    "        model.eval()\n",
    "        for batch in val_loader:\n",
    "            img, plexus = batch  # load from batch\n",
    "            img = img.cuda().to(dtype=torch.bfloat16) / 255  # (bsz, 3, H, W)\n",
    "            plexus = plexus.cuda().long()  # (bsz, H, W)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                with torch.cuda.amp.autocast(dtype=torch.bfloat16):\n",
    "                    x = model.patch_embed(img)\n",
    "                    x = x + model.pos_embed[:, 1:, :]\n",
    "\n",
    "                    cls_token = model.cls_token + model.pos_embed[:, :1, :]\n",
    "                    cls_tokens = cls_token.expand(x.shape[0], -1, -1)\n",
    "                    x = torch.cat((cls_tokens, x), dim=1)\n",
    "\n",
    "                    # apply Transformer blocks\n",
    "                    for blk in model.blocks:\n",
    "                        x = blk(x)  # (bsz, L, 768)\n",
    "\n",
    "                    x = linear(x)  # (bsz, L, 512)\n",
    "                    logits = rearrange(x[:, 1:, :], 'b (h w) (c i j) -> b c (h i) (w j)', h=14, w=14, c=2, i=16,\n",
    "                                       j=16)  # (bsz, 2, H, W)\n",
    "                    # logits = seg_head(features=x[:, 1:, :], HW_input=224, HW_target=224)  # (bsz, 2, H, W)\n",
    "\n",
    "            loss = loss_function(logits, plexus)\n",
    "            val_losses.append(loss.item())\n",
    "\n",
    "        train_losses = torch.Tensor(train_losses).mean().item()\n",
    "        val_losses = torch.Tensor(val_losses).mean().item()\n",
    "        print(f'Epoch: {epoch}, Train Loss: {train_losses}, Val Loss: {val_losses}, LR Backbone: {current_lr_backbone}, LR Head: {current_lr_head},')\n",
    "\n",
    "        if best_val_loss > val_losses:\n",
    "            best_val_loss = val_losses\n",
    "            print(f'SAVING')\n",
    "            # torch.save(obj={'backbone': model.state_dict(),\n",
    "            #                 'head': seg_head.state_dict()},\n",
    "            #            f=f'saved_models/ViT_HIPT_{fold_num}_muscle_5x_{base_lr}.pt')\n",
    "            torch.save(obj={'backbone': model.state_dict(),\n",
    "                            'linear': linear.state_dict()},\n",
    "                       f=f'saved_models/ViT_IN1k_{fold_num}_muscle_5x_{base_lr}.pt')\n",
    "            num_down = 0\n",
    "        else:\n",
    "            num_down += 1\n",
    "\n",
    "        # write to logs\n",
    "        with open(f'ViT_IN1k_muscle_logs_5x_{base_lr}.csv', 'a', errors=\"ignore\") as out_file:\n",
    "            csv_writer = csv.writer(out_file, delimiter=',', lineterminator='\\n')\n",
    "            csv_writer.writerow([epoch, train_losses, val_losses, best_val_loss, current_lr_backbone, current_lr_head, base_lr, fold_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbee1537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f4c55a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.1.0\n",
      "Is CUDA enabled? False\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch version:\",torch.__version__)\n",
    "\n",
    "print(\"Is CUDA enabled?\",torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e3e4e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
