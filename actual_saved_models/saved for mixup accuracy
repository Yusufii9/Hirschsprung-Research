Learning Rate: 1e-05
Epoch: 0, Train Loss: 1.343250036239624, Val mIoU: 0.2884918339533319, Test mIoU: 0.2826810220942777, LR Backbone: 0.0, LR Head: 0.0,
Best Learning Rate: 1e-05
SAVING
Epoch: 1, Train Loss: 0.8984375, Val mIoU: 0.4471760753241803, Test mIoU: 0.4586899993429837, LR Backbone: 5.000000000000001e-07, LR Head: 5.000000000000001e-07,
Best Learning Rate: 1e-05
SAVING
Epoch: 2, Train Loss: 0.46867188811302185, Val mIoU: 0.5922800552466899, Test mIoU: 0.5956877265645361, LR Backbone: 1.0000000000000002e-06, LR Head: 1.0000000000000002e-06,
Best Learning Rate: 1e-05
SAVING
Epoch: 3, Train Loss: 0.3412500023841858, Val mIoU: 0.6115426072800899, Test mIoU: 0.5911588509010477, LR Backbone: 1.5000000000000002e-06, LR Head: 1.5000000000000002e-06,
Best Learning Rate: 1e-05
SAVING
Epoch: 4, Train Loss: 0.2946445345878601, Val mIoU: 0.6426114657171462, Test mIoU: 0.6098187014441301, LR Backbone: 2.0000000000000003e-06, LR Head: 2.0000000000000003e-06,
Best Learning Rate: 1e-05
SAVING
Epoch: 5, Train Loss: 0.26795312762260437, Val mIoU: 0.6721406484576977, Test mIoU: 0.6782442853054289, LR Backbone: 2.5e-06, LR Head: 2.5e-06,
Best Learning Rate: 1e-05
SAVING
Epoch: 6, Train Loss: 0.2576054632663727, Val mIoU: 0.62199811368406, Test mIoU: 0.6138765399294328, LR Backbone: 2.4969550628247804e-06, LR Head: 2.4969550628247804e-06,
Epoch: 7, Train Loss: 0.24863672256469727, Val mIoU: 0.6069087310852617, Test mIoU: 0.5965402212813872, LR Backbone: 2.487835085926963e-06, LR Head: 2.487835085926963e-06,
Epoch: 8, Train Loss: 0.24501562118530273, Val mIoU: 0.6806815927256665, Test mIoU: 0.7005279066908721, LR Backbone: 2.4726845009172572e-06, LR Head: 2.4726845009172572e-06,
Best Learning Rate: 1e-05
SAVING
Epoch: 9, Train Loss: 0.239013671875, Val mIoU: 0.7083283657862285, Test mIoU: 0.7338004284890953, LR Backbone: 2.451577119922899e-06, LR Head: 2.451577119922899e-06,
Best Learning Rate: 1e-05
SAVING
Epoch: 10, Train Loss: 0.2341269552707672, Val mIoU: 0.6695317765043614, Test mIoU: 0.6828192580365653, LR Backbone: 2.4246157759823856e-06, LR Head: 2.4246157759823856e-06,
Epoch: 11, Train Loss: 0.23104296624660492, Val mIoU: 0.701053823418209, Test mIoU: 0.7208709672873657, LR Backbone: 2.391931822053251e-06, LR Head: 2.391931822053251e-06,
Epoch: 12, Train Loss: 0.2255898416042328, Val mIoU: 0.7445477490582912, Test mIoU: 0.7639080680776527, LR Backbone: 2.353684491073659e-06, LR Head: 2.353684491073659e-06,
Best Learning Rate: 1e-05
SAVING
Epoch: 13, Train Loss: 0.22435547411441803, Val mIoU: 0.7002884352298718, Test mIoU: 0.7043507966626517, LR Backbone: 2.3100601201955324e-06, LR Head: 2.3100601201955324e-06,
Epoch: 14, Train Loss: 0.22139061987400055, Val mIoU: 0.7270914449874619, Test mIoU: 0.7393065850579784, LR Backbone: 2.2612712429686846e-06, LR Head: 2.2612712429686846e-06,
Epoch: 15, Train Loss: 0.21990233659744263, Val mIoU: 0.6536309132045643, Test mIoU: 0.6476739579609364, LR Backbone: 2.2075555538987226e-06, LR Head: 2.2075555538987226e-06,
Epoch: 16, Train Loss: 0.21837499737739563, Val mIoU: 0.7441736932545333, Test mIoU: 0.7637177865021787, LR Backbone: 2.1491747504233142e-06, LR Head: 2.1491747504233142e-06,
Epoch: 17, Train Loss: 0.2151230424642563, Val mIoU: 0.7777575868256579, Test mIoU: 0.805572331496167, LR Backbone: 2.086413257948573e-06, LR Head: 2.086413257948573e-06,
Best Learning Rate: 1e-05
SAVING
Epoch: 18, Train Loss: 0.21450389921665192, Val mIoU: 0.7751532621782702, Test mIoU: 0.7846604947610791, LR Backbone: 2.019576844157073e-06, LR Head: 2.019576844157073e-06,
Epoch: 19, Train Loss: 0.21305078268051147, Val mIoU: 0.7233344553887767, Test mIoU: 0.7315159515494609, LR Backbone: 1.9489911293384335e-06, LR Head: 1.9489911293384335e-06,
Epoch: 20, Train Loss: 0.21324023604393005, Val mIoU: 0.7063289129601033, Test mIoU: 0.7076337841888036, LR Backbone: 1.8750000000000003e-06, LR Head: 1.8750000000000003e-06,
Epoch: 21, Train Loss: 0.21213671565055847, Val mIoU: 0.7444651859172629, Test mIoU: 0.7577992409783396, LR Backbone: 1.797963933486347e-06, LR Head: 1.797963933486347e-06,
Epoch: 22, Train Loss: 0.21220313012599945, Val mIoU: 0.7268468385923365, Test mIoU: 0.7396326244609113, LR Backbone: 1.71825824176989e-06, LR Head: 1.71825824176989e-06,
Epoch: 23, Train Loss: 0.2092246115207672, Val mIoU: 0.7738399046342147, Test mIoU: 0.7887357167224363, LR Backbone: 1.6362712429686844e-06, LR Head: 1.6362712429686844e-06,
Epoch: 24, Train Loss: 0.21143554151058197, Val mIoU: 0.7766206609063442, Test mIoU: 0.7837931974255541, LR Backbone: 1.5524023694995849e-06, LR Head: 1.5524023694995849e-06,
Epoch: 25, Train Loss: 0.20998242497444153, Val mIoU: 0.7737375868563652, Test mIoU: 0.7868513646988831, LR Backbone: 1.4670602220836634e-06, LR Head: 1.4670602220836634e-06,
Epoch: 26, Train Loss: 0.21123437583446503, Val mIoU: 0.7704275427487495, Test mIoU: 0.7780890427175665, LR Backbone: 1.380660579084567e-06, LR Head: 1.380660579084567e-06,
Epoch: 27, Train Loss: 0.20746289193630219, Val mIoU: 0.777938377254872, Test mIoU: 0.7906457071741917, LR Backbone: 1.2936243708781266e-06, LR Head: 1.2936243708781266e-06,
Best Learning Rate: 1e-05
SAVING
Epoch: 28, Train Loss: 0.20273242890834808, Val mIoU: 0.8023345770347851, Test mIoU: 0.8245763993777151, LR Backbone: 1.2063756291218743e-06, LR Head: 1.2063756291218743e-06,
Best Learning Rate: 1e-05
SAVING
Epoch: 29, Train Loss: 0.20926561951637268, Val mIoU: 0.7831475574376772, Test mIoU: 0.8018148938845404, LR Backbone: 1.1193394209154335e-06, LR Head: 1.1193394209154335e-06,
Epoch: 30, Train Loss: 0.20416796207427979, Val mIoU: 0.8128206644423663, Test mIoU: 0.838695626852811, LR Backbone: 1.0329397779163373e-06, LR Head: 1.0329397779163373e-06,
Best Learning Rate: 1e-05
SAVING
Epoch: 31, Train Loss: 0.2045312523841858, Val mIoU: 0.8113624203814713, Test mIoU: 0.8267550080952034, LR Backbone: 9.475976305004153e-07, LR Head: 9.475976305004153e-07,
Epoch: 32, Train Loss: 0.20516015589237213, Val mIoU: 0.7896552256609302, Test mIoU: 0.804311681406404, LR Backbone: 8.637287570313159e-07, LR Head: 8.637287570313159e-07,
Epoch: 33, Train Loss: 0.20423242449760437, Val mIoU: 0.8257771692483413, Test mIoU: 0.8399729671203736, LR Backbone: 7.8174175823011e-07, LR Head: 7.8174175823011e-07,
Best Learning Rate: 1e-05
SAVING
Epoch: 34, Train Loss: 0.20346485078334808, Val mIoU: 0.7990507879578863, Test mIoU: 0.8057480068697705, LR Backbone: 7.020360665136531e-07, LR Head: 7.020360665136531e-07,
Epoch: 35, Train Loss: 0.20327343046665192, Val mIoU: 0.840795544690925, Test mIoU: 0.8396082095030999, LR Backbone: 6.250000000000004e-07, LR Head: 6.250000000000004e-07,
Best Learning Rate: 1e-05
SAVING
Epoch: 36, Train Loss: 0.20143164694309235, Val mIoU: 0.7858594605165539, Test mIoU: 0.7798352251521621, LR Backbone: 5.510088706615667e-07, LR Head: 5.510088706615667e-07,
Epoch: 37, Train Loss: 0.20584765076637268, Val mIoU: 0.808231631138671, Test mIoU: 0.8176853622305251, LR Backbone: 4.804231558429272e-07, LR Head: 4.804231558429272e-07,
Epoch: 38, Train Loss: 0.20453906059265137, Val mIoU: 0.8074372705954624, Test mIoU: 0.8184952264618035, LR Backbone: 4.1358674205142726e-07, LR Head: 4.1358674205142726e-07,
Epoch: 39, Train Loss: 0.2009863257408142, Val mIoU: 0.7965193846385139, Test mIoU: 0.8028121377569982, LR Backbone: 3.50825249576686e-07, LR Head: 3.50825249576686e-07,
Epoch: 40, Train Loss: 0.20017382502555847, Val mIoU: 0.7862036194442628, Test mIoU: 0.795974528720111, LR Backbone: 2.9244444610127764e-07, LR Head: 2.9244444610127764e-07,
Epoch: 41, Train Loss: 0.20374414324760437, Val mIoU: 0.8201119359243738, Test mIoU: 0.834337480922958, LR Backbone: 2.387287570313158e-07, LR Head: 2.387287570313158e-07,
Epoch: 42, Train Loss: 0.20036327838897705, Val mIoU: 0.8157811202750237, Test mIoU: 0.8322433485297431, LR Backbone: 1.8993987980446756e-07, LR Head: 1.8993987980446756e-07,
Epoch: 43, Train Loss: 0.20139648020267487, Val mIoU: 0.8078565097806683, Test mIoU: 0.8174424571793256, LR Backbone: 1.4631550892634156e-07, LR Head: 1.4631550892634156e-07,
Epoch: 44, Train Loss: 0.20275390148162842, Val mIoU: 0.8221699039444572, Test mIoU: 0.8307985505102107, LR Backbone: 1.0806817794674906e-07, LR Head: 1.0806817794674906e-07,

Epoch: 45, Train Loss: 0.20377148687839508, Val mIoU: 0.8336332707993157, Test mIoU: 0.8456843918838366, LR Backbone: 7.53842240176146e-08, LR Head: 7.53842240176146e-08,
Epoch: 46, Train Loss: 0.19999414682388306, Val mIoU: 0.8036263570402848, Test mIoU: 0.8121398166473701, LR Backbone: 4.842288007710166e-08, LR Head: 4.842288007710166e-08,
Epoch: 47, Train Loss: 0.20195117592811584, Val mIoU: 0.81283221896201, Test mIoU: 0.8232964715376829, LR Backbone: 2.731549908274289e-08, LR Head: 2.731549908274289e-08,
Epoch: 48, Train Loss: 0.19807617366313934, Val mIoU: 0.8174802901967511, Test mIoU: 0.8287656298426209, LR Backbone: 1.2164914073037187e-08, LR Head: 1.2164914073037187e-08,
Epoch: 49, Train Loss: 0.20094922184944153, Val mIoU: 0.8176533512164039, Test mIoU: 0.8287865785092932, LR Backbone: 3.0449371752197533e-09, LR Head: 3.0449371752197533e-09,
Learning Rate: 1e-05
Epoch: 0, Train Loss: 1.3126250505447388, Val mIoU: 0.30484973223786727, Test mIoU: 0.30112599619649727, LR Backbone: 0.0, LR Head: 0.0,
Best Learning Rate: 1e-05
SAVING
Epoch: 1, Train Loss: 0.8885625004768372, Val mIoU: 0.4273084128081358, Test mIoU: 0.4390229080217427, LR Backbone: 5.000000000000001e-07, LR Head: 5.000000000000001e-07,
Best Learning Rate: 1e-05
SAVING
Epoch: 2, Train Loss: 0.5004062652587891, Val mIoU: 0.4744333291819544, Test mIoU: 0.4941300038107639, LR Backbone: 1.0000000000000002e-06, LR Head: 1.0000000000000002e-06,
Best Learning Rate: 1e-05
SAVING
Epoch: 3, Train Loss: 0.3892148435115814, Val mIoU: 0.5187568386786738, Test mIoU: 0.5488124333605331, LR Backbone: 1.5000000000000002e-06, LR Head: 1.5000000000000002e-06,
Best Learning Rate: 1e-05
SAVING
Epoch: 4, Train Loss: 0.3490859270095825, Val mIoU: 0.550064008764965, Test mIoU: 0.586296341155707, LR Backbone: 2.0000000000000003e-06, LR Head: 2.0000000000000003e-06,
Best Learning Rate: 1e-05
SAVING
Epoch: 5, Train Loss: 0.3294609487056732, Val mIoU: 0.5988264498478592, Test mIoU: 0.6109208845414998, LR Backbone: 2.5e-06, LR Head: 2.5e-06,
Best Learning Rate: 1e-05
SAVING
Epoch: 6, Train Loss: 0.3273320198059082, Val mIoU: 0.5626612034715426, Test mIoU: 0.5681871816085295, LR Backbone: 2.4969550628247804e-06, LR Head: 2.4969550628247804e-06,
Epoch: 7, Train Loss: 0.3211406171321869, Val mIoU: 0.632790399328313, Test mIoU: 0.6186469819153172, LR Backbone: 2.487835085926963e-06, LR Head: 2.487835085926963e-06,
Best Learning Rate: 1e-05
SAVING
Epoch: 8, Train Loss: 0.313539057970047, Val mIoU: 0.5142460150784658, Test mIoU: 0.5071096724939502, LR Backbone: 2.4726845009172572e-06, LR Head: 2.4726845009172572e-06,
Epoch: 9, Train Loss: 0.3163984417915344, Val mIoU: 0.5330750700330484, Test mIoU: 0.5104954565413521, LR Backbone: 2.451577119922899e-06, LR Head: 2.451577119922899e-06,
Epoch: 10, Train Loss: 0.3076874911785126, Val mIoU: 0.5346465650408172, Test mIoU: 0.514941902030043, LR Backbone: 2.4246157759823856e-06, LR Head: 2.4246157759823856e-06,
Epoch: 11, Train Loss: 0.305726557970047, Val mIoU: 0.5325441222709268, Test mIoU: 0.5154672710049368, LR Backbone: 2.391931822053251e-06, LR Head: 2.391931822053251e-06,
Epoch: 12, Train Loss: 0.3015078008174896, Val mIoU: 0.49273660777048284, Test mIoU: 0.4946472614924383, LR Backbone: 2.353684491073659e-06, LR Head: 2.353684491073659e-06,
Epoch: 13, Train Loss: 0.30097267031669617, Val mIoU: 0.5281276193336015, Test mIoU: 0.5122521632203397, LR Backbone: 2.3100601201955324e-06, LR Head: 2.3100601201955324e-06,
Epoch: 14, Train Loss: 0.30033984780311584, Val mIoU: 0.5042521939582818, Test mIoU: 0.5043371171749512, LR Backbone: 2.2612712429686846e-06, LR Head: 2.2612712429686846e-06,
Epoch: 15, Train Loss: 0.30524998903274536, Val mIoU: 0.556703357447483, Test mIoU: 0.5697563204303109, LR Backbone: 2.2075555538987226e-06, LR Head: 2.2075555538987226e-06,
Epoch: 16, Train Loss: 0.2957773506641388, Val mIoU: 0.49517203674770516, Test mIoU: 0.4877305511576969, LR Backbone: 2.1491747504233142e-06, LR Head: 2.1491747504233142e-06,
Epoch: 17, Train Loss: 0.2990117073059082, Val mIoU: 0.5230908380368071, Test mIoU: 0.5250790136699172, LR Backbone: 2.086413257948573e-06, LR Head: 2.086413257948573e-06,
Epoch: 18, Train Loss: 0.29264843463897705, Val mIoU: 0.5168337172837103, Test mIoU: 0.5131623391293201, LR Backbone: 2.019576844157073e-06, LR Head: 2.019576844157073e-06,
Epoch: 19, Train Loss: 0.29048827290534973, Val mIoU: 0.5489854434502746, Test mIoU: 0.5550086879506406, LR Backbone: 1.9489911293384335e-06, LR Head: 1.9489911293384335e-06,
Epoch: 20, Train Loss: 0.29567578434944153, Val mIoU: 0.5131784869669841, Test mIoU: 0.5122977771547526, LR Backbone: 1.8750000000000003e-06, LR Head: 1.8750000000000003e-06,
Epoch: 21, Train Loss: 0.28896093368530273, Val mIoU: 0.49763291877341764, Test mIoU: 0.5034160512662387, LR Backbone: 1.797963933486347e-06, LR Head: 1.797963933486347e-06,
Epoch: 22, Train Loss: 0.2852382957935333, Val mIoU: 0.5623197182361478, Test mIoU: 0.5627000145548832, LR Backbone: 1.71825824176989e-06, LR Head: 1.71825824176989e-06,
Epoch: 23, Train Loss: 0.28905078768730164, Val mIoU: 0.5101415483682032, Test mIoU: 0.5113908661536837, LR Backbone: 1.6362712429686844e-06, LR Head: 1.6362712429686844e-06,
Epoch: 24, Train Loss: 0.28602343797683716, Val mIoU: 0.5435910858593982, Test mIoU: 0.5503237796091172, LR Backbone: 1.5524023694995849e-06, LR Head: 1.5524023694995849e-06,
Epoch: 25, Train Loss: 0.28581640124320984, Val mIoU: 0.49781837859931377, Test mIoU: 0.5009629885004616, LR Backbone: 1.4670602220836634e-06, LR Head: 1.4670602220836634e-06,
Epoch: 26, Train Loss: 0.2833632826805115, Val mIoU: 0.5304973074344572, Test mIoU: 0.5322502016759911, LR Backbone: 1.380660579084567e-06, LR Head: 1.380660579084567e-06,
Epoch: 27, Train Loss: 0.28419139981269836, Val mIoU: 0.49642620482505506, Test mIoU: 0.5011644490668978, LR Backbone: 1.2936243708781266e-06, LR Head: 1.2936243708781266e-06,
Learning Rate: 1e-05
Epoch: 0, Train Loss: 1.2741249799728394, Val mIoU: 0.31913032809762115, Test mIoU: 0.3151913674735107, LR Backbone: 0.0, LR Head: 0.0,
Best Learning Rate: 1e-05
SAVING
Epoch: 1, Train Loss: 0.8708281517028809, Val mIoU: 0.4354393404897779, Test mIoU: 0.4440517642030914, LR Backbone: 5.000000000000001e-07, LR Head: 5.000000000000001e-07,
Best Learning Rate: 1e-05
SAVING
Epoch: 2, Train Loss: 0.4593828022480011, Val mIoU: 0.5148986531630827, Test mIoU: 0.515024916075328, LR Backbone: 1.0000000000000002e-06, LR Head: 1.0000000000000002e-06,
Best Learning Rate: 1e-05
SAVING
Epoch: 3, Train Loss: 0.3280703127384186, Val mIoU: 0.7055334140271952, Test mIoU: 0.645391880904134, LR Backbone: 1.5000000000000002e-06, LR Head: 1.5000000000000002e-06,
Best Learning Rate: 1e-05
SAVING
Epoch: 4, Train Loss: 0.28371483087539673, Val mIoU: 0.5967147261143836, Test mIoU: 0.5877310592125031, LR Backbone: 2.0000000000000003e-06, LR Head: 2.0000000000000003e-06,
Epoch: 5, Train Loss: 0.26905468106269836, Val mIoU: 0.7502865319654127, Test mIoU: 0.7678452209525413, LR Backbone: 2.5e-06, LR Head: 2.5e-06,
Best Learning Rate: 1e-05
SAVING
Epoch: 6, Train Loss: 0.25212109088897705, Val mIoU: 0.6970510518982297, Test mIoU: 0.7138694092769828, LR Backbone: 2.4969550628247804e-06, LR Head: 2.4969550628247804e-06,
Epoch: 7, Train Loss: 0.2514726519584656, Val mIoU: 0.7173153815767546, Test mIoU: 0.7572786958615007, LR Backbone: 2.487835085926963e-06, LR Head: 2.487835085926963e-06,
Epoch: 8, Train Loss: 0.2417265623807907, Val mIoU: 0.6837420219890991, Test mIoU: 0.7107254011020104, LR Backbone: 2.4726845009172572e-06, LR Head: 2.4726845009172572e-06,
Epoch: 9, Train Loss: 0.23634961247444153, Val mIoU: 0.8035766942342704, Test mIoU: 0.8379815627849331, LR Backbone: 2.451577119922899e-06, LR Head: 2.451577119922899e-06,
Best Learning Rate: 1e-05
SAVING
Epoch: 10, Train Loss: 0.23432812094688416, Val mIoU: 0.6774950091339494, Test mIoU: 0.7130828539658467, LR Backbone: 2.4246157759823856e-06, LR Head: 2.4246157759823856e-06,
Epoch: 11, Train Loss: 0.2303164005279541, Val mIoU: 0.8209148148327592, Test mIoU: 0.8434848676989011, LR Backbone: 2.391931822053251e-06, LR Head: 2.391931822053251e-06,
Best Learning Rate: 1e-05
SAVING
Epoch: 12, Train Loss: 0.22774414718151093, Val mIoU: 0.7325279887450471, Test mIoU: 0.7616766782819184, LR Backbone: 2.353684491073659e-06, LR Head: 2.353684491073659e-06,

Epoch: 13, Train Loss: 0.22456249594688416, Val mIoU: 0.7906605127702261, Test mIoU: 0.8255376148450153, LR Backbone: 2.3100601201955324e-06, LR Head: 2.3100601201955324e-06,
Epoch: 14, Train Loss: 0.22208984196186066, Val mIoU: 0.757035291086642, Test mIoU: 0.771897908930473, LR Backbone: 2.2612712429686846e-06, LR Head: 2.2612712429686846e-06,
Epoch: 15, Train Loss: 0.21738672256469727, Val mIoU: 0.742566490033856, Test mIoU: 0.7505715059125545, LR Backbone: 2.2075555538987226e-06, LR Head: 2.2075555538987226e-06,
Epoch: 16, Train Loss: 0.21921679377555847, Val mIoU: 0.8385701052328624, Test mIoU: 0.8204548011030707, LR Backbone: 2.1491747504233142e-06, LR Head: 2.1491747504233142e-06,
Best Learning Rate: 1e-05
SAVING
Epoch: 17, Train Loss: 0.21375781297683716, Val mIoU: 0.8653334532451025, Test mIoU: 0.8674378474972376, LR Backbone: 2.086413257948573e-06, LR Head: 2.086413257948573e-06,
Best Learning Rate: 1e-05
SAVING
Epoch: 18, Train Loss: 0.21472851932048798, Val mIoU: 0.8164165042870193, Test mIoU: 0.8266406107268589, LR Backbone: 2.019576844157073e-06, LR Head: 2.019576844157073e-06,
Epoch: 19, Train Loss: 0.2155117243528366, Val mIoU: 0.8229929826012414, Test mIoU: 0.8315385332108338, LR Backbone: 1.9489911293384335e-06, LR Head: 1.9489911293384335e-06,
Epoch: 20, Train Loss: 0.21235936880111694, Val mIoU: 0.8403003445095336, Test mIoU: 0.830950653753683, LR Backbone: 1.8750000000000003e-06, LR Head: 1.8750000000000003e-06,
Epoch: 21, Train Loss: 0.20825976133346558, Val mIoU: 0.874252552415093, Test mIoU: 0.8599137777406445, LR Backbone: 1.797963933486347e-06, LR Head: 1.797963933486347e-06,
Best Learning Rate: 1e-05
SAVING
Epoch: 22, Train Loss: 0.21034960448741913, Val mIoU: 0.9102730236752254, Test mIoU: 0.897850862004174, LR Backbone: 1.71825824176989e-06, LR Head: 1.71825824176989e-06,
Best Learning Rate: 1e-05
SAVING
Epoch: 23, Train Loss: 0.20561523735523224, Val mIoU: 0.8697947428983249, Test mIoU: 0.8617377447708857, LR Backbone: 1.6362712429686844e-06, LR Head: 1.6362712429686844e-06,
Epoch: 24, Train Loss: 0.2082539051771164, Val mIoU: 0.9017035019807923, Test mIoU: 0.8928753567117573, LR Backbone: 1.5524023694995849e-06, LR Head: 1.5524023694995849e-06,
Epoch: 25, Train Loss: 0.20909570157527924, Val mIoU: 0.8469213575485355, Test mIoU: 0.8325790403719061, LR Backbone: 1.4670602220836634e-06, LR Head: 1.4670602220836634e-06,
Epoch: 26, Train Loss: 0.2092597633600235, Val mIoU: 0.899625882632552, Test mIoU: 0.8841205062218891, LR Backbone: 1.380660579084567e-06, LR Head: 1.380660579084567e-06,
Epoch: 27, Train Loss: 0.20811133086681366, Val mIoU: 0.9192089262628294, Test mIoU: 0.9019552839043474, LR Backbone: 1.2936243708781266e-06, LR Head: 1.2936243708781266e-06,
Best Learning Rate: 1e-05
SAVING
Epoch: 28, Train Loss: 0.206605464220047, Val mIoU: 0.8459607440583663, Test mIoU: 0.8566320478047518, LR Backbone: 1.2063756291218743e-06, LR Head: 1.2063756291218743e-06,
Epoch: 29, Train Loss: 0.2056542932987213, Val mIoU: 0.8959025634571026, Test mIoU: 0.8914331045501438, LR Backbone: 1.1193394209154335e-06, LR Head: 1.1193394209154335e-06,
Epoch: 30, Train Loss: 0.20595897734165192, Val mIoU: 0.9273970970412415, Test mIoU: 0.9081098872820407, LR Backbone: 1.0329397779163373e-06, LR Head: 1.0329397779163373e-06,
Best Learning Rate: 1e-05
SAVING
Epoch: 31, Train Loss: 0.20359764993190765, Val mIoU: 0.9011305177974838, Test mIoU: 0.8795644312912536, LR Backbone: 9.475976305004153e-07, LR Head: 9.475976305004153e-07,
Epoch: 32, Train Loss: 0.20323242247104645, Val mIoU: 0.9138844456005134, Test mIoU: 0.901288001399025, LR Backbone: 8.637287570313159e-07, LR Head: 8.637287570313159e-07,
Epoch: 33, Train Loss: 0.20291991531848907, Val mIoU: 0.8716140918038577, Test mIoU: 0.8621344504193031, LR Backbone: 7.8174175823011e-07, LR Head: 7.8174175823011e-07,
Epoch: 34, Train Loss: 0.20067773759365082, Val mIoU: 0.8801602872097003, Test mIoU: 0.879444113619869, LR Backbone: 7.020360665136531e-07, LR Head: 7.020360665136531e-07,
Epoch: 35, Train Loss: 0.20213672518730164, Val mIoU: 0.8880155044034111, Test mIoU: 0.8791370602397455, LR Backbone: 6.250000000000004e-07, LR Head: 6.250000000000004e-07,
Epoch: 36, Train Loss: 0.2018691450357437, Val mIoU: 0.9025856125846541, Test mIoU: 0.88212469979226, LR Backbone: 5.510088706615667e-07, LR Head: 5.510088706615667e-07,
Epoch: 37, Train Loss: 0.20248828828334808, Val mIoU: 0.8876999073438772, Test mIoU: 0.8761880862570557, LR Backbone: 4.804231558429272e-07, LR Head: 4.804231558429272e-07,
Epoch: 38, Train Loss: 0.20066601037979126, Val mIoU: 0.8940876976720245, Test mIoU: 0.8823791925533009, LR Backbone: 4.1358674205142726e-07, LR Head: 4.1358674205142726e-07,
Epoch: 39, Train Loss: 0.2016914039850235, Val mIoU: 0.9000664722580571, Test mIoU: 0.8837078440587732, LR Backbone: 3.50825249576686e-07, LR Head: 3.50825249576686e-07,
Epoch: 40, Train Loss: 0.20130078494548798, Val mIoU: 0.8956682988427735, Test mIoU: 0.8789519100668888, LR Backbone: 2.9244444610127764e-07, LR Head: 2.9244444610127764e-07,
Epoch: 41, Train Loss: 0.20146094262599945, Val mIoU: 0.9175264298499345, Test mIoU: 0.8986796871959002, LR Backbone: 2.387287570313158e-07, LR Head: 2.387287570313158e-07,
Epoch: 42, Train Loss: 0.2012031227350235, Val mIoU: 0.8986153725243509, Test mIoU: 0.878235639926696, LR Backbone: 1.8993987980446756e-07, LR Head: 1.8993987980446756e-07,
Epoch: 43, Train Loss: 0.20182812213897705, Val mIoU: 0.9225881631450084, Test mIoU: 0.8995264529792277, LR Backbone: 1.4631550892634156e-07, LR Head: 1.4631550892634156e-07,
Epoch: 44, Train Loss: 0.201234370470047, Val mIoU: 0.8892472990485685, Test mIoU: 0.8702575104185268, LR Backbone: 1.0806817794674906e-07, LR Head: 1.0806817794674906e-07,
Epoch: 45, Train Loss: 0.19813866913318634, Val mIoU: 0.915717942072227, Test mIoU: 0.8949149946218673, LR Backbone: 7.53842240176146e-08, LR Head: 7.53842240176146e-08,
Epoch: 46, Train Loss: 0.1997031271457672, Val mIoU: 0.9055162623747244, Test mIoU: 0.8877242170722739, LR Backbone: 4.842288007710166e-08, LR Head: 4.842288007710166e-08,
Epoch: 47, Train Loss: 0.20018163323402405, Val mIoU: 0.9049984810076379, Test mIoU: 0.8861108848370047, LR Backbone: 2.731549908274289e-08, LR Head: 2.731549908274289e-08,
Epoch: 48, Train Loss: 0.19895702600479126, Val mIoU: 0.907295103207801, Test mIoU: 0.888141451735008, LR Backbone: 1.2164914073037187e-08, LR Head: 1.2164914073037187e-08,
Epoch: 49, Train Loss: 0.20015038549900055, Val mIoU: 0.9077099497444958, Test mIoU: 0.8884793670988569, LR Backbone: 3.0449371752197533e-09, LR Head: 3.0449371752197533e-09,
Learning Rate: 5e-05
Epoch: 0, Train Loss: 1.2893749475479126, Val mIoU: 0.29563855771508557, Test mIoU: 0.29076734131485205, LR Backbone: 0.0, LR Head: 0.0,
Best Learning Rate: 5e-05
SAVING
Epoch: 1, Train Loss: 0.5184179544448853, Val mIoU: 0.6666074570257174, Test mIoU: 0.6416146973250632, LR Backbone: 2.5e-06, LR Head: 2.5e-06,
Best Learning Rate: 5e-05
SAVING
Epoch: 2, Train Loss: 0.2837499976158142, Val mIoU: 0.6814631521918105, Test mIoU: 0.6912238226039585, LR Backbone: 5e-06, LR Head: 5e-06,
Best Learning Rate: 5e-05
SAVING
Epoch: 3, Train Loss: 0.25484374165534973, Val mIoU: 0.7365126167719453, Test mIoU: 0.7816554748256201, LR Backbone: 7.500000000000001e-06, LR Head: 7.500000000000001e-06,
Best Learning Rate: 5e-05
SAVING
Epoch: 4, Train Loss: 0.24257811903953552, Val mIoU: 0.6269548912147341, Test mIoU: 0.6202103439668167, LR Backbone: 1e-05, LR Head: 1e-05,
Epoch: 5, Train Loss: 0.2307773381471634, Val mIoU: 0.757563253865905, Test mIoU: 0.804972293684558, LR Backbone: 1.25e-05, LR Head: 1.25e-05,
Best Learning Rate: 5e-05
SAVING
Epoch: 6, Train Loss: 0.22129297256469727, Val mIoU: 0.6870388449100674, Test mIoU: 0.726515594181824, LR Backbone: 1.2484775314123903e-05, LR Head: 1.2484775314123903e-05,
Epoch: 7, Train Loss: 0.21522070467472076, Val mIoU: 0.8307860499552477, Test mIoU: 0.878343209939644, LR Backbone: 1.2439175429634816e-05, LR Head: 1.2439175429634816e-05,
Best Learning Rate: 5e-05
SAVING
Epoch: 8, Train Loss: 0.21123437583446503, Val mIoU: 0.7829648750873597, Test mIoU: 0.8458693059745223, LR Backbone: 1.2363422504586286e-05, LR Head: 1.2363422504586286e-05,

Epoch: 9, Train Loss: 0.21166016161441803, Val mIoU: 0.7830895896910105, Test mIoU: 0.8272281097747671, LR Backbone: 1.2257885599614494e-05, LR Head: 1.2257885599614494e-05,
Epoch: 10, Train Loss: 0.20646874606609344, Val mIoU: 0.8055407280666531, Test mIoU: 0.8469634722701873, LR Backbone: 1.2123078879911928e-05, LR Head: 1.2123078879911928e-05,
Epoch: 11, Train Loss: 0.20210546255111694, Val mIoU: 0.82739459022851, Test mIoU: 0.8836499305292167, LR Backbone: 1.1959659110266256e-05, LR Head: 1.1959659110266256e-05,
Epoch: 12, Train Loss: 0.20527733862400055, Val mIoU: 0.8109738478909092, Test mIoU: 0.8523258162075802, LR Backbone: 1.1768422455368295e-05, LR Head: 1.1768422455368295e-05,
Epoch: 13, Train Loss: 0.2020585983991623, Val mIoU: 0.7474810799017915, Test mIoU: 0.7933272645370026, LR Backbone: 1.1550300600977662e-05, LR Head: 1.1550300600977662e-05,
Epoch: 14, Train Loss: 0.2021757811307907, Val mIoU: 0.8389969195699281, Test mIoU: 0.8823759167586909, LR Backbone: 1.1306356214843423e-05, LR Head: 1.1306356214843423e-05,
Best Learning Rate: 5e-05
SAVING
Epoch: 15, Train Loss: 0.20146289467811584, Val mIoU: 0.6696315101598668, Test mIoU: 0.667573546564663, LR Backbone: 1.1037777769493613e-05, LR Head: 1.1037777769493613e-05,
Epoch: 16, Train Loss: 0.19741015136241913, Val mIoU: 0.7942763511230853, Test mIoU: 0.814348464257709, LR Backbone: 1.0745873752116569e-05, LR Head: 1.0745873752116569e-05,
Epoch: 17, Train Loss: 0.1986953169107437, Val mIoU: 0.8320927277059718, Test mIoU: 0.8749929797450811, LR Backbone: 1.0432066289742864e-05, LR Head: 1.0432066289742864e-05,
Epoch: 18, Train Loss: 0.19745507836341858, Val mIoU: 0.8874878572457988, Test mIoU: 0.9154112373372356, LR Backbone: 1.0097884220785363e-05, LR Head: 1.0097884220785363e-05,
Best Learning Rate: 5e-05
SAVING
Epoch: 19, Train Loss: 0.19892187416553497, Val mIoU: 0.8003126826711406, Test mIoU: 0.8354236524308651, LR Backbone: 9.744955646692168e-06, LR Head: 9.744955646692168e-06,
Epoch: 20, Train Loss: 0.1981484442949295, Val mIoU: 0.9187881728685183, Test mIoU: 0.9268280731018437, LR Backbone: 9.375000000000001e-06, LR Head: 9.375000000000001e-06,
Best Learning Rate: 5e-05
SAVING
Epoch: 21, Train Loss: 0.1947304755449295, Val mIoU: 0.9526394737364623, Test mIoU: 0.9417459061992255, LR Backbone: 8.989819667431734e-06, LR Head: 8.989819667431734e-06,
Best Learning Rate: 5e-05
SAVING
Epoch: 22, Train Loss: 0.19358202815055847, Val mIoU: 0.8820201058287804, Test mIoU: 0.8961148500496283, LR Backbone: 8.59129120884945e-06, LR Head: 8.59129120884945e-06,
Epoch: 23, Train Loss: 0.19291992485523224, Val mIoU: 0.8212557167873644, Test mIoU: 0.8037585526825652, LR Backbone: 8.181356214843423e-06, LR Head: 8.181356214843423e-06,
Epoch: 24, Train Loss: 0.19544336199760437, Val mIoU: 0.899156807496234, Test mIoU: 0.9141189227819977, LR Backbone: 7.762011847497924e-06, LR Head: 7.762011847497924e-06,
Epoch: 25, Train Loss: 0.1935156285762787, Val mIoU: 0.9183373312683398, Test mIoU: 0.9269101208986111, LR Backbone: 7.3353011104183164e-06, LR Head: 7.3353011104183164e-06,
Epoch: 26, Train Loss: 0.18956249952316284, Val mIoU: 0.9570049873060319, Test mIoU: 0.945199939036686, LR Backbone: 6.903302895422835e-06, LR Head: 6.903302895422835e-06,
Best Learning Rate: 5e-05
SAVING
Epoch: 27, Train Loss: 0.19034375250339508, Val mIoU: 0.9133508026468519, Test mIoU: 0.9171931394816052, LR Backbone: 6.468121854390633e-06, LR Head: 6.468121854390633e-06,
Epoch: 28, Train Loss: 0.1911289095878601, Val mIoU: 0.8370455244836258, Test mIoU: 0.8570576695379606, LR Backbone: 6.031878145609371e-06, LR Head: 6.031878145609371e-06,
Epoch: 29, Train Loss: 0.19105859100818634, Val mIoU: 0.8956339756423433, Test mIoU: 0.921176444401081, LR Backbone: 5.596697104577167e-06, LR Head: 5.596697104577167e-06,
Epoch: 30, Train Loss: 0.18939648568630219, Val mIoU: 0.8991195372853626, Test mIoU: 0.9166016801524735, LR Backbone: 5.164698889581686e-06, LR Head: 5.164698889581686e-06,
Epoch: 31, Train Loss: 0.18875780701637268, Val mIoU: 0.9364616318691954, Test mIoU: 0.9354116719263668, LR Backbone: 4.737988152502077e-06, LR Head: 4.737988152502077e-06,
Epoch: 32, Train Loss: 0.19001367688179016, Val mIoU: 0.9180902386738565, Test mIoU: 0.9220208114852482, LR Backbone: 4.3186437851565795e-06, LR Head: 4.3186437851565795e-06,
Epoch: 33, Train Loss: 0.19110742211341858, Val mIoU: 0.892524557322965, Test mIoU: 0.9034438580109742, LR Backbone: 3.90870879115055e-06, LR Head: 3.90870879115055e-06,
Epoch: 34, Train Loss: 0.18824610114097595, Val mIoU: 0.8931890028930605, Test mIoU: 0.909464595394225, LR Backbone: 3.5101803325682656e-06, LR Head: 3.5101803325682656e-06,
Epoch: 35, Train Loss: 0.18720702826976776, Val mIoU: 0.9380287528444462, Test mIoU: 0.9329491921627726, LR Backbone: 3.1250000000000014e-06, LR Head: 3.1250000000000014e-06,
Epoch: 36, Train Loss: 0.1873437464237213, Val mIoU: 0.9467256620103103, Test mIoU: 0.9366310316273159, LR Backbone: 2.7550443533078335e-06, LR Head: 2.7550443533078335e-06,
Epoch: 37, Train Loss: 0.1874355524778366, Val mIoU: 0.9447855537716875, Test mIoU: 0.9317425653406106, LR Backbone: 2.4021157792146356e-06, LR Head: 2.4021157792146356e-06,
Epoch: 38, Train Loss: 0.18529687821865082, Val mIoU: 0.903117096900077, Test mIoU: 0.9176063134762729, LR Backbone: 2.067933710257136e-06, LR Head: 2.067933710257136e-06,
Epoch: 39, Train Loss: 0.18919335305690765, Val mIoU: 0.8836511481126731, Test mIoU: 0.8753932449540405, LR Backbone: 1.75412624788343e-06, LR Head: 1.75412624788343e-06,
Epoch: 40, Train Loss: 0.18344922363758087, Val mIoU: 0.9105181502619173, Test mIoU: 0.9129057461157859, LR Backbone: 1.4622222305063882e-06, LR Head: 1.4622222305063882e-06,
Epoch: 41, Train Loss: 0.18639647960662842, Val mIoU: 0.9061703673111015, Test mIoU: 0.9178972431234875, LR Backbone: 1.1936437851565791e-06, LR Head: 1.1936437851565791e-06,
Epoch: 42, Train Loss: 0.1843613237142563, Val mIoU: 0.9273895530959644, Test mIoU: 0.9259353529092835, LR Backbone: 9.496993990223378e-07, LR Head: 9.496993990223378e-07,
Epoch: 43, Train Loss: 0.18855078518390656, Val mIoU: 0.9228089746409189, Test mIoU: 0.9209623037691442, LR Backbone: 7.315775446317077e-07, LR Head: 7.315775446317077e-07,
Epoch: 44, Train Loss: 0.186341792345047, Val mIoU: 0.9070367896500147, Test mIoU: 0.9120161778696425, LR Backbone: 5.403408897337453e-07, LR Head: 5.403408897337453e-07,
Epoch: 45, Train Loss: 0.1851191371679306, Val mIoU: 0.9055132137533708, Test mIoU: 0.9102429637080132, LR Backbone: 3.7692112008807306e-07, LR Head: 3.7692112008807306e-07,
Epoch: 46, Train Loss: 0.18427734076976776, Val mIoU: 0.921660980066431, Test mIoU: 0.9252238207059846, LR Backbone: 2.421144003855083e-07, LR Head: 2.421144003855083e-07,
Learning Rate: 5e-05
Epoch: 0, Train Loss: 1.3347500562667847, Val mIoU: 0.2986986262408613, Test mIoU: 0.2947016999891148, LR Backbone: 0.0, LR Head: 0.0,
Best Learning Rate: 5e-05
SAVING
Epoch: 1, Train Loss: 0.5605937242507935, Val mIoU: 0.5307190618437388, Test mIoU: 0.5559577563555913, LR Backbone: 2.5e-06, LR Head: 2.5e-06,
Best Learning Rate: 5e-05
SAVING
Epoch: 2, Train Loss: 0.358460932970047, Val mIoU: 0.5369089520871249, Test mIoU: 0.5977904048761419, LR Backbone: 5e-06, LR Head: 5e-06,
Best Learning Rate: 5e-05
SAVING
Epoch: 3, Train Loss: 0.3316406309604645, Val mIoU: 0.5601030805010497, Test mIoU: 0.6106546371955746, LR Backbone: 7.500000000000001e-06, LR Head: 7.500000000000001e-06,
Best Learning Rate: 5e-05
SAVING
Epoch: 4, Train Loss: 0.3213242292404175, Val mIoU: 0.520229978923409, Test mIoU: 0.5707437287737764, LR Backbone: 1e-05, LR Head: 1e-05,
Epoch: 5, Train Loss: 0.3115273416042328, Val mIoU: 0.5950647443422833, Test mIoU: 0.6499068063948068, LR Backbone: 1.25e-05, LR Head: 1.25e-05,
Best Learning Rate: 5e-05
SAVING
Epoch: 6, Train Loss: 0.3022109270095825, Val mIoU: 0.5265772916657264, Test mIoU: 0.5665808314887459, LR Backbone: 1.2484775314123903e-05, LR Head: 1.2484775314123903e-05,
Epoch: 7, Train Loss: 0.2948515713214874, Val mIoU: 0.488138269075248, Test mIoU: 0.5018710465511192, LR Backbone: 1.2439175429634816e-05, LR Head: 1.2439175429634816e-05,
Epoch: 8, Train Loss: 0.2910195291042328, Val mIoU: 0.5968660099980984, Test mIoU: 0.6324536929887474, LR Backbone: 1.2363422504586286e-05, LR Head: 1.2363422504586286e-05,
Best Learning Rate: 5e-05
SAVING

Epoch: 9, Train Loss: 0.28791406750679016, Val mIoU: 0.5229341375025058, Test mIoU: 0.5398729131047955, LR Backbone: 1.2257885599614494e-05, LR Head: 1.2257885599614494e-05,
Epoch: 10, Train Loss: 0.2834452986717224, Val mIoU: 0.5261887143886553, Test mIoU: 0.5472942797608835, LR Backbone: 1.2123078879911928e-05, LR Head: 1.2123078879911928e-05,
Epoch: 11, Train Loss: 0.2833574116230011, Val mIoU: 0.5174597838089094, Test mIoU: 0.5232497277595511, LR Backbone: 1.1959659110266256e-05, LR Head: 1.1959659110266256e-05,
Epoch: 12, Train Loss: 0.2809374928474426, Val mIoU: 0.4978351457784556, Test mIoU: 0.5016201185504623, LR Backbone: 1.1768422455368295e-05, LR Head: 1.1768422455368295e-05,
Epoch: 13, Train Loss: 0.27516797184944153, Val mIoU: 0.5849924702364679, Test mIoU: 0.5957792560993557, LR Backbone: 1.1550300600977662e-05, LR Head: 1.1550300600977662e-05,
Epoch: 14, Train Loss: 0.27949219942092896, Val mIoU: 0.4987750667067167, Test mIoU: 0.5149212036473315, LR Backbone: 1.1306356214843423e-05, LR Head: 1.1306356214843423e-05,
Epoch: 15, Train Loss: 0.27879297733306885, Val mIoU: 0.6032476523627386, Test mIoU: 0.6172901359677865, LR Backbone: 1.1037777769493613e-05, LR Head: 1.1037777769493613e-05,
Best Learning Rate: 5e-05
SAVING
Epoch: 16, Train Loss: 0.27680858969688416, Val mIoU: 0.5465042622757587, Test mIoU: 0.5555921008829625, LR Backbone: 1.0745873752116569e-05, LR Head: 1.0745873752116569e-05,
Epoch: 17, Train Loss: 0.26966798305511475, Val mIoU: 0.5714879053520148, Test mIoU: 0.5931375349041185, LR Backbone: 1.0432066289742864e-05, LR Head: 1.0432066289742864e-05,
Epoch: 18, Train Loss: 0.2709101438522339, Val mIoU: 0.5907976147287402, Test mIoU: 0.6180819032796299, LR Backbone: 1.0097884220785363e-05, LR Head: 1.0097884220785363e-05,
Epoch: 19, Train Loss: 0.26939648389816284, Val mIoU: 0.5316444331880789, Test mIoU: 0.5488634698684617, LR Backbone: 9.744955646692168e-06, LR Head: 9.744955646692168e-06,
Epoch: 20, Train Loss: 0.2632382810115814, Val mIoU: 0.5578670571776692, Test mIoU: 0.5849821405740903, LR Backbone: 9.375000000000001e-06, LR Head: 9.375000000000001e-06,
Epoch: 21, Train Loss: 0.2674882709980011, Val mIoU: 0.5900068691611488, Test mIoU: 0.6167486840926586, LR Backbone: 8.989819667431734e-06, LR Head: 8.989819667431734e-06,
Epoch: 22, Train Loss: 0.26475977897644043, Val mIoU: 0.48496061423715575, Test mIoU: 0.49263074556276965, LR Backbone: 8.59129120884945e-06, LR Head: 8.59129120884945e-06,
Epoch: 23, Train Loss: 0.26338282227516174, Val mIoU: 0.6056742766535717, Test mIoU: 0.6328618377481223, LR Backbone: 8.181356214843423e-06, LR Head: 8.181356214843423e-06,
Best Learning Rate: 5e-05
SAVING
Epoch: 24, Train Loss: 0.26561328768730164, Val mIoU: 0.5550540049496319, Test mIoU: 0.5693357795314611, LR Backbone: 7.762011847497924e-06, LR Head: 7.762011847497924e-06,
Epoch: 25, Train Loss: 0.2590312361717224, Val mIoU: 0.6331372105609067, Test mIoU: 0.650028735957449, LR Backbone: 7.3353011104183164e-06, LR Head: 7.3353011104183164e-06,
Best Learning Rate: 5e-05
SAVING
Epoch: 26, Train Loss: 0.2611015737056732, Val mIoU: 0.5839630922861541, Test mIoU: 0.6100697575349889, LR Backbone: 6.903302895422835e-06, LR Head: 6.903302895422835e-06,
Epoch: 27, Train Loss: 0.2580937445163727, Val mIoU: 0.5292365864461221, Test mIoU: 0.5508243917282007, LR Backbone: 6.468121854390633e-06, LR Head: 6.468121854390633e-06,
Epoch: 28, Train Loss: 0.26191017031669617, Val mIoU: 0.5941905090581983, Test mIoU: 0.5994018034438358, LR Backbone: 6.031878145609371e-06, LR Head: 6.031878145609371e-06,
Epoch: 29, Train Loss: 0.2617851495742798, Val mIoU: 0.6272880552779034, Test mIoU: 0.6503374168605057, LR Backbone: 5.596697104577167e-06, LR Head: 5.596697104577167e-06,
Epoch: 30, Train Loss: 0.2587636709213257, Val mIoU: 0.5766476725040255, Test mIoU: 0.5995914808988402, LR Backbone: 5.164698889581686e-06, LR Head: 5.164698889581686e-06,
Epoch: 31, Train Loss: 0.2583984434604645, Val mIoU: 0.5737250319703241, Test mIoU: 0.5865477538301374, LR Backbone: 4.737988152502077e-06, LR Head: 4.737988152502077e-06,
Epoch: 32, Train Loss: 0.2548515498638153, Val mIoU: 0.5736601005405405, Test mIoU: 0.5943205781579636, LR Backbone: 4.3186437851565795e-06, LR Head: 4.3186437851565795e-06,
Epoch: 33, Train Loss: 0.2550722658634186, Val mIoU: 0.5731721823894642, Test mIoU: 0.5934672849805765, LR Backbone: 3.90870879115055e-06, LR Head: 3.90870879115055e-06,
Epoch: 34, Train Loss: 0.2552851438522339, Val mIoU: 0.6441052325742256, Test mIoU: 0.665038116704096, LR Backbone: 3.5101803325682656e-06, LR Head: 3.5101803325682656e-06,
Best Learning Rate: 5e-05
SAVING
Epoch: 35, Train Loss: 0.25538671016693115, Val mIoU: 0.585248951936436, Test mIoU: 0.6035812489516221, LR Backbone: 3.1250000000000014e-06, LR Head: 3.1250000000000014e-06,
Epoch: 36, Train Loss: 0.25069141387939453, Val mIoU: 0.6068299734185046, Test mIoU: 0.6284510700683642, LR Backbone: 2.7550443533078335e-06, LR Head: 2.7550443533078335e-06,
Epoch: 37, Train Loss: 0.25261327624320984, Val mIoU: 0.5912676447412475, Test mIoU: 0.6084234407615104, LR Backbone: 2.4021157792146356e-06, LR Head: 2.4021157792146356e-06,
Epoch: 38, Train Loss: 0.2509843707084656, Val mIoU: 0.6356393920623071, Test mIoU: 0.6560270009494764, LR Backbone: 2.067933710257136e-06, LR Head: 2.067933710257136e-06,
Epoch: 39, Train Loss: 0.2544277310371399, Val mIoU: 0.634251479935531, Test mIoU: 0.6593959275935795, LR Backbone: 1.75412624788343e-06, LR Head: 1.75412624788343e-06,
Epoch: 40, Train Loss: 0.2535664141178131, Val mIoU: 0.6309390088828515, Test mIoU: 0.652691131282046, LR Backbone: 1.4622222305063882e-06, LR Head: 1.4622222305063882e-06,
Epoch: 41, Train Loss: 0.24940429627895355, Val mIoU: 0.6583203155557642, Test mIoU: 0.6758312558381845, LR Backbone: 1.1936437851565791e-06, LR Head: 1.1936437851565791e-06,
Best Learning Rate: 5e-05
SAVING
Epoch: 42, Train Loss: 0.25354883074760437, Val mIoU: 0.6424199985976718, Test mIoU: 0.660922179908018, LR Backbone: 9.496993990223378e-07, LR Head: 9.496993990223378e-07,
Epoch: 43, Train Loss: 0.25233006477355957, Val mIoU: 0.6198691864213923, Test mIoU: 0.6384410857779194, LR Backbone: 7.315775446317077e-07, LR Head: 7.315775446317077e-07,
Epoch: 44, Train Loss: 0.2527695298194885, Val mIoU: 0.6266568711789078, Test mIoU: 0.6440877669422598, LR Backbone: 5.403408897337453e-07, LR Head: 5.403408897337453e-07,
Epoch: 45, Train Loss: 0.2510976493358612, Val mIoU: 0.6140333793105586, Test mIoU: 0.6306385782182085, LR Backbone: 3.7692112008807306e-07, LR Head: 3.7692112008807306e-07,
Epoch: 46, Train Loss: 0.25098827481269836, Val mIoU: 0.6240059530019331, Test mIoU: 0.6413915054787391, LR Backbone: 2.421144003855083e-07, LR Head: 2.421144003855083e-07,
Epoch: 47, Train Loss: 0.25279882550239563, Val mIoU: 0.625720174921141, Test mIoU: 0.642429144795836, LR Backbone: 1.3657749541371446e-07, LR Head: 1.3657749541371446e-07,
Epoch: 48, Train Loss: 0.25209569931030273, Val mIoU: 0.6274837792702979, Test mIoU: 0.6447522445545356, LR Backbone: 6.082457036518594e-08, LR Head: 6.082457036518594e-08,
Epoch: 49, Train Loss: 0.25129881501197815, Val mIoU: 0.6295934101573892, Test mIoU: 0.647119045722609, LR Backbone: 1.5224685876098765e-08, LR Head: 1.5224685876098765e-08,
Learning Rate: 5e-05
Epoch: 0, Train Loss: 1.3920625448226929, Val mIoU: 0.2835826249822148, Test mIoU: 0.27828454575900563, LR Backbone: 0.0, LR Head: 0.0,
Best Learning Rate: 5e-05
SAVING
Epoch: 1, Train Loss: 0.5694570541381836, Val mIoU: 0.693616694834824, Test mIoU: 0.6944198263309346, LR Backbone: 2.5e-06, LR Head: 2.5e-06,
Best Learning Rate: 5e-05
SAVING
Epoch: 2, Train Loss: 0.2746835947036743, Val mIoU: 0.702828857251731, Test mIoU: 0.7344514217160379, LR Backbone: 5e-06, LR Head: 5e-06,
Best Learning Rate: 5e-05
SAVING
Epoch: 3, Train Loss: 0.24927343428134918, Val mIoU: 0.7487594907815766, Test mIoU: 0.8014494095179254, LR Backbone: 7.500000000000001e-06, LR Head: 7.500000000000001e-06,
Best Learning Rate: 5e-05
SAVING
Epoch: 4, Train Loss: 0.2352929711341858, Val mIoU: 0.6558360081746449, Test mIoU: 0.6578076636354087, LR Backbone: 1e-05, LR Head: 1e-05,
Epoch: 5, Train Loss: 0.22093555331230164, Val mIoU: 0.7107235394191949, Test mIoU: 0.7225288690865084, LR Backbone: 1.25e-05, LR Head: 1.25e-05,

Epoch: 6, Train Loss: 0.21773241460323334, Val mIoU: 0.8660694155393047, Test mIoU: 0.9077768625046121, LR Backbone: 1.2484775314123903e-05, LR Head: 1.2484775314123903e-05,
Best Learning Rate: 5e-05
SAVING
Epoch: 7, Train Loss: 0.2134062498807907, Val mIoU: 0.825877739040854, Test mIoU: 0.8683541360619749, LR Backbone: 1.2439175429634816e-05, LR Head: 1.2439175429634816e-05,
Epoch: 8, Train Loss: 0.20758984982967377, Val mIoU: 0.7448081244393597, Test mIoU: 0.7593451385339509, LR Backbone: 1.2363422504586286e-05, LR Head: 1.2363422504586286e-05,
Epoch: 9, Train Loss: 0.20783594250679016, Val mIoU: 0.8201882158644089, Test mIoU: 0.8599216038613188, LR Backbone: 1.2257885599614494e-05, LR Head: 1.2257885599614494e-05,
Epoch: 10, Train Loss: 0.2043105512857437, Val mIoU: 0.8962261468211655, Test mIoU: 0.9070730929476831, LR Backbone: 1.2123078879911928e-05, LR Head: 1.2123078879911928e-05,
Best Learning Rate: 5e-05
SAVING
Epoch: 11, Train Loss: 0.2048984318971634, Val mIoU: 0.9116768577590701, Test mIoU: 0.9167680714743109, LR Backbone: 1.1959659110266256e-05, LR Head: 1.1959659110266256e-05,
Best Learning Rate: 5e-05
SAVING
Epoch: 12, Train Loss: 0.20228905975818634, Val mIoU: 0.8241122504463358, Test mIoU: 0.841156266442636, LR Backbone: 1.1768422455368295e-05, LR Head: 1.1768422455368295e-05,
Epoch: 13, Train Loss: 0.2008066475391388, Val mIoU: 0.7814621545930331, Test mIoU: 0.7679583841015647, LR Backbone: 1.1550300600977662e-05, LR Head: 1.1550300600977662e-05,
Epoch: 14, Train Loss: 0.2010820358991623, Val mIoU: 0.8578205209993, Test mIoU: 0.8600742453361736, LR Backbone: 1.1306356214843423e-05, LR Head: 1.1306356214843423e-05,
Epoch: 15, Train Loss: 0.19776366651058197, Val mIoU: 0.9286191881547625, Test mIoU: 0.908862190160989, LR Backbone: 1.1037777769493613e-05, LR Head: 1.1037777769493613e-05,
Best Learning Rate: 5e-05
SAVING
Epoch: 16, Train Loss: 0.20270508527755737, Val mIoU: 0.9194946475236913, Test mIoU: 0.9194464043050669, LR Backbone: 1.0745873752116569e-05, LR Head: 1.0745873752116569e-05,
Epoch: 17, Train Loss: 0.19736719131469727, Val mIoU: 0.9237540249380822, Test mIoU: 0.9057734392559598, LR Backbone: 1.0432066289742864e-05, LR Head: 1.0432066289742864e-05,
Epoch: 18, Train Loss: 0.19807617366313934, Val mIoU: 0.9139946704727293, Test mIoU: 0.9156957448730583, LR Backbone: 1.0097884220785363e-05, LR Head: 1.0097884220785363e-05,
Epoch: 19, Train Loss: 0.19434569776058197, Val mIoU: 0.8053570985050771, Test mIoU: 0.7948672281953653, LR Backbone: 9.744955646692168e-06, LR Head: 9.744955646692168e-06,
Epoch: 20, Train Loss: 0.1923828125, Val mIoU: 0.8606330316479285, Test mIoU: 0.8738199668055882, LR Backbone: 9.375000000000001e-06, LR Head: 9.375000000000001e-06,
Epoch: 21, Train Loss: 0.1950332075357437, Val mIoU: 0.9225250449776204, Test mIoU: 0.9030503114234528, LR Backbone: 8.989819667431734e-06, LR Head: 8.989819667431734e-06,
Epoch: 22, Train Loss: 0.1922890692949295, Val mIoU: 0.9541278229153543, Test mIoU: 0.9386440908587519, LR Backbone: 8.59129120884945e-06, LR Head: 8.59129120884945e-06,
Best Learning Rate: 5e-05
SAVING
Epoch: 23, Train Loss: 0.19484961032867432, Val mIoU: 0.9378477929443381, Test mIoU: 0.9207340440890728, LR Backbone: 8.181356214843423e-06, LR Head: 8.181356214843423e-06,
Epoch: 24, Train Loss: 0.19306835532188416, Val mIoU: 0.9292271104701388, Test mIoU: 0.8897057848966814, LR Backbone: 7.762011847497924e-06, LR Head: 7.762011847497924e-06,
Epoch: 25, Train Loss: 0.19368359446525574, Val mIoU: 0.9495788524418898, Test mIoU: 0.9386988150166784, LR Backbone: 7.3353011104183164e-06, LR Head: 7.3353011104183164e-06,
Epoch: 26, Train Loss: 0.19211718440055847, Val mIoU: 0.916699466880198, Test mIoU: 0.8861510499939346, LR Backbone: 6.903302895422835e-06, LR Head: 6.903302895422835e-06,
Epoch: 27, Train Loss: 0.1903418004512787, Val mIoU: 0.9450746817144151, Test mIoU: 0.9220865144790764, LR Backbone: 6.468121854390633e-06, LR Head: 6.468121854390633e-06,
Epoch: 28, Train Loss: 0.19123438000679016, Val mIoU: 0.8107680298239113, Test mIoU: 0.7728454262484254, LR Backbone: 6.031878145609371e-06, LR Head: 6.031878145609371e-06,
Epoch: 29, Train Loss: 0.19272461533546448, Val mIoU: 0.937800095305838, Test mIoU: 0.9220138219389282, LR Backbone: 5.596697104577167e-06, LR Head: 5.596697104577167e-06,
Epoch: 30, Train Loss: 0.18775977194309235, Val mIoU: 0.9449370910027156, Test mIoU: 0.929920128615904, LR Backbone: 5.164698889581686e-06, LR Head: 5.164698889581686e-06,
Epoch: 31, Train Loss: 0.19043749570846558, Val mIoU: 0.9478318114469283, Test mIoU: 0.9128525240674457, LR Backbone: 4.737988152502077e-06, LR Head: 4.737988152502077e-06,
Epoch: 32, Train Loss: 0.18681250512599945, Val mIoU: 0.9303458997279509, Test mIoU: 0.9211311394610748, LR Backbone: 4.3186437851565795e-06, LR Head: 4.3186437851565795e-06,
Epoch: 33, Train Loss: 0.1904941350221634, Val mIoU: 0.9421942209657372, Test mIoU: 0.9211330590158424, LR Backbone: 3.90870879115055e-06, LR Head: 3.90870879115055e-06,
Epoch: 34, Train Loss: 0.18665820360183716, Val mIoU: 0.9504242162675274, Test mIoU: 0.9279805292828841, LR Backbone: 3.5101803325682656e-06, LR Head: 3.5101803325682656e-06,
Epoch: 35, Train Loss: 0.18476171791553497, Val mIoU: 0.9340584410460941, Test mIoU: 0.916761356630444, LR Backbone: 3.1250000000000014e-06, LR Head: 3.1250000000000014e-06,
Epoch: 36, Train Loss: 0.18914061784744263, Val mIoU: 0.9315552984307562, Test mIoU: 0.9107646343252094, LR Backbone: 2.7550443533078335e-06, LR Head: 2.7550443533078335e-06,
Epoch: 37, Train Loss: 0.1856074184179306, Val mIoU: 0.9513475883578815, Test mIoU: 0.928313104107428, LR Backbone: 2.4021157792146356e-06, LR Head: 2.4021157792146356e-06,
Epoch: 38, Train Loss: 0.18820703029632568, Val mIoU: 0.9524973569641484, Test mIoU: 0.9310369050935725, LR Backbone: 2.067933710257136e-06, LR Head: 2.067933710257136e-06,
Epoch: 39, Train Loss: 0.18644140660762787, Val mIoU: 0.9056097335133731, Test mIoU: 0.8740190947935921, LR Backbone: 1.75412624788343e-06, LR Head: 1.75412624788343e-06,
Epoch: 40, Train Loss: 0.18760156631469727, Val mIoU: 0.9052800112160473, Test mIoU: 0.8779545352205964, LR Backbone: 1.4622222305063882e-06, LR Head: 1.4622222305063882e-06,
Epoch: 41, Train Loss: 0.18644726276397705, Val mIoU: 0.939702441945163, Test mIoU: 0.9122502970162654, LR Backbone: 1.1936437851565791e-06, LR Head: 1.1936437851565791e-06,
Epoch: 42, Train Loss: 0.18386328220367432, Val mIoU: 0.9336718231117487, Test mIoU: 0.8973434923145223, LR Backbone: 9.496993990223378e-07, LR Head: 9.496993990223378e-07,
Learning Rate: 8e-05
Epoch: 0, Train Loss: 1.3359687328338623, Val mIoU: 0.2914090459642939, Test mIoU: 0.28632579801517477, LR Backbone: 0.0, LR Head: 0.0,
Best Learning Rate: 8e-05
SAVING
Epoch: 1, Train Loss: 0.47014063596725464, Val mIoU: 0.5501704500589679, Test mIoU: 0.569719983315146, LR Backbone: 4.000000000000001e-06, LR Head: 4.000000000000001e-06,
Best Learning Rate: 8e-05
SAVING
Epoch: 2, Train Loss: 0.26185154914855957, Val mIoU: 0.6708209805275777, Test mIoU: 0.7183894397560715, LR Backbone: 8.000000000000001e-06, LR Head: 8.000000000000001e-06,
Best Learning Rate: 8e-05
SAVING
Epoch: 3, Train Loss: 0.2332753837108612, Val mIoU: 0.6330033253175043, Test mIoU: 0.6375335158396745, LR Backbone: 1.2000000000000002e-05, LR Head: 1.2000000000000002e-05,
Epoch: 4, Train Loss: 0.22688867151737213, Val mIoU: 0.8220728213629762, Test mIoU: 0.8623771560644058, LR Backbone: 1.6000000000000003e-05, LR Head: 1.6000000000000003e-05,
Best Learning Rate: 8e-05
SAVING
Epoch: 5, Train Loss: 0.2172207087278366, Val mIoU: 0.7786122710068735, Test mIoU: 0.8188543915626014, LR Backbone: 2e-05, LR Head: 2e-05,
Epoch: 6, Train Loss: 0.21094530820846558, Val mIoU: 0.8835432492578273, Test mIoU: 0.9034540562872112, LR Backbone: 1.9975640502598243e-05, LR Head: 1.9975640502598243e-05,
Best Learning Rate: 8e-05
SAVING
Epoch: 7, Train Loss: 0.21151171624660492, Val mIoU: 0.8616100990221984, Test mIoU: 0.8948977052093665, LR Backbone: 1.9902680687415704e-05, LR Head: 1.9902680687415704e-05,
Epoch: 8, Train Loss: 0.2072441428899765, Val mIoU: 0.9006498293933385, Test mIoU: 0.9125428977076266, LR Backbone: 1.9781476007338058e-05, LR Head: 1.9781476007338058e-05,
Best Learning Rate: 8e-05
SAVING

Epoch: 9, Train Loss: 0.2049218714237213, Val mIoU: 0.9034492080850067, Test mIoU: 0.9181889286153635, LR Backbone: 1.961261695938319e-05, LR Head: 1.961261695938319e-05,
Best Learning Rate: 8e-05
SAVING
Epoch: 10, Train Loss: 0.20320898294448853, Val mIoU: 0.9395538373338651, Test mIoU: 0.9273952564763226, LR Backbone: 1.9396926207859085e-05, LR Head: 1.9396926207859085e-05,
Best Learning Rate: 8e-05
SAVING
Epoch: 11, Train Loss: 0.2018144577741623, Val mIoU: 0.8998696707821039, Test mIoU: 0.9185590763762455, LR Backbone: 1.913545457642601e-05, LR Head: 1.913545457642601e-05,
Epoch: 12, Train Loss: 0.1982753872871399, Val mIoU: 0.7950295628582713, Test mIoU: 0.8253772396094782, LR Backbone: 1.8829475928589272e-05, LR Head: 1.8829475928589272e-05,
Epoch: 13, Train Loss: 0.20298242568969727, Val mIoU: 0.9349773005359228, Test mIoU: 0.9318658552858178, LR Backbone: 1.848048096156426e-05, LR Head: 1.848048096156426e-05,
Epoch: 14, Train Loss: 0.19716796278953552, Val mIoU: 0.8585491186186406, Test mIoU: 0.8883754459910758, LR Backbone: 1.8090169943749477e-05, LR Head: 1.8090169943749477e-05,
Epoch: 15, Train Loss: 0.19850195944309235, Val mIoU: 0.8832337313686957, Test mIoU: 0.8991869369895369, LR Backbone: 1.766044443118978e-05, LR Head: 1.766044443118978e-05,
Epoch: 16, Train Loss: 0.19686132669448853, Val mIoU: 0.8706408359434147, Test mIoU: 0.8832755597546211, LR Backbone: 1.7193398003386514e-05, LR Head: 1.7193398003386514e-05,
Epoch: 17, Train Loss: 0.19516797363758087, Val mIoU: 0.8890390977485232, Test mIoU: 0.8950969787191351, LR Backbone: 1.6691306063588583e-05, LR Head: 1.6691306063588583e-05,
Epoch: 18, Train Loss: 0.19361522793769836, Val mIoU: 0.9412550613390461, Test mIoU: 0.9377705568056507, LR Backbone: 1.6156614753256583e-05, LR Head: 1.6156614753256583e-05,
Best Learning Rate: 8e-05
SAVING
Epoch: 19, Train Loss: 0.1955859363079071, Val mIoU: 0.895920960950353, Test mIoU: 0.8916085090801911, LR Backbone: 1.5591929034707468e-05, LR Head: 1.5591929034707468e-05,
Epoch: 20, Train Loss: 0.1929042935371399, Val mIoU: 0.8949551032963652, Test mIoU: 0.9146498595450312, LR Backbone: 1.5000000000000002e-05, LR Head: 1.5000000000000002e-05,
Epoch: 21, Train Loss: 0.1965000033378601, Val mIoU: 0.8532879980078336, Test mIoU: 0.8743420862110619, LR Backbone: 1.4383711467890776e-05, LR Head: 1.4383711467890776e-05,
Epoch: 22, Train Loss: 0.19117774069309235, Val mIoU: 0.8729467440646338, Test mIoU: 0.8912710454708916, LR Backbone: 1.374606593415912e-05, LR Head: 1.374606593415912e-05,
Epoch: 23, Train Loss: 0.18852050602436066, Val mIoU: 0.9311717524639862, Test mIoU: 0.9328046820390385, LR Backbone: 1.3090169943749475e-05, LR Head: 1.3090169943749475e-05,
Epoch: 24, Train Loss: 0.18888281285762787, Val mIoU: 0.903112915041481, Test mIoU: 0.8914931312299033, LR Backbone: 1.2419218955996679e-05, LR Head: 1.2419218955996679e-05,
Epoch: 25, Train Loss: 0.18794922530651093, Val mIoU: 0.7720455761604414, Test mIoU: 0.7701844092731022, LR Backbone: 1.1736481776669307e-05, LR Head: 1.1736481776669307e-05,
Epoch: 26, Train Loss: 0.1886601597070694, Val mIoU: 0.9303090894070197, Test mIoU: 0.9290118473894009, LR Backbone: 1.1045284632676535e-05, LR Head: 1.1045284632676535e-05,
Epoch: 27, Train Loss: 0.18783985078334808, Val mIoU: 0.8888133108553589, Test mIoU: 0.8883881706272323, LR Backbone: 1.0348994967025012e-05, LR Head: 1.0348994967025012e-05,
Epoch: 28, Train Loss: 0.18747460842132568, Val mIoU: 0.9403910125592415, Test mIoU: 0.9301493352035143, LR Backbone: 9.651005032974994e-06, LR Head: 9.651005032974994e-06,
Epoch: 29, Train Loss: 0.1861249953508377, Val mIoU: 0.9484034536895212, Test mIoU: 0.9275294052615195, LR Backbone: 8.954715367323468e-06, LR Head: 8.954715367323468e-06,
Best Learning Rate: 8e-05
SAVING
Epoch: 30, Train Loss: 0.18686524033546448, Val mIoU: 0.9117687877076364, Test mIoU: 0.8805320880538592, LR Backbone: 8.263518223330698e-06, LR Head: 8.263518223330698e-06,
Epoch: 31, Train Loss: 0.18735352158546448, Val mIoU: 0.8941863876888285, Test mIoU: 0.8944372911647844, LR Backbone: 7.580781044003323e-06, LR Head: 7.580781044003323e-06,
Epoch: 32, Train Loss: 0.18830469250679016, Val mIoU: 0.8861484809478003, Test mIoU: 0.8809293745079241, LR Backbone: 6.909830056250527e-06, LR Head: 6.909830056250527e-06,
Epoch: 33, Train Loss: 0.1857871115207672, Val mIoU: 0.961517899045115, Test mIoU: 0.9328772401987877, LR Backbone: 6.25393406584088e-06, LR Head: 6.25393406584088e-06,
Best Learning Rate: 8e-05
SAVING
Epoch: 34, Train Loss: 0.18321679532527924, Val mIoU: 0.9240527670142246, Test mIoU: 0.9136547182823334, LR Backbone: 5.616288532109225e-06, LR Head: 5.616288532109225e-06,
Epoch: 35, Train Loss: 0.18562500178813934, Val mIoU: 0.9429675290417221, Test mIoU: 0.925244845062615, LR Backbone: 5.000000000000003e-06, LR Head: 5.000000000000003e-06,
Epoch: 36, Train Loss: 0.18241992592811584, Val mIoU: 0.9368791949593531, Test mIoU: 0.9235350435729, LR Backbone: 4.408070965292534e-06, LR Head: 4.408070965292534e-06,
Epoch: 37, Train Loss: 0.182679682970047, Val mIoU: 0.9351285365794768, Test mIoU: 0.906327695924878, LR Backbone: 3.8433852467434175e-06, LR Head: 3.8433852467434175e-06,
Epoch: 38, Train Loss: 0.18344727158546448, Val mIoU: 0.9422404270358946, Test mIoU: 0.9292768726627304, LR Backbone: 3.308693936411418e-06, LR Head: 3.308693936411418e-06,
Epoch: 39, Train Loss: 0.18465234339237213, Val mIoU: 0.9448332781309756, Test mIoU: 0.9194018497302077, LR Backbone: 2.806601996613488e-06, LR Head: 2.806601996613488e-06,
Epoch: 40, Train Loss: 0.18063867092132568, Val mIoU: 0.9272558983039236, Test mIoU: 0.8945839170398424, LR Backbone: 2.339555568810221e-06, LR Head: 2.339555568810221e-06,
Epoch: 41, Train Loss: 0.1849375069141388, Val mIoU: 0.936853832944003, Test mIoU: 0.9159854653433981, LR Backbone: 1.9098300562505266e-06, LR Head: 1.9098300562505266e-06,
Epoch: 42, Train Loss: 0.18314257264137268, Val mIoU: 0.9315160499149688, Test mIoU: 0.9099087008639813, LR Backbone: 1.5195190384357405e-06, LR Head: 1.5195190384357405e-06,
Epoch: 43, Train Loss: 0.18340429663658142, Val mIoU: 0.9204587152484791, Test mIoU: 0.8920247444400826, LR Backbone: 1.1705240714107324e-06, LR Head: 1.1705240714107324e-06,
Epoch: 44, Train Loss: 0.18289843201637268, Val mIoU: 0.932218263177922, Test mIoU: 0.9014852128223352, LR Backbone: 8.645454235739925e-07, LR Head: 8.645454235739925e-07,
Epoch: 45, Train Loss: 0.18225781619548798, Val mIoU: 0.9268672781015361, Test mIoU: 0.8977492806072319, LR Backbone: 6.030737921409169e-07, LR Head: 6.030737921409169e-07,
Epoch: 46, Train Loss: 0.18338671326637268, Val mIoU: 0.9271275637648617, Test mIoU: 0.8974066104889525, LR Backbone: 3.873830406168133e-07, LR Head: 3.873830406168133e-07,
Epoch: 47, Train Loss: 0.1816679686307907, Val mIoU: 0.9341546894185014, Test mIoU: 0.9054492811785897, LR Backbone: 2.1852399266194312e-07, LR Head: 2.1852399266194312e-07,
Epoch: 48, Train Loss: 0.18251366913318634, Val mIoU: 0.9342763193199778, Test mIoU: 0.905173753962855, LR Backbone: 9.73193125842975e-08, LR Head: 9.73193125842975e-08,
Epoch: 49, Train Loss: 0.18149609863758087, Val mIoU: 0.9349046141678583, Test mIoU: 0.9058573316725942, LR Backbone: 2.4359497401758026e-08, LR Head: 2.4359497401758026e-08,
Learning Rate: 8e-05
Epoch: 0, Train Loss: 1.3137500286102295, Val mIoU: 0.30030765086543676, Test mIoU: 0.29637795052071964, LR Backbone: 0.0, LR Head: 0.0,
Best Learning Rate: 8e-05
SAVING
Epoch: 1, Train Loss: 0.5221640467643738, Val mIoU: 0.43892454950132365, Test mIoU: 0.45736159342371785, LR Backbone: 4.000000000000001e-06, LR Head: 4.000000000000001e-06,
Best Learning Rate: 8e-05
SAVING
Epoch: 2, Train Loss: 0.33607813715934753, Val mIoU: 0.44255723919648315, Test mIoU: 0.4642228627055245, LR Backbone: 8.000000000000001e-06, LR Head: 8.000000000000001e-06,
Best Learning Rate: 8e-05
SAVING
Epoch: 3, Train Loss: 0.3155234456062317, Val mIoU: 0.48436375644562796, Test mIoU: 0.5171020453821664, LR Backbone: 1.2000000000000002e-05, LR Head: 1.2000000000000002e-05,
Best Learning Rate: 8e-05
SAVING
Epoch: 4, Train Loss: 0.31022655963897705, Val mIoU: 0.5582945939450812, Test mIoU: 0.5856715306767075, LR Backbone: 1.6000000000000003e-05, LR Head: 1.6000000000000003e-05,
Best Learning Rate: 8e-05
SAVING

Epoch: 5, Train Loss: 0.2992500066757202, Val mIoU: 0.5292913521949126, Test mIoU: 0.5602209871312587, LR Backbone: 2e-05, LR Head: 2e-05,
Epoch: 6, Train Loss: 0.29530468583106995, Val mIoU: 0.4665135786053106, Test mIoU: 0.4945186514724374, LR Backbone: 1.9975640502598243e-05, LR Head: 1.9975640502598243e-05,
Epoch: 7, Train Loss: 0.2839687466621399, Val mIoU: 0.5412442392589892, Test mIoU: 0.5512309091276801, LR Backbone: 1.9902680687415704e-05, LR Head: 1.9902680687415704e-05,
Epoch: 8, Train Loss: 0.2828066349029541, Val mIoU: 0.5846652395299715, Test mIoU: 0.6099307454720422, LR Backbone: 1.9781476007338058e-05, LR Head: 1.9781476007338058e-05,
Best Learning Rate: 8e-05
SAVING
Epoch: 9, Train Loss: 0.27815625071525574, Val mIoU: 0.6381481887266811, Test mIoU: 0.683451589915343, LR Backbone: 1.961261695938319e-05, LR Head: 1.961261695938319e-05,
Best Learning Rate: 8e-05
SAVING
Epoch: 10, Train Loss: 0.27888086438179016, Val mIoU: 0.5806131354322135, Test mIoU: 0.5866821310606237, LR Backbone: 1.9396926207859085e-05, LR Head: 1.9396926207859085e-05,
Epoch: 11, Train Loss: 0.27577343583106995, Val mIoU: 0.5977513357810817, Test mIoU: 0.5945538045302149, LR Backbone: 1.913545457642601e-05, LR Head: 1.913545457642601e-05,
Epoch: 12, Train Loss: 0.27402734756469727, Val mIoU: 0.581349981946683, Test mIoU: 0.5923304935390874, LR Backbone: 1.8829475928589272e-05, LR Head: 1.8829475928589272e-05,
Epoch: 13, Train Loss: 0.2697070240974426, Val mIoU: 0.5076901519024808, Test mIoU: 0.5113776622380486, LR Backbone: 1.848048096156426e-05, LR Head: 1.848048096156426e-05,
Epoch: 14, Train Loss: 0.26979687809944153, Val mIoU: 0.634358476291061, Test mIoU: 0.6477000764114282, LR Backbone: 1.8090169943749477e-05, LR Head: 1.8090169943749477e-05,
Epoch: 15, Train Loss: 0.26908203959465027, Val mIoU: 0.4912979216604678, Test mIoU: 0.4845593376553536, LR Backbone: 1.766044443118978e-05, LR Head: 1.766044443118978e-05,
Epoch: 16, Train Loss: 0.26592186093330383, Val mIoU: 0.5496265640714267, Test mIoU: 0.5479968286231537, LR Backbone: 1.7193398003386514e-05, LR Head: 1.7193398003386514e-05,
Epoch: 17, Train Loss: 0.2609316408634186, Val mIoU: 0.7251434539529913, Test mIoU: 0.7400877610191743, LR Backbone: 1.6691306063588583e-05, LR Head: 1.6691306063588583e-05,
Best Learning Rate: 8e-05
SAVING
Epoch: 18, Train Loss: 0.26274022459983826, Val mIoU: 0.509688704122315, Test mIoU: 0.5207289693215028, LR Backbone: 1.6156614753256583e-05, LR Head: 1.6156614753256583e-05,
Epoch: 19, Train Loss: 0.26085546612739563, Val mIoU: 0.5695850038466803, Test mIoU: 0.5802322903121315, LR Backbone: 1.5591929034707468e-05, LR Head: 1.5591929034707468e-05,
Epoch: 20, Train Loss: 0.2613164186477661, Val mIoU: 0.5592014826381626, Test mIoU: 0.567706669729088, LR Backbone: 1.5000000000000002e-05, LR Head: 1.5000000000000002e-05,
Epoch: 21, Train Loss: 0.25858983397483826, Val mIoU: 0.6055906915521649, Test mIoU: 0.619355843483202, LR Backbone: 1.4383711467890776e-05, LR Head: 1.4383711467890776e-05,
Epoch: 22, Train Loss: 0.2559492290019989, Val mIoU: 0.5846531297088577, Test mIoU: 0.5767363107576309, LR Backbone: 1.374606593415912e-05, LR Head: 1.374606593415912e-05,
Epoch: 23, Train Loss: 0.2606523334980011, Val mIoU: 0.5689872120867644, Test mIoU: 0.570886529819027, LR Backbone: 1.3090169943749475e-05, LR Head: 1.3090169943749475e-05,
Epoch: 24, Train Loss: 0.25208789110183716, Val mIoU: 0.5758759385462447, Test mIoU: 0.5714774723730158, LR Backbone: 1.2419218955996679e-05, LR Head: 1.2419218955996679e-05,
Epoch: 25, Train Loss: 0.2524140477180481, Val mIoU: 0.6554073133709061, Test mIoU: 0.6510824953461116, LR Backbone: 1.1736481776669307e-05, LR Head: 1.1736481776669307e-05,
Epoch: 26, Train Loss: 0.257443368434906, Val mIoU: 0.5464689827164706, Test mIoU: 0.5421784028921731, LR Backbone: 1.1045284632676535e-05, LR Head: 1.1045284632676535e-05,
Epoch: 27, Train Loss: 0.2540000081062317, Val mIoU: 0.671093109836039, Test mIoU: 0.6624554254963917, LR Backbone: 1.0348994967025012e-05, LR Head: 1.0348994967025012e-05,
Epoch: 28, Train Loss: 0.24830859899520874, Val mIoU: 0.6000143336738207, Test mIoU: 0.6024991018844801, LR Backbone: 9.651005032974994e-06, LR Head: 9.651005032974994e-06,
Epoch: 29, Train Loss: 0.2503984272480011, Val mIoU: 0.6213098591167208, Test mIoU: 0.6193131562349874, LR Backbone: 8.954715367323468e-06, LR Head: 8.954715367323468e-06,
Epoch: 30, Train Loss: 0.25148826837539673, Val mIoU: 0.5287552337962453, Test mIoU: 0.519630658295652, LR Backbone: 8.263518223330698e-06, LR Head: 8.263518223330698e-06,
Epoch: 31, Train Loss: 0.24864453077316284, Val mIoU: 0.5825748621421976, Test mIoU: 0.5775818014780036, LR Backbone: 7.580781044003323e-06, LR Head: 7.580781044003323e-06,
Epoch: 32, Train Loss: 0.250914067029953, Val mIoU: 0.6263076958083124, Test mIoU: 0.6189484774165968, LR Backbone: 6.909830056250527e-06, LR Head: 6.909830056250527e-06,
Epoch: 33, Train Loss: 0.24817383289337158, Val mIoU: 0.6151044149057806, Test mIoU: 0.6279343053092916, LR Backbone: 6.25393406584088e-06, LR Head: 6.25393406584088e-06,
Epoch: 34, Train Loss: 0.24610351026058197, Val mIoU: 0.6487345199750159, Test mIoU: 0.6526386137304512, LR Backbone: 5.616288532109225e-06, LR Head: 5.616288532109225e-06,
Epoch: 35, Train Loss: 0.24993360042572021, Val mIoU: 0.5804885460051287, Test mIoU: 0.569174740126251, LR Backbone: 5.000000000000003e-06, LR Head: 5.000000000000003e-06,
Epoch: 36, Train Loss: 0.24858398735523224, Val mIoU: 0.6534159497625275, Test mIoU: 0.6385949937700285, LR Backbone: 4.408070965292534e-06, LR Head: 4.408070965292534e-06,
Epoch: 37, Train Loss: 0.24882422387599945, Val mIoU: 0.6178104757912247, Test mIoU: 0.6078642896552939, LR Backbone: 3.8433852467434175e-06, LR Head: 3.8433852467434175e-06,
Learning Rate: 8e-05
Epoch: 0, Train Loss: 1.3391562700271606, Val mIoU: 0.28748311487025074, Test mIoU: 0.2823085204445671, LR Backbone: 0.0, LR Head: 0.0,
Best Learning Rate: 8e-05
SAVING
Epoch: 1, Train Loss: 0.4456445276737213, Val mIoU: 0.7641871357195296, Test mIoU: 0.7871321626048973, LR Backbone: 4.000000000000001e-06, LR Head: 4.000000000000001e-06,
Best Learning Rate: 8e-05
SAVING
Epoch: 2, Train Loss: 0.27180078625679016, Val mIoU: 0.6783073539330668, Test mIoU: 0.7096470054830014, LR Backbone: 8.000000000000001e-06, LR Head: 8.000000000000001e-06,
Epoch: 3, Train Loss: 0.24777929484844208, Val mIoU: 0.7674132172471302, Test mIoU: 0.8264970197576018, LR Backbone: 1.2000000000000002e-05, LR Head: 1.2000000000000002e-05,
Best Learning Rate: 8e-05
SAVING
Epoch: 4, Train Loss: 0.23191796243190765, Val mIoU: 0.7735418503430436, Test mIoU: 0.8233059630780352, LR Backbone: 1.6000000000000003e-05, LR Head: 1.6000000000000003e-05,
Best Learning Rate: 8e-05
SAVING
Epoch: 5, Train Loss: 0.2214999943971634, Val mIoU: 0.8288914459078345, Test mIoU: 0.8617180325516653, LR Backbone: 2e-05, LR Head: 2e-05,
Best Learning Rate: 8e-05
SAVING
Epoch: 6, Train Loss: 0.21445313096046448, Val mIoU: 0.7941752284593917, Test mIoU: 0.842846268757536, LR Backbone: 1.9975640502598243e-05, LR Head: 1.9975640502598243e-05,
Epoch: 7, Train Loss: 0.21228711307048798, Val mIoU: 0.7904706749531409, Test mIoU: 0.8586606642322219, LR Backbone: 1.9902680687415704e-05, LR Head: 1.9902680687415704e-05,
Epoch: 8, Train Loss: 0.20920702815055847, Val mIoU: 0.756198616309087, Test mIoU: 0.8045295534795646, LR Backbone: 1.9781476007338058e-05, LR Head: 1.9781476007338058e-05,
Epoch: 9, Train Loss: 0.20951563119888306, Val mIoU: 0.7756053912111684, Test mIoU: 0.8368143519892899, LR Backbone: 1.961261695938319e-05, LR Head: 1.961261695938319e-05,
Epoch: 10, Train Loss: 0.20378319919109344, Val mIoU: 0.840500165745238, Test mIoU: 0.8800341807973466, LR Backbone: 1.9396926207859085e-05, LR Head: 1.9396926207859085e-05,
Best Learning Rate: 8e-05
SAVING
Epoch: 11, Train Loss: 0.20460547506809235, Val mIoU: 0.8971202667932281, Test mIoU: 0.9189914622628939, LR Backbone: 1.913545457642601e-05, LR Head: 1.913545457642601e-05,
Best Learning Rate: 8e-05
SAVING
Epoch: 12, Train Loss: 0.20103320479393005, Val mIoU: 0.6930532673586884, Test mIoU: 0.6979234763046398, LR Backbone: 1.8829475928589272e-05, LR Head: 1.8829475928589272e-05,

Epoch: 13, Train Loss: 0.1992460936307907, Val mIoU: 0.8218578970299937, Test mIoU: 0.8482499579217349, LR Backbone: 1.848048096156426e-05, LR Head: 1.848048096156426e-05,
Epoch: 14, Train Loss: 0.2017480432987213, Val mIoU: 0.8077352722889389, Test mIoU: 0.8449146129544439, LR Backbone: 1.8090169943749477e-05, LR Head: 1.8090169943749477e-05,
Epoch: 15, Train Loss: 0.1979101598262787, Val mIoU: 0.8086344320403749, Test mIoU: 0.8466173213572588, LR Backbone: 1.766044443118978e-05, LR Head: 1.766044443118978e-05,
Epoch: 16, Train Loss: 0.19719530642032623, Val mIoU: 0.8613338808930602, Test mIoU: 0.8789755315067274, LR Backbone: 1.7193398003386514e-05, LR Head: 1.7193398003386514e-05,
Epoch: 17, Train Loss: 0.19706054031848907, Val mIoU: 0.8264957695441506, Test mIoU: 0.8191765720797661, LR Backbone: 1.6691306063588583e-05, LR Head: 1.6691306063588583e-05,
Epoch: 18, Train Loss: 0.19727930426597595, Val mIoU: 0.9445198060176312, Test mIoU: 0.9404647361588923, LR Backbone: 1.6156614753256583e-05, LR Head: 1.6156614753256583e-05,
Best Learning Rate: 8e-05
SAVING
Epoch: 19, Train Loss: 0.1979043036699295, Val mIoU: 0.8748415958693763, Test mIoU: 0.8901372756658013, LR Backbone: 1.5591929034707468e-05, LR Head: 1.5591929034707468e-05,
Epoch: 20, Train Loss: 0.19403710961341858, Val mIoU: 0.7963561289690846, Test mIoU: 0.8283343891124358, LR Backbone: 1.5000000000000002e-05, LR Head: 1.5000000000000002e-05,
Epoch: 21, Train Loss: 0.19138671457767487, Val mIoU: 0.7385958279697342, Test mIoU: 0.7447843380441523, LR Backbone: 1.4383711467890776e-05, LR Head: 1.4383711467890776e-05,
Epoch: 22, Train Loss: 0.19141601026058197, Val mIoU: 0.8554482080632471, Test mIoU: 0.8803208999440899, LR Backbone: 1.374606593415912e-05, LR Head: 1.374606593415912e-05,
Epoch: 23, Train Loss: 0.19223828613758087, Val mIoU: 0.7601990255710751, Test mIoU: 0.7694403130692036, LR Backbone: 1.3090169943749475e-05, LR Head: 1.3090169943749475e-05,
Epoch: 24, Train Loss: 0.1904316395521164, Val mIoU: 0.9074793719570458, Test mIoU: 0.9168797755897515, LR Backbone: 1.2419218955996679e-05, LR Head: 1.2419218955996679e-05,
Epoch: 25, Train Loss: 0.18763378262519836, Val mIoU: 0.913368508908569, Test mIoU: 0.9131863847886217, LR Backbone: 1.1736481776669307e-05, LR Head: 1.1736481776669307e-05,
Epoch: 26, Train Loss: 0.1946992129087448, Val mIoU: 0.8433048317942607, Test mIoU: 0.8615068626409916, LR Backbone: 1.1045284632676535e-05, LR Head: 1.1045284632676535e-05,
Epoch: 27, Train Loss: 0.18781445920467377, Val mIoU: 0.9399724012945121, Test mIoU: 0.932739340518697, LR Backbone: 1.0348994967025012e-05, LR Head: 1.0348994967025012e-05,
Epoch: 28, Train Loss: 0.19014649093151093, Val mIoU: 0.8548905072356503, Test mIoU: 0.8540669639670386, LR Backbone: 9.651005032974994e-06, LR Head: 9.651005032974994e-06,
Epoch: 29, Train Loss: 0.18974219262599945, Val mIoU: 0.9191648329322548, Test mIoU: 0.9313576686427728, LR Backbone: 8.954715367323468e-06, LR Head: 8.954715367323468e-06,
Epoch: 30, Train Loss: 0.18684960901737213, Val mIoU: 0.8561724985009644, Test mIoU: 0.8842871980515512, LR Backbone: 8.263518223330698e-06, LR Head: 8.263518223330698e-06,
Epoch: 31, Train Loss: 0.1901269555091858, Val mIoU: 0.8798231281586911, Test mIoU: 0.8922198063578464, LR Backbone: 7.580781044003323e-06, LR Head: 7.580781044003323e-06,
Epoch: 32, Train Loss: 0.18718554079532623, Val mIoU: 0.9128854578434027, Test mIoU: 0.9213620829170661, LR Backbone: 6.909830056250527e-06, LR Head: 6.909830056250527e-06,
Epoch: 33, Train Loss: 0.1910078078508377, Val mIoU: 0.868984576411477, Test mIoU: 0.8629998041195552, LR Backbone: 6.25393406584088e-06, LR Head: 6.25393406584088e-06,
Epoch: 34, Train Loss: 0.18644140660762787, Val mIoU: 0.8387320619612358, Test mIoU: 0.8462325820304601, LR Backbone: 5.616288532109225e-06, LR Head: 5.616288532109225e-06,
Epoch: 35, Train Loss: 0.1860664039850235, Val mIoU: 0.8937616545246965, Test mIoU: 0.887593579622353, LR Backbone: 5.000000000000003e-06, LR Head: 5.000000000000003e-06,
Epoch: 36, Train Loss: 0.1868261694908142, Val mIoU: 0.8770624509727911, Test mIoU: 0.8703431092139144, LR Backbone: 4.408070965292534e-06, LR Head: 4.408070965292534e-06,
Epoch: 37, Train Loss: 0.18528710305690765, Val mIoU: 0.8778265455903758, Test mIoU: 0.8827532084726446, LR Backbone: 3.8433852467434175e-06, LR Head: 3.8433852467434175e-06,
Epoch: 38, Train Loss: 0.18523046374320984, Val mIoU: 0.8664454708456775, Test mIoU: 0.8739716327245212, LR Backbone: 3.308693936411418e-06, LR Head: 3.308693936411418e-06,
Learning Rate: 0.0001
Epoch: 0, Train Loss: 1.2935937643051147, Val mIoU: 0.2965295341398678, Test mIoU: 0.2915693605798007, LR Backbone: 0.0, LR Head: 0.0,
Best Learning Rate: 0.0001
SAVING
Epoch: 1, Train Loss: 0.4147109389305115, Val mIoU: 0.5766290514810737, Test mIoU: 0.5798490471619674, LR Backbone: 5e-06, LR Head: 5e-06,
Best Learning Rate: 0.0001
SAVING
Epoch: 2, Train Loss: 0.25432032346725464, Val mIoU: 0.7095957233787331, Test mIoU: 0.7495896740557596, LR Backbone: 1e-05, LR Head: 1e-05,
Best Learning Rate: 0.0001
SAVING
Epoch: 3, Train Loss: 0.23176172375679016, Val mIoU: 0.6870437378523115, Test mIoU: 0.6986817436814629, LR Backbone: 1.5000000000000002e-05, LR Head: 1.5000000000000002e-05,
Epoch: 4, Train Loss: 0.22543750703334808, Val mIoU: 0.8450478941262236, Test mIoU: 0.8929182834452525, LR Backbone: 2e-05, LR Head: 2e-05,
Best Learning Rate: 0.0001
SAVING
Epoch: 5, Train Loss: 0.21603906154632568, Val mIoU: 0.7227366627350111, Test mIoU: 0.7785869689345906, LR Backbone: 2.5e-05, LR Head: 2.5e-05,
Epoch: 6, Train Loss: 0.2117343693971634, Val mIoU: 0.8191382559657516, Test mIoU: 0.8642350302289739, LR Backbone: 2.4969550628247805e-05, LR Head: 2.4969550628247805e-05,
Epoch: 7, Train Loss: 0.20826563239097595, Val mIoU: 0.8974517587421589, Test mIoU: 0.9189765224537435, LR Backbone: 2.487835085926963e-05, LR Head: 2.487835085926963e-05,
Best Learning Rate: 0.0001
SAVING
Epoch: 8, Train Loss: 0.20304882526397705, Val mIoU: 0.87632038301024, Test mIoU: 0.8884522737628167, LR Backbone: 2.4726845009172572e-05, LR Head: 2.4726845009172572e-05,
Epoch: 9, Train Loss: 0.20237109065055847, Val mIoU: 0.9286226130869277, Test mIoU: 0.9261400270028712, LR Backbone: 2.4515771199228987e-05, LR Head: 2.4515771199228987e-05,
Best Learning Rate: 0.0001
SAVING
Epoch: 10, Train Loss: 0.20070117712020874, Val mIoU: 0.8000771936495922, Test mIoU: 0.8190105520949597, LR Backbone: 2.4246157759823855e-05, LR Head: 2.4246157759823855e-05,
Epoch: 11, Train Loss: 0.20051172375679016, Val mIoU: 0.79253182506556, Test mIoU: 0.8312298357124941, LR Backbone: 2.391931822053251e-05, LR Head: 2.391931822053251e-05,
Epoch: 12, Train Loss: 0.19834180176258087, Val mIoU: 0.9055661838855542, Test mIoU: 0.923635748248123, LR Backbone: 2.353684491073659e-05, LR Head: 2.353684491073659e-05,
Epoch: 13, Train Loss: 0.1936015635728836, Val mIoU: 0.87023638213872, Test mIoU: 0.8931659576212203, LR Backbone: 2.3100601201955324e-05, LR Head: 2.3100601201955324e-05,
Epoch: 14, Train Loss: 0.19764453172683716, Val mIoU: 0.927884928270475, Test mIoU: 0.9284150200236905, LR Backbone: 2.2612712429686845e-05, LR Head: 2.2612712429686845e-05,
Epoch: 15, Train Loss: 0.19404882192611694, Val mIoU: 0.8760778438642185, Test mIoU: 0.8926035387022153, LR Backbone: 2.2075555538987227e-05, LR Head: 2.2075555538987227e-05,
Epoch: 16, Train Loss: 0.1963769495487213, Val mIoU: 0.8428879849626392, Test mIoU: 0.8698349119382831, LR Backbone: 2.1491747504233138e-05, LR Head: 2.1491747504233138e-05,
Epoch: 17, Train Loss: 0.19521678984165192, Val mIoU: 0.9211216502662765, Test mIoU: 0.9131892128106313, LR Backbone: 2.086413257948573e-05, LR Head: 2.086413257948573e-05,
Epoch: 18, Train Loss: 0.19045117497444153, Val mIoU: 0.8976155967134868, Test mIoU: 0.8933588152588486, LR Backbone: 2.0195768441570727e-05, LR Head: 2.0195768441570727e-05,
Epoch: 19, Train Loss: 0.18992969393730164, Val mIoU: 0.9001834820343153, Test mIoU: 0.9093908335266658, LR Backbone: 1.9489911293384337e-05, LR Head: 1.9489911293384337e-05,
Epoch: 20, Train Loss: 0.19150391221046448, Val mIoU: 0.8336408692934156, Test mIoU: 0.8343750235646119, LR Backbone: 1.8750000000000002e-05, LR Head: 1.8750000000000002e-05,

Epoch: 21, Train Loss: 0.19011327624320984, Val mIoU: 0.9149071086839606, Test mIoU: 0.906607515739937, LR Backbone: 1.7979639334863467e-05, LR Head: 1.7979639334863467e-05,
Epoch: 22, Train Loss: 0.19051562249660492, Val mIoU: 0.9521272438872538, Test mIoU: 0.9383592762700297, LR Backbone: 1.71825824176989e-05, LR Head: 1.71825824176989e-05,
Best Learning Rate: 0.0001
SAVING
Epoch: 23, Train Loss: 0.1902167946100235, Val mIoU: 0.9097417493006656, Test mIoU: 0.9030199960543963, LR Backbone: 1.6362712429686846e-05, LR Head: 1.6362712429686846e-05,
Epoch: 24, Train Loss: 0.1855507791042328, Val mIoU: 0.9339020259115887, Test mIoU: 0.9196259563424973, LR Backbone: 1.5524023694995848e-05, LR Head: 1.5524023694995848e-05,
Epoch: 25, Train Loss: 0.18918554484844208, Val mIoU: 0.910463274760718, Test mIoU: 0.9157091034333804, LR Backbone: 1.4670602220836633e-05, LR Head: 1.4670602220836633e-05,
Epoch: 26, Train Loss: 0.19002538919448853, Val mIoU: 0.9313964313906402, Test mIoU: 0.923099767469755, LR Backbone: 1.380660579084567e-05, LR Head: 1.380660579084567e-05,
Epoch: 27, Train Loss: 0.18558593094348907, Val mIoU: 0.9139833225795801, Test mIoU: 0.9098331156376205, LR Backbone: 1.2936243708781266e-05, LR Head: 1.2936243708781266e-05,
Epoch: 28, Train Loss: 0.1848164051771164, Val mIoU: 0.9542525813425471, Test mIoU: 0.9358181419741612, LR Backbone: 1.2063756291218742e-05, LR Head: 1.2063756291218742e-05,
Best Learning Rate: 0.0001
SAVING
Epoch: 29, Train Loss: 0.1871660202741623, Val mIoU: 0.9335888336332319, Test mIoU: 0.9295472613075864, LR Backbone: 1.1193394209154334e-05, LR Head: 1.1193394209154334e-05,
Epoch: 30, Train Loss: 0.18510156869888306, Val mIoU: 0.9449506477303209, Test mIoU: 0.9339177193527646, LR Backbone: 1.0329397779163372e-05, LR Head: 1.0329397779163372e-05,
Epoch: 31, Train Loss: 0.18589258193969727, Val mIoU: 0.9298484614673153, Test mIoU: 0.9152882910311801, LR Backbone: 9.475976305004153e-06, LR Head: 9.475976305004153e-06,
Epoch: 32, Train Loss: 0.18521679937839508, Val mIoU: 0.954872166711326, Test mIoU: 0.9359087603685391, LR Backbone: 8.637287570313159e-06, LR Head: 8.637287570313159e-06,
Best Learning Rate: 0.0001
SAVING
Epoch: 33, Train Loss: 0.1839609444141388, Val mIoU: 0.9348266016420367, Test mIoU: 0.9207175482737948, LR Backbone: 7.8174175823011e-06, LR Head: 7.8174175823011e-06,
Epoch: 34, Train Loss: 0.18214061856269836, Val mIoU: 0.961622203754134, Test mIoU: 0.937396320390153, LR Backbone: 7.020360665136531e-06, LR Head: 7.020360665136531e-06,
Best Learning Rate: 0.0001
SAVING
Epoch: 35, Train Loss: 0.18308788537979126, Val mIoU: 0.9319037182652313, Test mIoU: 0.921986866319549, LR Backbone: 6.250000000000003e-06, LR Head: 6.250000000000003e-06,
Epoch: 36, Train Loss: 0.1816367208957672, Val mIoU: 0.9416498423258355, Test mIoU: 0.9336495387248953, LR Backbone: 5.510088706615667e-06, LR Head: 5.510088706615667e-06,
Epoch: 37, Train Loss: 0.18144531548023224, Val mIoU: 0.9131095748658855, Test mIoU: 0.8993869981586586, LR Backbone: 4.804231558429271e-06, LR Head: 4.804231558429271e-06,
Epoch: 38, Train Loss: 0.18663671612739563, Val mIoU: 0.9546182036029953, Test mIoU: 0.9314125808956387, LR Backbone: 4.135867420514272e-06, LR Head: 4.135867420514272e-06,
Epoch: 39, Train Loss: 0.1824648380279541, Val mIoU: 0.9343228864191317, Test mIoU: 0.9160050915521215, LR Backbone: 3.50825249576686e-06, LR Head: 3.50825249576686e-06,
Epoch: 40, Train Loss: 0.18085156381130219, Val mIoU: 0.9287296050631126, Test mIoU: 0.9107473740224498, LR Backbone: 2.9244444610127764e-06, LR Head: 2.9244444610127764e-06,
Epoch: 41, Train Loss: 0.18229492008686066, Val mIoU: 0.9444213350167661, Test mIoU: 0.9137872845200348, LR Backbone: 2.3872875703131583e-06, LR Head: 2.3872875703131583e-06,
Epoch: 42, Train Loss: 0.18183983862400055, Val mIoU: 0.9334848477753392, Test mIoU: 0.9040453437632385, LR Backbone: 1.8993987980446755e-06, LR Head: 1.8993987980446755e-06,
Epoch: 43, Train Loss: 0.1806289106607437, Val mIoU: 0.9351151222476504, Test mIoU: 0.9112522036267438, LR Backbone: 1.4631550892634154e-06, LR Head: 1.4631550892634154e-06,
Epoch: 44, Train Loss: 0.18140429258346558, Val mIoU: 0.9320069421873225, Test mIoU: 0.9075569044328775, LR Backbone: 1.0806817794674906e-06, LR Head: 1.0806817794674906e-06,
Epoch: 45, Train Loss: 0.18275585770606995, Val mIoU: 0.9523851587843144, Test mIoU: 0.925976193801312, LR Backbone: 7.538422401761461e-07, LR Head: 7.538422401761461e-07,
Epoch: 46, Train Loss: 0.17708104848861694, Val mIoU: 0.9365186922609035, Test mIoU: 0.9120499361955012, LR Backbone: 4.842288007710166e-07, LR Head: 4.842288007710166e-07,
Epoch: 47, Train Loss: 0.18147461116313934, Val mIoU: 0.9387851328711379, Test mIoU: 0.9135998991660117, LR Backbone: 2.7315499082742893e-07, LR Head: 2.7315499082742893e-07,
Epoch: 48, Train Loss: 0.18016210198402405, Val mIoU: 0.9382739446846293, Test mIoU: 0.9120373335759087, LR Backbone: 1.2164914073037188e-07, LR Head: 1.2164914073037188e-07,
Epoch: 49, Train Loss: 0.17885351181030273, Val mIoU: 0.9384079350757881, Test mIoU: 0.9123050743891636, LR Backbone: 3.044937175219753e-08, LR Head: 3.044937175219753e-08,
Learning Rate: 0.0001
Epoch: 0, Train Loss: 1.3124687671661377, Val mIoU: 0.30974118803159234, Test mIoU: 0.30577673702057867, LR Backbone: 0.0, LR Head: 0.0,
Best Learning Rate: 0.0001
SAVING
Epoch: 1, Train Loss: 0.48737889528274536, Val mIoU: 0.5027974871094415, Test mIoU: 0.5036837396849688, LR Backbone: 5e-06, LR Head: 5e-06,
Best Learning Rate: 0.0001
SAVING
Epoch: 2, Train Loss: 0.3403359353542328, Val mIoU: 0.5093743681567967, Test mIoU: 0.54575813954175, LR Backbone: 1e-05, LR Head: 1e-05,
Best Learning Rate: 0.0001
SAVING
Epoch: 3, Train Loss: 0.31370311975479126, Val mIoU: 0.47529851076781343, Test mIoU: 0.5043257838953124, LR Backbone: 1.5000000000000002e-05, LR Head: 1.5000000000000002e-05,
Epoch: 4, Train Loss: 0.30764061212539673, Val mIoU: 0.47296589677024753, Test mIoU: 0.5051408518101873, LR Backbone: 2e-05, LR Head: 2e-05,
Epoch: 5, Train Loss: 0.29987889528274536, Val mIoU: 0.5399344606380247, Test mIoU: 0.5537890101199938, LR Backbone: 2.5e-05, LR Head: 2.5e-05,
Best Learning Rate: 0.0001
SAVING
Epoch: 6, Train Loss: 0.2912304699420929, Val mIoU: 0.5200681057117652, Test mIoU: 0.5427945404964395, LR Backbone: 2.4969550628247805e-05, LR Head: 2.4969550628247805e-05,
Epoch: 7, Train Loss: 0.28609374165534973, Val mIoU: 0.4618665418576888, Test mIoU: 0.4690949508193931, LR Backbone: 2.487835085926963e-05, LR Head: 2.487835085926963e-05,
Epoch: 8, Train Loss: 0.2836875021457672, Val mIoU: 0.5993134938589646, Test mIoU: 0.656388122289159, LR Backbone: 2.4726845009172572e-05, LR Head: 2.4726845009172572e-05,
Best Learning Rate: 0.0001
SAVING
Epoch: 9, Train Loss: 0.2831484377384186, Val mIoU: 0.5021008159554922, Test mIoU: 0.5230240814544098, LR Backbone: 2.4515771199228987e-05, LR Head: 2.4515771199228987e-05,
Epoch: 10, Train Loss: 0.2780742049217224, Val mIoU: 0.5091434189596573, Test mIoU: 0.5248403954919018, LR Backbone: 2.4246157759823855e-05, LR Head: 2.4246157759823855e-05,
Epoch: 11, Train Loss: 0.27811717987060547, Val mIoU: 0.5294513473982165, Test mIoU: 0.5349207809955548, LR Backbone: 2.391931822053251e-05, LR Head: 2.391931822053251e-05,
Epoch: 12, Train Loss: 0.2722148299217224, Val mIoU: 0.5489226740297566, Test mIoU: 0.5805768251782287, LR Backbone: 2.353684491073659e-05, LR Head: 2.353684491073659e-05,
Epoch: 13, Train Loss: 0.27576953172683716, Val mIoU: 0.5137409720438764, Test mIoU: 0.5360725176974878, LR Backbone: 2.3100601201955324e-05, LR Head: 2.3100601201955324e-05,
Epoch: 14, Train Loss: 0.2697812616825104, Val mIoU: 0.599944860200635, Test mIoU: 0.6304371418161687, LR Backbone: 2.2612712429686845e-05, LR Head: 2.2612712429686845e-05,
Best Learning Rate: 0.0001
SAVING
Epoch: 15, Train Loss: 0.26854100823402405, Val mIoU: 0.5266071420788347, Test mIoU: 0.5305690240682305, LR Backbone: 2.2075555538987227e-05, LR Head: 2.2075555538987227e-05,
Epoch: 16, Train Loss: 0.264892578125, Val mIoU: 0.6388498076710178, Test mIoU: 0.6634423678214294, LR Backbone: 2.1491747504233138e-05, LR Head: 2.1491747504233138e-05,
Best Learning Rate: 0.0001
SAVING

Epoch: 17, Train Loss: 0.26683592796325684, Val mIoU: 0.5134418521847204, Test mIoU: 0.5200549049380154, LR Backbone: 2.086413257948573e-05, LR Head: 2.086413257948573e-05,
Epoch: 18, Train Loss: 0.26637890934944153, Val mIoU: 0.5586888509931422, Test mIoU: 0.5891264017990403, LR Backbone: 2.0195768441570727e-05, LR Head: 2.0195768441570727e-05,
Epoch: 19, Train Loss: 0.2597343623638153, Val mIoU: 0.5365933256037758, Test mIoU: 0.5388540160791901, LR Backbone: 1.9489911293384337e-05, LR Head: 1.9489911293384337e-05,
Epoch: 20, Train Loss: 0.25999608635902405, Val mIoU: 0.60990630618397, Test mIoU: 0.6248760383557899, LR Backbone: 1.8750000000000002e-05, LR Head: 1.8750000000000002e-05,
Epoch: 21, Train Loss: 0.26490235328674316, Val mIoU: 0.5748437523086699, Test mIoU: 0.5916416395183111, LR Backbone: 1.7979639334863467e-05, LR Head: 1.7979639334863467e-05,
Epoch: 22, Train Loss: 0.25938281416893005, Val mIoU: 0.5725340467764863, Test mIoU: 0.5840760478339063, LR Backbone: 1.71825824176989e-05, LR Head: 1.71825824176989e-05,
Epoch: 23, Train Loss: 0.2581484317779541, Val mIoU: 0.5746467826530947, Test mIoU: 0.5727632249094925, LR Backbone: 1.6362712429686846e-05, LR Head: 1.6362712429686846e-05,
Epoch: 24, Train Loss: 0.2626406252384186, Val mIoU: 0.5046176584105079, Test mIoU: 0.5150330838434406, LR Backbone: 1.5524023694995848e-05, LR Head: 1.5524023694995848e-05,
Epoch: 25, Train Loss: 0.25712695717811584, Val mIoU: 0.5617662164257905, Test mIoU: 0.5677870323548105, LR Backbone: 1.4670602220836633e-05, LR Head: 1.4670602220836633e-05,
Epoch: 26, Train Loss: 0.2567499876022339, Val mIoU: 0.6086108103827986, Test mIoU: 0.630528010567146, LR Backbone: 1.380660579084567e-05, LR Head: 1.380660579084567e-05,
Epoch: 27, Train Loss: 0.2550976574420929, Val mIoU: 0.5453209420389552, Test mIoU: 0.5324485279556189, LR Backbone: 1.2936243708781266e-05, LR Head: 1.2936243708781266e-05,
Epoch: 28, Train Loss: 0.25706639885902405, Val mIoU: 0.5207048581259219, Test mIoU: 0.5309242173279822, LR Backbone: 1.2063756291218742e-05, LR Head: 1.2063756291218742e-05,
Epoch: 29, Train Loss: 0.25471875071525574, Val mIoU: 0.5837015736480727, Test mIoU: 0.589514988331348, LR Backbone: 1.1193394209154334e-05, LR Head: 1.1193394209154334e-05,
Epoch: 30, Train Loss: 0.2515859305858612, Val mIoU: 0.6561960365050676, Test mIoU: 0.6760399922290676, LR Backbone: 1.0329397779163372e-05, LR Head: 1.0329397779163372e-05,
Best Learning Rate: 0.0001
SAVING
Epoch: 31, Train Loss: 0.2529257833957672, Val mIoU: 0.590898469807325, Test mIoU: 0.6043897517054749, LR Backbone: 9.475976305004153e-06, LR Head: 9.475976305004153e-06,
Epoch: 32, Train Loss: 0.2509218752384186, Val mIoU: 0.6037962263405466, Test mIoU: 0.6203823937667672, LR Backbone: 8.637287570313159e-06, LR Head: 8.637287570313159e-06,
Epoch: 33, Train Loss: 0.25236913561820984, Val mIoU: 0.6288581623945078, Test mIoU: 0.6394739795817421, LR Backbone: 7.8174175823011e-06, LR Head: 7.8174175823011e-06,
Epoch: 34, Train Loss: 0.24739257991313934, Val mIoU: 0.6012135517152342, Test mIoU: 0.6099664675027874, LR Backbone: 7.020360665136531e-06, LR Head: 7.020360665136531e-06,
Epoch: 35, Train Loss: 0.25126171112060547, Val mIoU: 0.6124343919308213, Test mIoU: 0.6245642238955276, LR Backbone: 6.250000000000003e-06, LR Head: 6.250000000000003e-06,
Epoch: 36, Train Loss: 0.25019142031669617, Val mIoU: 0.5820357910886031, Test mIoU: 0.6009770541792384, LR Backbone: 5.510088706615667e-06, LR Head: 5.510088706615667e-06,
Epoch: 37, Train Loss: 0.2482578158378601, Val mIoU: 0.6306106614372631, Test mIoU: 0.6501357833922021, LR Backbone: 4.804231558429271e-06, LR Head: 4.804231558429271e-06,
Epoch: 38, Train Loss: 0.24668359756469727, Val mIoU: 0.6326188066327009, Test mIoU: 0.6484325070045085, LR Backbone: 4.135867420514272e-06, LR Head: 4.135867420514272e-06,
Epoch: 39, Train Loss: 0.2504570186138153, Val mIoU: 0.5851047469758651, Test mIoU: 0.5997688993398798, LR Backbone: 3.50825249576686e-06, LR Head: 3.50825249576686e-06,
Epoch: 40, Train Loss: 0.24741797149181366, Val mIoU: 0.635587148270869, Test mIoU: 0.6500613478903947, LR Backbone: 2.9244444610127764e-06, LR Head: 2.9244444610127764e-06,
Epoch: 41, Train Loss: 0.24428124725818634, Val mIoU: 0.6129302009136357, Test mIoU: 0.6243613051283619, LR Backbone: 2.3872875703131583e-06, LR Head: 2.3872875703131583e-06,
Epoch: 42, Train Loss: 0.24234570562839508, Val mIoU: 0.6206506743748635, Test mIoU: 0.632040125429141, LR Backbone: 1.8993987980446755e-06, LR Head: 1.8993987980446755e-06,
Epoch: 43, Train Loss: 0.24571093916893005, Val mIoU: 0.6333759926571336, Test mIoU: 0.6410580437421912, LR Backbone: 1.4631550892634154e-06, LR Head: 1.4631550892634154e-06,
Epoch: 44, Train Loss: 0.242738276720047, Val mIoU: 0.6295438903780789, Test mIoU: 0.6407447154592174, LR Backbone: 1.0806817794674906e-06, LR Head: 1.0806817794674906e-06,
Epoch: 45, Train Loss: 0.24506835639476776, Val mIoU: 0.6161854385039931, Test mIoU: 0.6253346680941514, LR Backbone: 7.538422401761461e-07, LR Head: 7.538422401761461e-07,
Epoch: 46, Train Loss: 0.24809570610523224, Val mIoU: 0.6228470084131413, Test mIoU: 0.6331643937660345, LR Backbone: 4.842288007710166e-07, LR Head: 4.842288007710166e-07,
Epoch: 47, Train Loss: 0.24579297006130219, Val mIoU: 0.6283660968929068, Test mIoU: 0.6396112632381616, LR Backbone: 2.7315499082742893e-07, LR Head: 2.7315499082742893e-07,
Epoch: 48, Train Loss: 0.2421601563692093, Val mIoU: 0.6294057140945061, Test mIoU: 0.6407033249061524, LR Backbone: 1.2164914073037188e-07, LR Head: 1.2164914073037188e-07,
Epoch: 49, Train Loss: 0.2424003928899765, Val mIoU: 0.626404132300622, Test mIoU: 0.6372453194449775, LR Backbone: 3.044937175219753e-08, LR Head: 3.044937175219753e-08,
Learning Rate: 0.0001
Epoch: 0, Train Loss: 1.372249960899353, Val mIoU: 0.29159999584980695, Test mIoU: 0.28717070386729493, LR Backbone: 0.0, LR Head: 0.0,
Best Learning Rate: 0.0001
SAVING
Epoch: 1, Train Loss: 0.44517970085144043, Val mIoU: 0.6129311118792824, Test mIoU: 0.6126798213161134, LR Backbone: 5e-06, LR Head: 5e-06,
Best Learning Rate: 0.0001
SAVING
Epoch: 2, Train Loss: 0.24893750250339508, Val mIoU: 0.7183178651601859, Test mIoU: 0.7751843302831221, LR Backbone: 1e-05, LR Head: 1e-05,
Best Learning Rate: 0.0001
SAVING
Epoch: 3, Train Loss: 0.23095703125, Val mIoU: 0.8108212518913092, Test mIoU: 0.8530082047980305, LR Backbone: 1.5000000000000002e-05, LR Head: 1.5000000000000002e-05,
Best Learning Rate: 0.0001
SAVING
Epoch: 4, Train Loss: 0.2211582064628601, Val mIoU: 0.8862879596603381, Test mIoU: 0.9150662403635754, LR Backbone: 2e-05, LR Head: 2e-05,
Best Learning Rate: 0.0001
SAVING
Epoch: 5, Train Loss: 0.21778906881809235, Val mIoU: 0.9012414956297894, Test mIoU: 0.904727587999971, LR Backbone: 2.5e-05, LR Head: 2.5e-05,
Best Learning Rate: 0.0001
SAVING
Epoch: 6, Train Loss: 0.21179687976837158, Val mIoU: 0.9309986843518512, Test mIoU: 0.934806310068512, LR Backbone: 2.4969550628247805e-05, LR Head: 2.4969550628247805e-05,
Best Learning Rate: 0.0001
SAVING
Epoch: 7, Train Loss: 0.2046806663274765, Val mIoU: 0.7146135182924866, Test mIoU: 0.7434816407092555, LR Backbone: 2.487835085926963e-05, LR Head: 2.487835085926963e-05,
Epoch: 8, Train Loss: 0.20503515005111694, Val mIoU: 0.9262628711448065, Test mIoU: 0.9277127374547083, LR Backbone: 2.4726845009172572e-05, LR Head: 2.4726845009172572e-05,
Epoch: 9, Train Loss: 0.20344531536102295, Val mIoU: 0.9007088959501115, Test mIoU: 0.9123675313904236, LR Backbone: 2.4515771199228987e-05, LR Head: 2.4515771199228987e-05,
Epoch: 10, Train Loss: 0.20178906619548798, Val mIoU: 0.8554588116081911, Test mIoU: 0.8875054330551484, LR Backbone: 2.4246157759823855e-05, LR Head: 2.4246157759823855e-05,
Epoch: 11, Train Loss: 0.19685742259025574, Val mIoU: 0.8269066064057204, Test mIoU: 0.8490838279390531, LR Backbone: 2.391931822053251e-05, LR Head: 2.391931822053251e-05,
Epoch: 12, Train Loss: 0.19950976967811584, Val mIoU: 0.9139079559382142, Test mIoU: 0.9157487049280344, LR Backbone: 2.353684491073659e-05, LR Head: 2.353684491073659e-05,
Epoch: 13, Train Loss: 0.19562891125679016, Val mIoU: 0.9471985452807297, Test mIoU: 0.9377408802060638, LR Backbone: 2.3100601201955324e-05, LR Head: 2.3100601201955324e-05,
Best Learning Rate: 0.0001
SAVING

Epoch: 14, Train Loss: 0.19694530963897705, Val mIoU: 0.7441537479083524, Test mIoU: 0.8059011332513064, LR Backbone: 2.2612712429686845e-05, LR Head: 2.2612712429686845e-05,
Epoch: 15, Train Loss: 0.20296679437160492, Val mIoU: 0.8980361819364422, Test mIoU: 0.902729276986322, LR Backbone: 2.2075555538987227e-05, LR Head: 2.2075555538987227e-05,
Epoch: 16, Train Loss: 0.1955878883600235, Val mIoU: 0.8108921675363148, Test mIoU: 0.8322213945134991, LR Backbone: 2.1491747504233138e-05, LR Head: 2.1491747504233138e-05,
Epoch: 17, Train Loss: 0.19421875476837158, Val mIoU: 0.8163293636857447, Test mIoU: 0.8170722500588881, LR Backbone: 2.086413257948573e-05, LR Head: 2.086413257948573e-05,
Epoch: 18, Train Loss: 0.1930234432220459, Val mIoU: 0.8491707948734597, Test mIoU: 0.8660740655191623, LR Backbone: 2.0195768441570727e-05, LR Head: 2.0195768441570727e-05,
Epoch: 19, Train Loss: 0.19266405701637268, Val mIoU: 0.8483964922083473, Test mIoU: 0.8459629718551585, LR Backbone: 1.9489911293384337e-05, LR Head: 1.9489911293384337e-05,
Epoch: 20, Train Loss: 0.19175781309604645, Val mIoU: 0.9187487873229248, Test mIoU: 0.9253587310697821, LR Backbone: 1.8750000000000002e-05, LR Head: 1.8750000000000002e-05,
Epoch: 21, Train Loss: 0.18916405737400055, Val mIoU: 0.9055479794878278, Test mIoU: 0.9135716871314099, LR Backbone: 1.7979639334863467e-05, LR Head: 1.7979639334863467e-05,
Epoch: 22, Train Loss: 0.19048047065734863, Val mIoU: 0.935757336596998, Test mIoU: 0.9319506282498882, LR Backbone: 1.71825824176989e-05, LR Head: 1.71825824176989e-05,
Epoch: 23, Train Loss: 0.18697461485862732, Val mIoU: 0.9365147940519287, Test mIoU: 0.9110374057218417, LR Backbone: 1.6362712429686846e-05, LR Head: 1.6362712429686846e-05,
Epoch: 24, Train Loss: 0.18983203172683716, Val mIoU: 0.8920227433391767, Test mIoU: 0.8857867145921903, LR Backbone: 1.5524023694995848e-05, LR Head: 1.5524023694995848e-05,
Epoch: 25, Train Loss: 0.18754883110523224, Val mIoU: 0.9318003556641766, Test mIoU: 0.9352993825180016, LR Backbone: 1.4670602220836633e-05, LR Head: 1.4670602220836633e-05,
Epoch: 26, Train Loss: 0.18853320181369781, Val mIoU: 0.9318297352190804, Test mIoU: 0.9408828761982315, LR Backbone: 1.380660579084567e-05, LR Head: 1.380660579084567e-05,
Epoch: 27, Train Loss: 0.18605859577655792, Val mIoU: 0.8945716643140578, Test mIoU: 0.8587642831224122, LR Backbone: 1.2936243708781266e-05, LR Head: 1.2936243708781266e-05,
Epoch: 28, Train Loss: 0.18413086235523224, Val mIoU: 0.911304644148254, Test mIoU: 0.9062330143010606, LR Backbone: 1.2063756291218742e-05, LR Head: 1.2063756291218742e-05,
Epoch: 29, Train Loss: 0.1841738224029541, Val mIoU: 0.9195662308709784, Test mIoU: 0.9157614310709522, LR Backbone: 1.1193394209154334e-05, LR Head: 1.1193394209154334e-05,
Epoch: 30, Train Loss: 0.18637500703334808, Val mIoU: 0.8994402968692906, Test mIoU: 0.8766991912418131, LR Backbone: 1.0329397779163372e-05, LR Head: 1.0329397779163372e-05,
Epoch: 31, Train Loss: 0.1850546896457672, Val mIoU: 0.9259993062484319, Test mIoU: 0.9172992668978461, LR Backbone: 9.475976305004153e-06, LR Head: 9.475976305004153e-06,
Epoch: 32, Train Loss: 0.18122461438179016, Val mIoU: 0.9469728118297963, Test mIoU: 0.9321050680684833, LR Backbone: 8.637287570313159e-06, LR Head: 8.637287570313159e-06,
Epoch: 33, Train Loss: 0.18319140374660492, Val mIoU: 0.9442337175062286, Test mIoU: 0.9411662169473066, LR Backbone: 7.8174175823011e-06, LR Head: 7.8174175823011e-06,
Learning Rate: 0.0002
Epoch: 0, Train Loss: 1.2956875562667847, Val mIoU: 0.2663441878278048, Test mIoU: 0.26009322200154444, LR Backbone: 0.0, LR Head: 0.0,
Best Learning Rate: 0.0002
SAVING
Epoch: 1, Train Loss: 0.3624882698059082, Val mIoU: 0.6608877122064973, Test mIoU: 0.7322038171575018, LR Backbone: 1e-05, LR Head: 1e-05,
Best Learning Rate: 0.0002
SAVING
Epoch: 2, Train Loss: 0.2475566416978836, Val mIoU: 0.6368493949951185, Test mIoU: 0.688092153514916, LR Backbone: 2e-05, LR Head: 2e-05,
Epoch: 3, Train Loss: 0.2292773425579071, Val mIoU: 0.7524639651062244, Test mIoU: 0.8061543331888652, LR Backbone: 3.0000000000000004e-05, LR Head: 3.0000000000000004e-05,
Best Learning Rate: 0.0002
SAVING
Epoch: 4, Train Loss: 0.22227734327316284, Val mIoU: 0.9091132375768332, Test mIoU: 0.9171977642718097, LR Backbone: 4e-05, LR Head: 4e-05,
Best Learning Rate: 0.0002
SAVING
Epoch: 5, Train Loss: 0.21293359994888306, Val mIoU: 0.6607581424192283, Test mIoU: 0.6943478990935903, LR Backbone: 5e-05, LR Head: 5e-05,
Epoch: 6, Train Loss: 0.21032226085662842, Val mIoU: 0.8096258460188679, Test mIoU: 0.8248343652624925, LR Backbone: 4.993910125649561e-05, LR Head: 4.993910125649561e-05,
Epoch: 7, Train Loss: 0.20552735030651093, Val mIoU: 0.8274388235441343, Test mIoU: 0.8325366287363659, LR Backbone: 4.975670171853926e-05, LR Head: 4.975670171853926e-05,
Epoch: 8, Train Loss: 0.20561328530311584, Val mIoU: 0.8380615961997913, Test mIoU: 0.8567747113019029, LR Backbone: 4.9453690018345144e-05, LR Head: 4.9453690018345144e-05,
Epoch: 9, Train Loss: 0.19832812249660492, Val mIoU: 0.8852565979407875, Test mIoU: 0.8917367590642846, LR Backbone: 4.9031542398457974e-05, LR Head: 4.9031542398457974e-05,
Epoch: 10, Train Loss: 0.19948242604732513, Val mIoU: 0.8709295248700581, Test mIoU: 0.8437618331874944, LR Backbone: 4.849231551964771e-05, LR Head: 4.849231551964771e-05,
Epoch: 11, Train Loss: 0.19949999451637268, Val mIoU: 0.9435759447075394, Test mIoU: 0.9370463279012569, LR Backbone: 4.783863644106502e-05, LR Head: 4.783863644106502e-05,
Best Learning Rate: 0.0002
SAVING
Epoch: 12, Train Loss: 0.19338086247444153, Val mIoU: 0.8693781806482377, Test mIoU: 0.8410682646963964, LR Backbone: 4.707368982147318e-05, LR Head: 4.707368982147318e-05,
Epoch: 13, Train Loss: 0.19828321039676666, Val mIoU: 0.9202443719151103, Test mIoU: 0.9270509238113881, LR Backbone: 4.620120240391065e-05, LR Head: 4.620120240391065e-05,
Epoch: 14, Train Loss: 0.19887304306030273, Val mIoU: 0.9119149153920396, Test mIoU: 0.9158868269854278, LR Backbone: 4.522542485937369e-05, LR Head: 4.522542485937369e-05,
Epoch: 15, Train Loss: 0.19106639921665192, Val mIoU: 0.8997831579744757, Test mIoU: 0.8833217472377071, LR Backbone: 4.415111107797445e-05, LR Head: 4.415111107797445e-05,
Epoch: 16, Train Loss: 0.1936679631471634, Val mIoU: 0.9163920672437333, Test mIoU: 0.9240825023164976, LR Backbone: 4.2983495008466276e-05, LR Head: 4.2983495008466276e-05,
Epoch: 17, Train Loss: 0.1931132823228836, Val mIoU: 0.8744936854636349, Test mIoU: 0.8627695079332971, LR Backbone: 4.172826515897146e-05, LR Head: 4.172826515897146e-05,
Epoch: 18, Train Loss: 0.1908535212278366, Val mIoU: 0.9049356250388848, Test mIoU: 0.9210976902222756, LR Backbone: 4.039153688314145e-05, LR Head: 4.039153688314145e-05,
Epoch: 19, Train Loss: 0.1877089887857437, Val mIoU: 0.902224669471819, Test mIoU: 0.8947703561989278, LR Backbone: 3.897982258676867e-05, LR Head: 3.897982258676867e-05,
Epoch: 20, Train Loss: 0.1906777322292328, Val mIoU: 0.9159819840365334, Test mIoU: 0.913814761484784, LR Backbone: 3.7500000000000003e-05, LR Head: 3.7500000000000003e-05,
Epoch: 21, Train Loss: 0.18970702588558197, Val mIoU: 0.8621113520820942, Test mIoU: 0.8622090115056886, LR Backbone: 3.5959278669726935e-05, LR Head: 3.5959278669726935e-05,
Epoch: 22, Train Loss: 0.1892441362142563, Val mIoU: 0.9526583393091765, Test mIoU: 0.9356845218997598, LR Backbone: 3.43651648353978e-05, LR Head: 3.43651648353978e-05,
Best Learning Rate: 0.0002
SAVING
Epoch: 23, Train Loss: 0.18582811951637268, Val mIoU: 0.9387031089356932, Test mIoU: 0.9245013647856378, LR Backbone: 3.272542485937369e-05, LR Head: 3.272542485937369e-05,
Epoch: 24, Train Loss: 0.19007422029972076, Val mIoU: 0.9281638052755186, Test mIoU: 0.9138700418531118, LR Backbone: 3.1048047389991696e-05, LR Head: 3.1048047389991696e-05,
Epoch: 25, Train Loss: 0.18641601502895355, Val mIoU: 0.9200734617630804, Test mIoU: 0.913395558599248, LR Backbone: 2.9341204441673266e-05, LR Head: 2.9341204441673266e-05,
Epoch: 26, Train Loss: 0.1865566372871399, Val mIoU: 0.9299529022587101, Test mIoU: 0.9195447651809419, LR Backbone: 2.761321158169134e-05, LR Head: 2.761321158169134e-05,

Epoch: 27, Train Loss: 0.18428124487400055, Val mIoU: 0.9359533728764815, Test mIoU: 0.9363165013521704, LR Backbone: 2.587248741756253e-05, LR Head: 2.587248741756253e-05,
Epoch: 28, Train Loss: 0.18474805355072021, Val mIoU: 0.9298243535995581, Test mIoU: 0.9238578555189599, LR Backbone: 2.4127512582437485e-05, LR Head: 2.4127512582437485e-05,
Epoch: 29, Train Loss: 0.18541210889816284, Val mIoU: 0.909409518673399, Test mIoU: 0.9123259267467747, LR Backbone: 2.238678841830867e-05, LR Head: 2.238678841830867e-05,
Epoch: 30, Train Loss: 0.18485155701637268, Val mIoU: 0.9070875363852382, Test mIoU: 0.9044137557618214, LR Backbone: 2.0658795558326743e-05, LR Head: 2.0658795558326743e-05,
Epoch: 31, Train Loss: 0.18378125131130219, Val mIoU: 0.9290354086954579, Test mIoU: 0.9271274326963397, LR Backbone: 1.8951952610008307e-05, LR Head: 1.8951952610008307e-05,
Epoch: 32, Train Loss: 0.1836816370487213, Val mIoU: 0.9227779033218059, Test mIoU: 0.909318416739454, LR Backbone: 1.7274575140626318e-05, LR Head: 1.7274575140626318e-05,
Epoch: 33, Train Loss: 0.18120703101158142, Val mIoU: 0.9355454548158069, Test mIoU: 0.9315456912466293, LR Backbone: 1.56348351646022e-05, LR Head: 1.56348351646022e-05,
Epoch: 34, Train Loss: 0.18096289038658142, Val mIoU: 0.9572533473364288, Test mIoU: 0.9463811065566543, LR Backbone: 1.4040721330273062e-05, LR Head: 1.4040721330273062e-05,
Best Learning Rate: 0.0002
SAVING
Epoch: 35, Train Loss: 0.17918163537979126, Val mIoU: 0.9394379633912451, Test mIoU: 0.9293886130495621, LR Backbone: 1.2500000000000006e-05, LR Head: 1.2500000000000006e-05,
Epoch: 36, Train Loss: 0.18132421374320984, Val mIoU: 0.9459842194856627, Test mIoU: 0.9309523269708837, LR Backbone: 1.1020177413231334e-05, LR Head: 1.1020177413231334e-05,
Epoch: 37, Train Loss: 0.18302929401397705, Val mIoU: 0.9440140827875125, Test mIoU: 0.930050475404601, LR Backbone: 9.608463116858542e-06, LR Head: 9.608463116858542e-06,
Epoch: 38, Train Loss: 0.18000976741313934, Val mIoU: 0.9609918859935371, Test mIoU: 0.9458666244187228, LR Backbone: 8.271734841028545e-06, LR Head: 8.271734841028545e-06,
Best Learning Rate: 0.0002
SAVING
Epoch: 39, Train Loss: 0.18099218606948853, Val mIoU: 0.950370782633082, Test mIoU: 0.9313325510301123, LR Backbone: 7.01650499153372e-06, LR Head: 7.01650499153372e-06,
Epoch: 40, Train Loss: 0.1801777333021164, Val mIoU: 0.950438252644521, Test mIoU: 0.9190349528443185, LR Backbone: 5.848888922025553e-06, LR Head: 5.848888922025553e-06,
Epoch: 41, Train Loss: 0.18170702457427979, Val mIoU: 0.952457671693465, Test mIoU: 0.9305705859574278, LR Backbone: 4.7745751406263165e-06, LR Head: 4.7745751406263165e-06,
Epoch: 42, Train Loss: 0.18030664324760437, Val mIoU: 0.9477267772823624, Test mIoU: 0.926026637086359, LR Backbone: 3.798797596089351e-06, LR Head: 3.798797596089351e-06,
Epoch: 43, Train Loss: 0.17720311880111694, Val mIoU: 0.9523453875184396, Test mIoU: 0.9367499816595706, LR Backbone: 2.926310178526831e-06, LR Head: 2.926310178526831e-06,
Epoch: 44, Train Loss: 0.17890624701976776, Val mIoU: 0.9593066829856587, Test mIoU: 0.9432233583330276, LR Backbone: 2.161363558934981e-06, LR Head: 2.161363558934981e-06,
Epoch: 45, Train Loss: 0.18091405928134918, Val mIoU: 0.9519377818185397, Test mIoU: 0.9315251400383524, LR Backbone: 1.5076844803522922e-06, LR Head: 1.5076844803522922e-06,
Epoch: 46, Train Loss: 0.17997851967811584, Val mIoU: 0.9522746513848399, Test mIoU: 0.9318823665116078, LR Backbone: 9.684576015420333e-07, LR Head: 9.684576015420333e-07,
Epoch: 47, Train Loss: 0.17768944799900055, Val mIoU: 0.9534822821761326, Test mIoU: 0.9319568553571693, LR Backbone: 5.463099816548579e-07, LR Head: 5.463099816548579e-07,
Epoch: 48, Train Loss: 0.1804531216621399, Val mIoU: 0.9524025737443643, Test mIoU: 0.9304119261869779, LR Backbone: 2.4329828146074376e-07, LR Head: 2.4329828146074376e-07,
Epoch: 49, Train Loss: 0.17897266149520874, Val mIoU: 0.9530333678373304, Test mIoU: 0.9314909821691466, LR Backbone: 6.089874350439506e-08, LR Head: 6.089874350439506e-08,
Learning Rate: 0.0002
Epoch: 0, Train Loss: 1.250406265258789, Val mIoU: 0.30227223118530183, Test mIoU: 0.29722361257685104, LR Backbone: 0.0, LR Head: 0.0,
Best Learning Rate: 0.0002
SAVING
Epoch: 1, Train Loss: 0.43312498927116394, Val mIoU: 0.4954677517350957, Test mIoU: 0.5265474948734727, LR Backbone: 1e-05, LR Head: 1e-05,
Best Learning Rate: 0.0002
SAVING
Epoch: 2, Train Loss: 0.3280976414680481, Val mIoU: 0.47736046484639294, Test mIoU: 0.5132676175844344, LR Backbone: 2e-05, LR Head: 2e-05,
Epoch: 3, Train Loss: 0.3048163950443268, Val mIoU: 0.4465458540950243, Test mIoU: 0.4648644083943548, LR Backbone: 3.0000000000000004e-05, LR Head: 3.0000000000000004e-05,
Epoch: 4, Train Loss: 0.29969921708106995, Val mIoU: 0.5160792603675537, Test mIoU: 0.5362552498604366, LR Backbone: 4e-05, LR Head: 4e-05,
Best Learning Rate: 0.0002
SAVING
Epoch: 5, Train Loss: 0.29413673281669617, Val mIoU: 0.4967471304388219, Test mIoU: 0.5106845320052849, LR Backbone: 5e-05, LR Head: 5e-05,
Epoch: 6, Train Loss: 0.2869296967983246, Val mIoU: 0.5482001748732294, Test mIoU: 0.5720743670879892, LR Backbone: 4.993910125649561e-05, LR Head: 4.993910125649561e-05,
Best Learning Rate: 0.0002
SAVING
Epoch: 7, Train Loss: 0.2819218635559082, Val mIoU: 0.5527533800587638, Test mIoU: 0.5669221709411113, LR Backbone: 4.975670171853926e-05, LR Head: 4.975670171853926e-05,
Best Learning Rate: 0.0002
SAVING
Epoch: 8, Train Loss: 0.2817656397819519, Val mIoU: 0.5066705844577699, Test mIoU: 0.49499170510613233, LR Backbone: 4.9453690018345144e-05, LR Head: 4.9453690018345144e-05,
Epoch: 9, Train Loss: 0.2793789207935333, Val mIoU: 0.5416131504024754, Test mIoU: 0.5300417559376867, LR Backbone: 4.9031542398457974e-05, LR Head: 4.9031542398457974e-05,
Epoch: 10, Train Loss: 0.2716953158378601, Val mIoU: 0.600188066558679, Test mIoU: 0.6315110891048619, LR Backbone: 4.849231551964771e-05, LR Head: 4.849231551964771e-05,
Best Learning Rate: 0.0002
SAVING
Epoch: 11, Train Loss: 0.2720703184604645, Val mIoU: 0.5716251523044638, Test mIoU: 0.5743051753140983, LR Backbone: 4.783863644106502e-05, LR Head: 4.783863644106502e-05,
Epoch: 12, Train Loss: 0.2707890570163727, Val mIoU: 0.5456312645468072, Test mIoU: 0.5679890694418311, LR Backbone: 4.707368982147318e-05, LR Head: 4.707368982147318e-05,
Epoch: 13, Train Loss: 0.2650683522224426, Val mIoU: 0.5459059607302245, Test mIoU: 0.5755119918569687, LR Backbone: 4.620120240391065e-05, LR Head: 4.620120240391065e-05,
Epoch: 14, Train Loss: 0.2724882960319519, Val mIoU: 0.5771156636829868, Test mIoU: 0.5742956214954171, LR Backbone: 4.522542485937369e-05, LR Head: 4.522542485937369e-05,
Epoch: 15, Train Loss: 0.26723048090934753, Val mIoU: 0.5540059212199994, Test mIoU: 0.5561361825045256, LR Backbone: 4.415111107797445e-05, LR Head: 4.415111107797445e-05,
Epoch: 16, Train Loss: 0.2609921991825104, Val mIoU: 0.5305758576598392, Test mIoU: 0.5288646951688777, LR Backbone: 4.2983495008466276e-05, LR Head: 4.2983495008466276e-05,
Epoch: 17, Train Loss: 0.2639843821525574, Val mIoU: 0.4715435764718485, Test mIoU: 0.4768124693563492, LR Backbone: 4.172826515897146e-05, LR Head: 4.172826515897146e-05,
Epoch: 18, Train Loss: 0.26554688811302185, Val mIoU: 0.47080192226782674, Test mIoU: 0.48661320928726826, LR Backbone: 4.039153688314145e-05, LR Head: 4.039153688314145e-05,
Epoch: 19, Train Loss: 0.2570468783378601, Val mIoU: 0.5286039003303674, Test mIoU: 0.5432454864833557, LR Backbone: 3.897982258676867e-05, LR Head: 3.897982258676867e-05,
Epoch: 20, Train Loss: 0.2597343623638153, Val mIoU: 0.5436966821942593, Test mIoU: 0.5611993121073783, LR Backbone: 3.7500000000000003e-05, LR Head: 3.7500000000000003e-05,
Epoch: 21, Train Loss: 0.2595878839492798, Val mIoU: 0.5857215471468111, Test mIoU: 0.5915802481773731, LR Backbone: 3.5959278669726935e-05, LR Head: 3.5959278669726935e-05,
Epoch: 22, Train Loss: 0.25733789801597595, Val mIoU: 0.5299342124187432, Test mIoU: 0.5298158922308573, LR Backbone: 3.43651648353978e-05, LR Head: 3.43651648353978e-05,
Epoch: 23, Train Loss: 0.2560039162635803, Val mIoU: 0.5377794672898922, Test mIoU: 0.5425238948474572, LR Backbone: 3.272542485937369e-05, LR Head: 3.272542485937369e-05,

Epoch: 24, Train Loss: 0.2562773525714874, Val mIoU: 0.5314149894149347, Test mIoU: 0.5340377690555104, LR Backbone: 3.1048047389991696e-05, LR Head: 3.1048047389991696e-05,
Epoch: 25, Train Loss: 0.2510410249233246, Val mIoU: 0.6654868621097441, Test mIoU: 0.6631278826498411, LR Backbone: 2.9341204441673266e-05, LR Head: 2.9341204441673266e-05,
Best Learning Rate: 0.0002
SAVING
Epoch: 26, Train Loss: 0.2577187418937683, Val mIoU: 0.6018949910039272, Test mIoU: 0.6098086401206281, LR Backbone: 2.761321158169134e-05, LR Head: 2.761321158169134e-05,
Epoch: 27, Train Loss: 0.250431627035141, Val mIoU: 0.5214674473924776, Test mIoU: 0.5298664964589643, LR Backbone: 2.587248741756253e-05, LR Head: 2.587248741756253e-05,
Epoch: 28, Train Loss: 0.2540332078933716, Val mIoU: 0.5661496118806364, Test mIoU: 0.5950069436192463, LR Backbone: 2.4127512582437485e-05, LR Head: 2.4127512582437485e-05,
Epoch: 29, Train Loss: 0.2486923784017563, Val mIoU: 0.528872263620844, Test mIoU: 0.5326416980093873, LR Backbone: 2.238678841830867e-05, LR Head: 2.238678841830867e-05,
Epoch: 30, Train Loss: 0.2498769462108612, Val mIoU: 0.6985934730602017, Test mIoU: 0.7180259667025867, LR Backbone: 2.0658795558326743e-05, LR Head: 2.0658795558326743e-05,
Best Learning Rate: 0.0002
SAVING
Epoch: 31, Train Loss: 0.24683398008346558, Val mIoU: 0.5937243532804501, Test mIoU: 0.5915425853809071, LR Backbone: 1.8951952610008307e-05, LR Head: 1.8951952610008307e-05,
Epoch: 32, Train Loss: 0.24990233778953552, Val mIoU: 0.5174442182466898, Test mIoU: 0.5348702863253678, LR Backbone: 1.7274575140626318e-05, LR Head: 1.7274575140626318e-05,
Epoch: 33, Train Loss: 0.24604101479053497, Val mIoU: 0.6544997582343682, Test mIoU: 0.6548923392569342, LR Backbone: 1.56348351646022e-05, LR Head: 1.56348351646022e-05,
Epoch: 34, Train Loss: 0.24587500095367432, Val mIoU: 0.6469416129921555, Test mIoU: 0.6529750474905995, LR Backbone: 1.4040721330273062e-05, LR Head: 1.4040721330273062e-05,
Epoch: 35, Train Loss: 0.2463984340429306, Val mIoU: 0.5511205796094559, Test mIoU: 0.5543321980941406, LR Backbone: 1.2500000000000006e-05, LR Head: 1.2500000000000006e-05,
Epoch: 36, Train Loss: 0.24794921278953552, Val mIoU: 0.621030486953754, Test mIoU: 0.6255489516387288, LR Backbone: 1.1020177413231334e-05, LR Head: 1.1020177413231334e-05,
Epoch: 37, Train Loss: 0.24744531512260437, Val mIoU: 0.6115845384004334, Test mIoU: 0.6066234953041085, LR Backbone: 9.608463116858542e-06, LR Head: 9.608463116858542e-06,
Epoch: 38, Train Loss: 0.24721288681030273, Val mIoU: 0.6695339707593283, Test mIoU: 0.664179761637619, LR Backbone: 8.271734841028545e-06, LR Head: 8.271734841028545e-06,
Epoch: 39, Train Loss: 0.2452070266008377, Val mIoU: 0.592197720967175, Test mIoU: 0.5995491117984436, LR Backbone: 7.01650499153372e-06, LR Head: 7.01650499153372e-06,
Epoch: 40, Train Loss: 0.2446250021457672, Val mIoU: 0.6192669283992408, Test mIoU: 0.6213280415624509, LR Backbone: 5.848888922025553e-06, LR Head: 5.848888922025553e-06,
Epoch: 41, Train Loss: 0.2402988225221634, Val mIoU: 0.6108003327071181, Test mIoU: 0.6141867766182758, LR Backbone: 4.7745751406263165e-06, LR Head: 4.7745751406263165e-06,

